@inproceedings{wan2024white,
  title={White Men Lead, Black Women Help? Benchmarking Language Agency Social Biases in LLMs},
paper_url={https://arxiv.org/abs/2404.10508},
  author={Yixin Wan, Md. Rizwan Parvez},
  pub_type=pre-print,
  year={2024},
  abstract={Language agency is an important aspect of evaluating social biases in texts. While several studies approached agency-related bias in human-written language, very limited research has investigated such biases in Large Language Model (LLM)-generated content. In addition, previous research often relies on string-matching techniques to identify agentic and communal words within texts, which fall short of accurately classifying language agency. We introduce the novel Language Agency Bias Evaluation (LABE) benchmark, which comprehensively evaluates biases in LLMs by analyzing agency levels attributed to different demographic groups in model generations. LABE leverages 5,400 template-based prompts, an accurate agency classifier, and corresponding bias metrics to test for gender, racial, and intersectional language agency biases in LLMs on 3 text generation tasks: biographies, professor reviews, and reference letters. To build better and more accurate automated agency classifiers, we also contribute and release the Language Agency Classification (LAC) dataset, consisting of 3,724 agentic and communal sentences. Using LABE, we unveil previously under-explored language agency social biases in 3 recent LLMs: ChatGPT, Llama3, and Mistral. We observe that: (1) For the same text category, LLM generations demonstrate higher levels of gender bias than human-written texts; (2) On most generation tasks, models show remarkably higher levels of intersectional bias than the other bias aspects. Those who are at the intersection of gender and racial minority groups -- such as Black females -- are consistently described by texts with lower levels of agency; (3) Among the 3 LLMs investigated, Llama3 demonstrates greatest overall bias in language agency; (4) Not only does prompt-based mitigation fail to resolve language agency bias in LLMs, but it frequently leads to the exacerbation of biases in generated texts.},
keynote={Best paper at TrustNLP workshop at NAACL 2024},
}



@inproceedings{wang2024journeybench,
  title = {JourneyBench: A Challenging One-Stop Vision-Language Understanding Benchmark of Generated Images},
  author = {Wang, Zhecan and Liu, Junzhang and Tang, Chia-Wei and Alomari, Hani and Sivakumar, Anushka and Sun, Rui and Li, Wenhao and Atabuzzaman, Md. and Ayyubi, Hammad and You, Haoxuan and Ishmam, Alvi Md and Chang, Kai-Wei and Chang, Shih-Fu and Thomas, Chris},
  paper_url={https://arxiv.org/abs/2409.12953},
  abstract = {Existing vision-language understanding benchmarks largely consist of images of objects in their usual contexts. As a consequence, recent multimodal large language models can perform well with only a shallow visual understanding by relying on background language biases. Thus, strong performance on these benchmarks does not necessarily correlate with strong visual understanding. In this paper, we release JourneyBench, a comprehensive human-annotated benchmark of generated images designed to assess the model's fine-grained multimodal reasoning abilities across five tasks: complementary multimodal chain of thought, multi-image VQA, imaginary image captioning, VQA with hallucination triggers, and fine-grained retrieval with sample-specific distractors. Unlike existing benchmarks, JourneyBench explicitly requires fine-grained multimodal reasoning in unusual imaginary scenarios where language bias and holistic image gist are insufficient. We benchmark state-of-the-art models on JourneyBench and analyze performance along a number of fine-grained dimensions. Results across all five tasks show that JourneyBench is exceptionally challenging for even the best models, indicating that models' visual reasoning abilities are not as strong as they first appear. We discuss the implications of our findings and propose avenues for further research.},
  booktitle = {NeurIPS (Datasets and Benchmarks Track)},
  rank = 16, 
  year = {2024}
}

@inproceedings{wu2024daco,
  title = {DACO: Towards Application-Driven and Comprehensive Data Analysis via Code Generation},
  author = {Wu, Xueqing and Zheng, Rui and Sha, Jingzhen and Wu, Te-Lin and Zhou, Hanyu and Mohan, Tang and Chang, Kai-Wei and Peng, Nanyun and Huang, Haoran},
  booktitle = {NeurIPS (Datasets and Benchmarks Track)},
  abstract = {Data analysis is a crucial analytical process to generate in-depth studies and conclusive insights to comprehensively answer a given user query for tabular data. In this work, we aim to propose new resources and benchmarks to inspire future research on this crucial yet challenging and under-explored task. However, collecting data analysis annotations curated by experts can be prohibitively expensive. We propose to automatically generate high-quality answer annotations leveraging the code-generation capabilities of LLMs with a multi-turn prompting technique. We construct the DACO dataset, containing (1) 440 databases (of tabular data) collected from real-world scenarios, (2) ~2k query-answer pairs that can serve as weak supervision for model training, and (3) a concentrated but high-quality test set with human refined annotations that serves as our main evaluation benchmark. We train a 6B supervised fine-tuning (SFT) model on DACO dataset, and find that the SFT model learns reasonable data analysis capabilities. To further align the models with human preference, we use reinforcement learning to encourage generating analysis perceived by human as helpful, and design a set of dense rewards to propagate the sparse human preference reward to intermediate code generation steps. Our DACO-RL algorithm is evaluated by human annotators to produce more helpful answers than SFT model in 57.72% cases, validating the effectiveness of our proposed algorithm.},
  github_url={https://github.com/shirley-wu/daco},
  paper_url = {https://arxiv.org/abs/2403.02528},
  rank = 16,
  year = {2024}
}


@inproceedings{deng2024enhancing,
  title = {Enhancing Large Vision Language Models with Self-Training on Image Comprehension},
  author = {Deng, Yihe and Lu, Pan and Yin, Fan and Hu, Ziniu and Shen, Sheng and Gu, Quanquan and Zou, James and Chang, Kai-Wei and Wang, Wei},
  booktitle = {NeurIPS},
  paper_url = {https://arxiv.org/abs/2405.19716},
  abstract = {Large vision language models (LVLMs) integrate large language models (LLMs) with pre-trained vision encoders, thereby activating the perception capability of the model to understand image inputs for different queries and conduct subsequent reasoning. Improving this capability requires high-quality vision-language data, which is costly and labor-intensive to acquire. Self-training approaches have been effective in single-modal settings to alleviate the need for labeled data by leveraging model's own generation. However, effective self-training remains a challenge regarding the unique visual perception and reasoning capability of LVLMs. To address this, we introduce Self-Training on Image Comprehension (STIC), which emphasizes a self-training approach specifically for image comprehension. First, the model self-constructs a preference dataset for image descriptions using unlabeled images. Preferred responses are generated through a step-by-step prompt, while dis-preferred responses are generated from either corrupted images or misleading prompts. To further self-improve reasoning on the extracted visual information, we let the model reuse a small portion of existing instruction-tuning data and append its self-generated image descriptions to the prompts. We validate the effectiveness of STIC across seven different benchmarks, demonstrating substantial performance gains of 4.0% on average while using 70% less supervised fine-tuning data than the current method. Further studies investigate various components of STIC and highlight its potential to leverage vast quantities of unlabeled images for self-training. Code and data are made publicly available.},
  rank = 15, 
  year = {2024}
}

@inproceedings{hu2024mqt,
  title = {MQT-LLaVA: Matryoshka Query Transformer for Large Vision-Language Models},
  author = {Hu, Wenbo and Dou, Zi-Yi and Li, Liunian Harold and Kamath, Amita and Peng, Nanyun and Chang, Kai-Wei},
  booktitle = {NeurIPS},
  paper_url = {https://arxiv.org/abs/2405.19315},
  rank = 15,
  year = {2024}
}


@inproceedings{yin2024safeworld,
  title = {SafeWorld: Geo-Diverse Safety Alignment},
  author = {Yin, Da and Qiu, Haoyi and Huang, Kung-Hsiang and Chang, Kai-Wei and Peng, Nanyun},
  booktitle = {NeurIPS},
  abstract = {Content Warning: This paper may contain examples of harmful contents by nature.
In the rapidly evolving field of Large Language Models (LLMs), ensuring safety
is a crucial and widely discussed topic. However, existing works often overlook
the geo-diversity of cultural and legal standards across the world. To demonstrate
the challenges posed by geo-diverse safety standards, we introduce SAFEWORLD,
a novel benchmark specifically designed to evaluate LLMs' ability to generate
responses that are not only helpful but also culturally sensitive and legally compliant across diverse global contexts. SAFEWORLD encompasses 2,775 test user
queries, each grounded in high-quality, human-verified cultural norms and legal
policies from 50 countries and 493 regions/races. On top of it, we propose a multidimensional automatic safety evaluation framework that assesses the contextual
appropriateness, accuracy, and comprehensiveness of responses. Our evaluations
reveal that current LLMs struggle to meet these criteria. To enhance LLMs' alignment with geo-diverse safety standards, we synthesize helpful preference pairs for
Direct Preference Optimization (DPO) alignment training. The preference pair
construction aims to encourage LLMs to behave appropriately and provide precise
references to relevant cultural norms and policies when necessary. Our trained
SAFEWORLDLM outperforms all competing models, including GPT-4o on all the
three evaluation dimensions by a large margin. Global human evaluators also note
a nearly 20% higher winning rate in helpfulness and harmfulness evaluation.},
  rank = 15,
  year = {2024}
}

@inproceedings{mehrabi2024flirt,
  title = {FLIRT: Feedback Loop In-context Red Teaming},
  paper_url={https://arxiv.org/abs/2308.04265},
  author = {Mehrabi, Ninareh and Goyal, Palash and Dupuy, Christophe and Hu, Qian and Ghosh, Shalini and Zemel, Richard and Chang, Kai-Wei and Galstyan, Aram and Gupta, Rahul},
  booktitle = {EMNLP},
  abstract={As generative models become available for public use in various applications, testing and analyzing vulnerabilities of these models has become a priority. Here we propose an automatic red teaming framework that evaluates a given model and exposes its vulnerabilities against unsafe and inappropriate content generation. Our framework uses in-context learning in a feedback loop to red team models and trigger them into unsafe content generation. We propose different in-context attack strategies to automatically learn effective and diverse adversarial prompts for text-to-image models. Our experiments demonstrate that compared to baseline approaches, our proposed strategy is significantly more effective in exposing vulnerabilities in Stable Diffusion (SD) model, even when the latter is enhanced with safety features. Furthermore, we demonstrate that the proposed framework is effective for red teaming text-to-text models, resulting in significantly higher toxic response generation rate compared to previously reported numbers.},
  rank = 18,
  year = {2024}
}

@inproceedings{suvarna2024qudselect,
  title = {QUDSELECT: Selective Decoding for Questions Under Discussion Parsing},
  author = {Suvarna, Ashima and Liu, Xiao and Parekh, Tanmay and Chang, Kai-Wei and Peng, Nanyun},
  booktitle = {EMNLP},
  abstract={Question Under Discussion (QUD) is a discourse framework that uses implicit questions to reveal discourse relationships between sentences. In QUD parsing, each sentence is viewed as an answer to a question triggered by an anchor sentence in prior context. The resulting QUD structure is required to conform to several theoretical criteria like answer compatibility (how well the question is answered), making QUD parsing a challenging task. Previous works construct QUD parsers in a pipelined manner (i.e. detect the trigger sentence in context and then generate the question). However, these parsers lack a holistic view of the task and can hardly satisfy all the criteria. In this work, we introduce QUDSELECT, a joint-training framework that selectively decodes the QUD dependency structures considering the QUD criteria. Using instruction-tuning, we train models to simultaneously predict the anchor sentence and generate the associated question. To explicitly incorporate the criteria, we adopt a selective decoding strategy of sampling multiple QUD candidates during inference, followed by selecting the best one with criteria scorers. Our method outperforms the state-of-the-art baseline models by 9% in human evaluation and 4% in automatic evaluation, demonstrating the effectiveness of our framework.},
  rank = 18,
  paper_url="https://arxiv.org/abs/2408.01046",
  year = {2024}
}

@inproceedings{meng2024llm,
  title = {LLM-A*: Large Language Model Enhanced Incremental Heuristic Search on Path Planning},
  author = {Meng, Silin and Wang, Yiwei and Yang, Cheng-Fu and Peng, Nanyun and Chang, Kai-Wei},
  booktitle = {EMNLP-Finding},
  rank = 19,
  paper_url={https://arxiv.org/abs/2407.02511},
  abstract={Path planning is a fundamental scientific problem in robotics and autonomous navigation, requiring the derivation of efficient routes from starting to destination points while avoiding obstacles. Traditional algorithms like A* and its variants are capable of ensuring path validity but suffer from significant computational and memory inefficiencies as the state space grows. Conversely, large language models (LLMs) excel in broader environmental analysis through contextual understanding, providing global insights into environments. However, they fall short in detailed spatial and temporal reasoning, often leading to invalid or inefficient routes. In this work, we propose LLM-A*, an new LLM based route planning method that synergistically combines the precise pathfinding capabilities of A* with the global reasoning capability of LLMs. This hybrid approach aims to enhance pathfinding efficiency in terms of time and space complexity while maintaining the integrity of path validity, especially in large-scale scenarios. By integrating the strengths of both methodologies, LLM-A* addresses the computational and memory limitations of conventional algorithms without compromising on the validity required for effective pathfinding.},
  year = {2024}
}

@inproceedings{wang2024data,
  title = {Data Advisor: Data Curation with Foresight for Safety Alignment of Large Language Models},
  author = {Wang, Fei and Mehrabi, Ninareh and Goyal, Palash and Gupta, Rahul and Chang, Kai-Wei and Galstyan, Aram},
  booktitle = {EMNLP},
  paper_url = {https://arxiv.org/abs/2410.05269},
  abstract = {Data is a crucial element in large language model (LLM) alignment. Recent studies have explored using LLMs for efficient data collection. However, LLM-generated data often suffers from quality issues, with underrepresented or absent aspects and low-quality datapoints. To address these problems, we propose Data Advisor, an enhanced LLM-based method for generating data that takes into account the characteristics of the desired dataset. Starting from a set of pre-defined principles in hand, Data Advisor monitors the status of the generated data, identifies weaknesses in the current dataset, and advises the next iteration of data generation accordingly. Data Advisor can be easily integrated into existing data generation methods to enhance data quality and coverage. Experiments on safety alignment of three representative LLMs (i.e., Mistral, Llama2, and Falcon) demonstrate the effectiveness of Data Advisor in enhancing model safety against various fine-grained safety issues without sacrificing model utility.},
  rank = 18,
  year = {2024}
}

@inproceedings{wan2024factuality,
  title = {The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention},
  author = {Wan, Yixin and Wu, Di and Wang, Haoran and Chang, Kai-Wei},
  booktitle = {EMNLP},
  paper_url={https://arxiv.org/abs/2407.00377},
  abstract={Prompt-based "diversity interventions" are commonly adopted to improve the diversity of Text-to-Image (T2I) models depicting individuals with various racial or gender traits. However, will this strategy result in nonfactual demographic distribution, especially when generating real historical figures? In this work, we propose DemOgraphic FActualIty Representation (DoFaiR), a benchmark to systematically quantify the trade-off between using diversity interventions and preserving demographic factuality in T2I models. DoFaiR consists of 756 meticulously fact-checked test instances to reveal the factuality tax of various diversity prompts through an automated evidence-supported evaluation pipeline. Experiments on DoFaiR unveil that diversity-oriented instructions increase the number of different gender and racial groups in DALLE-3's generations at the cost of historically inaccurate demographic distributions. To resolve this issue, we propose Fact-Augmented Intervention (FAI), which instructs a Large Language Model (LLM) to reflect on verbalized or retrieved factual information about gender and racial compositions of generation subjects in history, and incorporate it into the generation context of T2I models. By orienting model generations using the reflected historical truths, FAI significantly improves the demographic factuality under diversity interventions while preserving diversity.},
  rank = 18,
  year = {2024}
}

@inproceedings{wu2024synchronous,
  title = {Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation},
  author = {Wu, Di and Gu, Jia-Chen and Yin, Fan and Peng, Nanyun and Chang, Kai-Wei},
  booktitle = {EMNLP},
  abstract={Retrieval-augmented language models (RALMs) have shown strong performance and wide applicability in knowledge-intensive tasks. However, there are significant trustworthiness concerns as RALMs are prone to generating unfaithful outputs, including baseless information or contradictions with the retrieved context. This paper proposes SynCheck, a lightweight monitor that leverages fine-grained decoding dynamics including sequence likelihood, uncertainty quantification, context influence, and semantic alignment to synchronously detect unfaithful sentences. By integrating efficiently measurable and complementary signals, SynCheck enables accurate and immediate feedback and intervention, achieving 0.85 AUROC in detecting faithfulness errors across six long-form retrieval-augmented generation tasks, improving prior best method by 4%. Leveraging SynCheck, we further introduce FOD, a faithfulness-oriented decoding algorithm guided by beam search for long-form retrieval-augmented generation. Empirical results demonstrate that FOD outperforms traditional strategies such as abstention, reranking, or contrastive decoding significantly in terms of faithfulness, achieving over 10% improvement across six datasets.},
  paper_url={https://arxiv.org/abs/2406.13692},
  rank = 18,
  year = {2024}
}


@inproceedings{parekh2024speed,
  title = {SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness},
  author = {Parekh, Tanmay and Kwan, Jeffrey and Yu, Jiarui and Johri, Sparsh and Ahn, Hyosang and Muppalla, Sreya and Chang, Kai-Wei and Wang, Wei and Peng, Nanyun},
  booktitle = {EMNLP},
  paper_url = {https://aclanthology.org/2024.emnlp-main.720.pdf},
  abstract = {Social media is often the first place where communities discuss the latest societal trends. Prior works have utilized this platform to extract epidemic-related information (e.g. infections, preventive measures) to provide early warnings for epidemic prediction. However, these works only focused on English posts, while epidemics can occur anywhere in the world, and early discussions are often in the local, non-English languages. In this work, we introduce the first multilingual Event Extraction (EE) framework SPEED++ for extracting epidemic event information for any disease and language. To this end, we extend a previous epidemic ontology with 20 argument roles; and curate our multilingual EE dataset SPEED++ comprising 5.1K tweets in four languages for four diseases. Annotating data in every language is infeasible; thus we develop zero-shot cross-lingual cross-disease models (i.e., training only on English COVID data) utilizing multilingual pre-training and show their efficacy in extracting epidemic-related events for 65 diverse languages across different diseases. Experiments demonstrate that our framework can provide epidemic warnings for COVID-19 in its earliest stages in Dec 2019 (3 weeks before global discussions) from Chinese Weibo posts without any training in Chinese. Furthermore, we exploit our framework's argument extraction capabilities to aggregate community epidemic discussions like symptoms and cure measures, aiding misinformation detection and public attention monitoring. Overall, we lay a strong foundation for multilingual epidemic preparedness.},
  rank = 18,
  year = {2024}, 
  
}

@inproceedings{wu2024macaroon,
  title = {MACAROON: Training Vision-Language Models To Be Your Engaged Partners},
  author = {Wu, Shujin and Fung, Yi and Li, Sha and Wan, Yixin and Chang, Kai-Wei and Ji, Heng},
  booktitle = {EMNLP-Finding},
  rank = 19,
  paper_url={https://arxiv.org/abs/2406.14137},
  abstract={Large vision-language models (LVLMs), while proficient in following instructions and responding to diverse questions, invariably generate detailed responses even when questions are ambiguous or unanswerable, leading to hallucinations and bias issues. Thus, it is essential for LVLMs to proactively engage with humans to ask for clarifications or additional information for better responses. In this study, we aim to shift LVLMs from passive answer providers to proactive engaged partners. We begin by establishing a three-tiered hierarchy for questions of invalid, ambiguous, and personalizable nature to measure the proactive engagement capabilities of LVLMs. Utilizing this hierarchy, we create PIE, (ProactIve Engagement Evaluation) through GPT-4o and human annotators, consisting of 853 questions across six distinct, fine-grained question types that are verified by human annotators and accompanied with well-defined metrics. Our evaluations on \benchmark indicate poor performance of existing LVLMs, with the best-performing open-weights model only achieving an Aggregate Align Rate (AAR) of 0.28. In response, we introduce MACAROON, self-iMaginAtion for ContrAstive pReference OptimizatiON, which instructs LVLMs to autonomously generate contrastive response pairs for unlabeled questions given the task description and human-crafted criteria. Then, the self-imagined data is formatted for conditional reinforcement learning. Experimental results show MACAROON effectively improves LVLMs' capabilities to be proactively engaged (0.84 AAR) while maintaining comparable performance on general tasks.},
year = {2024}
}

@inproceedings{wu2024metakp,
  title = {MetaKP: On-Demand Keyphrase Generation},
  author = {Wu, Di and Shen, Xiaoxian and Chang, Kai-Wei},
  booktitle = {EMNLP-Finding},
  paper_url={https://arxiv.org/abs/2407.00191},
  abstract={Traditional keyphrase prediction methods predict a single set of keyphrases per document, failing to cater to the diverse needs of users and downstream applications. To bridge the gap, we introduce on-demand keyphrase generation, a novel paradigm that requires keyphrases that conform to specific high-level goals or intents. For this task, we present MetaKP, a large-scale benchmark comprising four datasets, 7500 documents, and 3760 goals across news and biomedical domains with human-annotated keyphrases. Leveraging MetaKP, we design both supervised and unsupervised methods, including a multi-task fine-tuning approach and a self-consistency prompting method with large language models. The results highlight the challenges of supervised fine-tuning, whose performance is not robust to distribution shifts. By contrast, the proposed self-consistency prompting approach greatly improves the performance of large language models, enabling GPT-4o to achieve 0.548 SemF1, surpassing the performance of a fully fine-tuned BART-base model. Finally, we demonstrate the potential of our method to serve as a general NLP infrastructure, exemplified by its application in epidemic event detection from social media.},
  rank = 19,
  year = {2024}
}

@inproceedings{li2024llms,
  title = {Control Large Language Models via Divide and Conquer},
  author = {Li, Bingxuan and Wang, Yiwei and Meng, Tao and Chang, Kai-Wei and Peng, Nanyun },
  booktitle = {EMNLP},
  paper_url={https://aclanthology.org/2024.emnlp-main.850.pdf},
  abstrct= {This paper investigates the capability of LLMs on controllable generation with prompt-based controlling, focusing on Lexically Constrained Generation (LCG). We systematically evaluate the performance of LLMs on satisfying lexical constraints with prompt-based controlling, as well as their efficacy in downstream applications. We identified three key reasons that highlight the limitations of LLMs in LCG, including (1) position bias, where LLMs tend to satisfy constraints that appear in specific positions within the input; (2) low responsiveness to control decoding parameters, which minimally impact the performance of LLMs; and (3) struggle with handling the inherent complexity of certain constraints (e.g. compound word). We conclude that black-box LLMs face significant challenges in consistently satisfying lexical constraints with prompt-based controlling. To address this bottleneck, we introduce the Divide and Conquer Generation strategy, effective for both white-box and black-box LLMs, to enhance LLMs performance in LCG tasks, which demonstrates over 90% improvement on success rate in the most challenging LCG task. Our analysis aims to provide valuable insights into the performance of LLMs in LCG with prompt-based controlling, and our proposed strategy offers a pathway to more sophisticated and customized text generation applications.},
  rank = 18,
  year = {2024}
}

@inproceedings{dou2024rere,
  title = {Re-ReST: Reflection-Reinforced Self-Training for Language Agents},
  author = {Dou, Zi-Yi and Yang, Cheng-Fu and Wu, Xueqing and Chang, Kai-Wei and Peng, Nanyun},
  booktitle = {EMNLP},
  rank = 18,
  year = {2024},
  paper_url={https://arxiv.org/abs/2406.01495},
  abstrct={Finetuning language agents with reasoning-action trajectories is effective, but obtaining these trajectories from human annotations or stronger models is costly and sometimes impractical. In this paper, we investigate the use of self-training in language agents, which can generate supervision from the agent itself, offering a promising alternative without relying on human or stronger model demonstrations. Self-training, however, requires high-quality model-generated samples, which are hard to obtain for challenging language agent tasks. To address this, we present Reflection-Reinforced Self-Training (Re-ReST), which uses a \textit{reflector} to refine low-quality generated samples during self-training. The reflector takes the agent's output and feedback from an external environment (e.g., unit test results in code generation) to produce improved samples. This technique enhances the quality of inferior samples and efficiently enriches the self-training dataset with higher-quality samples. We conduct extensive experiments on open-source language agents across tasks, including multi-hop question answering, sequential decision-making, code generation, visual question answering, and text-to-image generation. The results demonstrate the effectiveness of self-training and Re-ReST in language agent tasks, with self-training improving baselines by 7.6\% on HotpotQA and 28.4\% on AlfWorld, and Re-ReST further boosting performance by 2.0\% and 14.1\%, respectively. Our studies also confirm the efficiency of using a reflector to generate high-quality samples for self-training. Moreover, we demonstrate a method to employ reflection during inference without ground-truth feedback, addressing the limitation of previous reflection work. },
 code_url={https://github.com/PlusLabNLP/Re-ReST}
}

@inproceedings{gu2024model,
  title = {Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue},
  author = {Gu, Jia-Chen and Xu, Hao-Xiang and Ma, Jun-Yu and Lu, Pan and Ling, Zhen-Hua and Chang, Kai-Wei and Peng, Nanyun},
  booktitle = {EMNLP},
  rank = 18,
  paper_url={https://arxiv.org/abs/2401.04700},
  abstract={Model editing is a technique that edits the large language models (LLMs) with updated knowledge to alleviate hallucinations without resource-intensive retraining. While current model editing methods can effectively modify a model's behavior within a specific area of interest, they often overlook the potential unintended side effects on the general abilities of LLMs such as reasoning, natural language inference, and question answering. In this paper, we raise concerns that model editing's improvements on factuality may come at the cost of a significant degradation of the model's general abilities. We systematically analyze the side effects by evaluating four popular editing methods on three LLMs across eight representative tasks. Our extensive empirical experiments show that it is challenging for current editing methods to simultaneously improve factuality of LLMs and maintain their general abilities. Our analysis reveals that the side effects are caused by model editing altering the original model weights excessively, leading to overfitting to the edited facts. To mitigate this, a method named RECT (RElative Change in weighT) is proposed to regularize the edit update weights. Evaluation results show that RECT can significantly mitigate the side effects of editing while still maintaining over 94% editing performance.},
  year = {2024}
}

@inproceedings{wu2024vdebugger,
  title = {VDebugger: Harnessing Execution Feedback for Debugging Visual Programs},
  author = {Wu, Xueqing and Lin, Zongyu and Zhao, Songyan and Wu, Te-Lin and Lu, Pan and Peng, Nanyun and Chang, Kai-Wei},
  booktitle = {EMNLP-Finding},
  rank = 19,
  paper_url={https://arxiv.org/abs/2406.13444},
  abstract={Visual programs are executable code generated by large language models to address visual reasoning problems. They decompose complex questions into multiple reasoning steps and invoke specialized models for each step to solve the problems. However, these programs are prone to logic errors, with our preliminary evaluation showing that 58% of the total errors are caused by program logic errors. Debugging complex visual programs remains a major bottleneck for visual reasoning. To address this, we introduce VDebugger, a novel critic-refiner framework trained to localize and debug visual programs by tracking execution step by step. VDebugger identifies and corrects program errors leveraging detailed execution feedback, improving interpretability and accuracy. The training data is generated through an automated pipeline that injects errors into correct visual programs using a novel mask-best decoding technique. Evaluations on six datasets demonstrate VDebugger's effectiveness, showing performance improvements of up to 3.2% in downstream task accuracy. Further studies show VDebugger's ability to generalize to unseen tasks, bringing a notable improvement of 2.3% on the unseen COVR task.},
  code_url={https://github.com/shirley-wu/vdebugger/},
  year = {2024}
}

@inproceedings{meng2024attribute,
  title = {Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification},
  author = {Meng, Tao and Mehrabi, Ninareh and Goyal, Palash and Ramakrishna, Anil and Galstyan, Aram and Zemel, Richard and Chang, Kai-Wei and Gupta, Rahul and Peris, Charith},
  booktitle = {EMNLP-Finding},
  paper_url = {https://arxiv.org/abs/2410.05559},
  abstract = {We propose a constraint learning schema for fine-tuning Large Language Models (LLMs) with attribute control. Given a training corpus and control criteria formulated as a sequence-level constraint on model outputs, our method fine-tunes the LLM on the training corpus while enhancing constraint satisfaction with minimal impact on its utility and generation quality. Specifically, our approach regularizes the LLM training by penalizing the KL divergence between the desired output distribution, which satisfies the constraints, and the LLM's posterior. This regularization term can be approximated by an auxiliary model trained to decompose the sequence-level constraints into token-level guidance, allowing the term to be measured by a closed-form formulation. To further improve efficiency, we design a parallel scheme for concurrently updating both the LLM and the auxiliary model. We evaluate the empirical performance of our approach by controlling the toxicity when training an LLM. We show that our approach leads to an LLM that produces fewer inappropriate responses while achieving competitive performance on benchmarks and a toxicity detection task.},
  rank = 19,
  year = {2024}
}



@inproceedings{zhang2024mathverse,
title={MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?},
author={Renrui Zhang and Dongzhi Jiang and Yichi Zhang and Haokun Lin and Pengshuo Qiu and Ziyu Guo and Aojun Zhou and Pan Lu and Md. Rizwan Parvez and Peng Gao and Hongsheng Li},
booktitle={ECCV},
rank=20,
paper_url={https://arxiv.org/abs/2403.14624},
year = {2024},
abstract={The remarkable progress of Multi-modal Large Language Models (MLLMs) has garnered unparalleled attention, due to their superior performance in visual contexts. However, their capabilities in visual math problem-solving remain insufficiently evaluated and understood. We investigate current benchmarks to incorporate excessive visual content within textual questions, which potentially assist MLLMs in deducing answers without truly interpreting the input diagrams. To this end, we introduce MathVerse, an all-around visual math benchmark designed for an equitable and in-depth evaluation of MLLMs. We meticulously collect 2,612 high-quality, multi-subject math problems with diagrams from publicly available sources. Each problem is then transformed by human annotators into six distinct versions, each offering varying degrees of information content in multi-modality, contributing to 15K test samples in total. This approach allows MathVerse to comprehensively assess whether and how much MLLMs can truly understand the visual diagrams for mathematical reasoning. In addition, we propose a Chain-of-Thought (CoT) evaluation strategy for a fine-grained assessment of the output answers. Rather than naively judging true or false, we employ GPT-4(V) to adaptively extract crucial reasoning steps, and then assess each step with error analysis to derive a total score, which can reveal the inner CoT reasoning quality by MLLMs. With MathVerse, we unveil that, most existing MLLMs struggle to understand math diagrams, relying heavily on textual questions. Surprisingly, some of them even achieve 5%+ higher accuracy without the visual input, e.g., Gemini-Pro and SPHINX-MoE. In contrast, GPT-4V and InternLM-XComposer2 demonstrate relatively better comprehension of the visual content for mathematical reasoning. We hope the MathVerse benchmark may provide unique insights to guide the future development of MLLMs.},
code_url={https://github.com/ZrrSkywalker/MathVerse}
}

@inproceedings{kamath2024hard,
title={The Hard Positive Truth about Vision-Language Compositionality},
author={Amita Kamath and Cheng-Yu Hsieh and Md. Rizwan Parvez and Ranjay Krishna},
booktitle={ECCV},
paper_url={https://amitakamath.github.io/oversensitivity.pdf},
rank=20,
year=2024,
abstract={Several benchmarks have concluded that our best vision-language models (e.g., CLIP) are lacking in compositionality. Given an image, these benchmarks probe a model's ability to identify its associated caption amongst a set of compositional distractors. In response, a surge of recent proposals show improvements by finetuning CLIP with distractors as hard negatives. Our investigations reveal that these improvements have been overstated --- because existing benchmarks do not probe whether finetuned models remain invariant to hard positives. By curating an evaluation dataset with 112,382 both hard negatives and hard positives, we uncover that including hard positives decreases CLIP's performance by 12.9%, while humans perform effortlessly at 99%. CLIP finetuned with hard negatives results in an even larger decrease, up to 38.7%. With this finding, we then produce a 1,775,259 training set with both hard negatives and hard positives captions. By training with both, we see improvements on existing benchmarks while simultaneously improving performance on hard positives, indicating an improvement in compositionality. Our work suggests the need for future research to rigorously test and improve CLIP's understanding of semantic relationships between related ``positive'' concepts.}
}



@inproceedings{wu2024kpeval,
  title = {KPEval: Towards Fine-Grained Semantic-Based Keyphrase Evaluation},
  author = {Wu, Di and Yin, Da and Chang, Kai-Wei},
  booktitle = {ACL-Findings},
  paper_url={KPEval: Towards Fine-Grained Semantic-Based Keyphrase Evaluation},
  rank = 22,
  abstract={Despite the significant advancements in keyphrase extraction and keyphrase generation methods, the predominant approach for evaluation mainly relies on exact matching with human references. This scheme fails to recognize systems that generate keyphrases semantically equivalent to the references or diverse keyphrases that carry practical utility. To better assess the capability of keyphrase systems, we propose KPEval, a comprehensive evaluation framework consisting of four critical aspects: reference agreement, faithfulness, diversity, and utility. For each aspect, we design semantic-based metrics to reflect the evaluation objectives. Meta-evaluation studies demonstrate that our evaluation strategy correlates better with human preferences compared to a range of previously proposed metrics. Using KPEval, we re-evaluate 21 keyphrase systems and discover that (1) established model comparison results have blind-spots especially when considering reference-free evaluation; (2) large language models are underestimated by prior evaluation works; and (3) there is no single best model that can excel in all the aspects.},
  code_url={https://github.com/uclanlp/KPEval},
  year = {2024}
}

@inproceedings{liu2024are,
  title = {Are LLMs Capable of Data-based Statistical and Causal Reasoning? Benchmarking Advanced Quantitative Reasoning with Data},
  author = {Liu, Xiao and Wu, Zirui and Wu, Xueqing and Lu, Pan and Chang, Kai-Wei and Feng, Yansong},
  booktitle = {ACL-Findings},
  paper_url={https://arxiv.org/abs/2402.17644},
  rank = 22,
  abstract={Quantitative reasoning is a critical skill to analyze data, yet the assessment of such ability remains limited. To address this gap, we introduce the Quantitative Reasoning with Data (QRData) benchmark, aiming to evaluate Large Language Models' capability in statistical and causal reasoning with real-world data. The benchmark comprises a carefully constructed dataset of 411 questions accompanied by data sheets from textbooks, online learning materials, and academic papers. To compare models' quantitative reasoning abilities on data and text, we enrich the benchmark with an auxiliary set of 290 text-only questions, namely QRText. We evaluate natural language reasoning, program-based reasoning, and agent reasoning methods including Chain-of-Thought, Program-of-Thoughts, ReAct, and code interpreter assistants on diverse models. The strongest model GPT-4 achieves an accuracy of 58%, which has a large room for improvement. Among open-source models, Deepseek-coder-instruct, a code LLM pretrained on 2T tokens, gets the highest accuracy of 37%. Analysis reveals that models encounter difficulties in data analysis and causal reasoning, and struggle in using causal knowledge and provided data simultaneously.},
  code_url={https://github.com/xxxiaol/QRData},
  year = {2024}
}

@inproceedings{markowitz2024tree,
  title = {Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs},
  author = {Markowitz, Elan Sopher and Ramakrishna, Anil and Dhamala, Jwala and Mehrabi, Ninareh and Peris, Charith and Gupta, Rahul and Chang, Kai-Wei and Galstyan, Aram},
  booktitle = {ACL},
  paper_url = {https://arxiv.org/abs/2407.21358},
  rank = 21,
  year = {2024}
}

@inproceedings{yin2024agent,
  title = {Agent Lumos: Unified and Modular Training for Open-Source Language Agents},
  author = {Yin, Da and Brahman, Faeze and Ravichander, Abhilasha and Chandu, Khyathi and Chang, Kai-Wei and Choi, Yejin and Lin, Bill Yuchen},
  booktitle = {ACL},
  paper_url={https://arxiv.org/abs/2311.05657},
  rank = 21,
  abstrct={Closed-source agents suffer from several issues such as a lack of affordability, transparency, and reproducibility, particularly on complex interactive tasks. This motivates the development of open-source alternatives. We introduce LUMOS, one of the first frameworks for training open-source LLM-based agents. LUMOS features a learnable, unified, and modular architecture with a planning module that learns high-level subgoal generation, and a grounding module trained to translate these into actions using various tools in the execution module. The design allows for modular upgrades and wider applicability to diverse interactive tasks. To foster generalizable agent learning, we collect large-scale, unified, and high-quality training annotations derived from diverse ground-truth reasoning rationales across various complex interactive tasks. On 9 datasets, LUMOS exhibits several key advantages: (1) LUMOS excels multiple larger open-source agents on the held-out datasets (unused for training) for each task type. LUMOS even surpasses GPT agents on QA and web tasks; (2) LUMOS outperforms open-source agents produced by chain-of-thoughts and unmodularized integrated training; and (3) LUMOS effectively generalizes to unseen tasks, outperforming 33B-scale agents and domain-specific agents.},
  year = {2024}
}

@inproceedings{huang2024textee,
  title = {TextEE: Benchmark, Reevaluation, Reflections, and Future Challenges in Event Extraction},
  author = {Huang, Kuan-Hao and Hsu, I-Hung and Parekh, Tanmay and Xie, Zhiyu and Zhang, Zixuan and Natarajan, Prem and Chang, Kai-Wei and Peng, Nanyun and Ji, Heng},
  booktitle = {ACL-Findings},
  year = {2024},
  paper_url={https://arxiv.org/abs/2311.09562},
  abstrct={Event extraction has gained considerable interest due to its wide-ranging applications. However, recent studies draw attention to evaluation issues, suggesting that reported scores may not accurately reflect the true performance. In this work, we identify and address evaluation challenges, including inconsistency due to varying data assumptions or preprocessing steps, the insufficiency of current evaluation frameworks that may introduce dataset or data split bias, and the low reproducibility of some previous approaches. To address these challenges, we present TextEE, a standardized, fair, and reproducible benchmark for event extraction. TextEE comprises standardized data preprocessing scripts and splits for 14 datasets spanning seven diverse domains and includes 14 recent methodologies, conducting a comprehensive benchmark reevaluation. We also evaluate five varied large language models on our TextEE benchmark and demonstrate how they struggle to achieve satisfactory performance. Inspired by our reevaluation results and findings, we discuss the role of event extraction in the current NLP era, as well as future challenges and insights derived from TextEE. We believe TextEE, the first standardized comprehensive benchmarking tool, will significantly facilitate future event extraction research.},
  rank = 22
}


@inproceedings{yin2024charactering,
title={Characterizing Truthfulness in Large Language Model Generations with Local Intrinsic Dimension},
author={Fan Yin and Jayanth Srinivasa and Md. Rizwan Parvez},
booktitle={ICML},
rank = 23,
year=2024,
paper_url={https://arxiv.org/abs/2402.18048}
}

@inproceedings{zheng2024prompt,
title={Prompt-Driven LLM Safeguarding via Directed Representation Optimization},
author={Chujie Zheng and  Fan Yin and  Hao Zhou and  Fandong Meng and  Jie Zhou and  Md. Rizwan Parvez and  Minlie Huang and  Nanyun Peng},
rank=24, 
year=2024, 
booktitle={ICML},
paper_url={https://arxiv.org/abs/2401.18018}
}

@inproceedings{huang2024position, 
title={TrustLLM: Trustworthiness in Large Language Models}, 
author={Yue Huang and  Lichao Sun and  Haoran Wang and  Siyuan Wu and  Qihui Zhang and  Yuan Li and  Chujie Gao and  Yixin Huang and  Wenhan Lyu and  Yixuan Zhang and  Xiner Li and  Hanchi Sun and  Zhengliang Liu and  Yixin Liu and  Yijue Wang and  Zhikun Zhang and  Bertie Vidgen and  Bhavya Kailkhura and  Caiming Xiong and  Chaowei Xiao and  Chunyuan Li and  Eric P. Xing and  Furong Huang and  Hao Liu and  Heng Ji and  Hongyi Wang and  Huan Zhang and  Huaxiu Yao and  Manolis Kellis and  Marinka Zitnik and  Meng Jiang and  Mohit Bansal and  James Zou and  Jian Pei and  Jian Liu and  Jianfeng Gao and  Jiawei Han and  Jieyu Zhao and  Jiliang Tang and  Jindong Wang and  Joaquin Vanschoren and  John Mitchell and  Kai Shu and  Kaidi Xu and  Md. Rizwan Parvez and  Lifang He and  Lifu Huang and  Michael Backes and  Neil Zhenqiang Gong and  Philip S. Yu and  Pin-Yu Chen and  Quanquan Gu and  Ran Xu and  Rex Ying and  Shuiwang Ji and  Suman Jana and  Tianlong Chen and  Tianming Liu and  Tianyi Zhou and  William Yang Wang and  Xiang Li and  Xiangliang Zhang and  Xiao Wang and  Xing Xie and  Xun Chen and  Xuyu Wang and  Yan Liu and  Yanfang Ye and  Yinzhi Cao and  Yong Chen and  Yue Zhao},
rank=24,
year=2024,
booktitle={ICML},
paper_url={https://arxiv.org/abs/2401.05561}
}




@inproceedings{ovalle2024are,
    title={Are you talking to ['xem'] or ['x', 'em']? On Tokenization and Addressing Misgendering in LLMs with Pronoun Tokenization Parity},
    author={Anaelia Ovalle and Ninareh Mehrabi and Palash Goyal and Jwala Dhamala and Md. Rizwan Parvez and Richard Zemel and Aram Galstyan and Yuval Pinter and Rahul Gupta},
    booktitle={NAACL-Findings},
    rank=32,
    year=2024,
    paper_url={https://arxiv.org/abs/2312.11779}
}


@inproceedings{ma2024mitigating,
    title={Mitigating Bias for Question Answering Models by Tracking Bias Influence},
    author={Mingyu Derek Ma and Jiun-Yu Kao and Arpit Gupta and Yu-Hsiang Lin and Wenbo Zhao and Tagyoung Chung and Wei Wang and Md. Rizwan Parvez and Nanyun Peng},
    booktitle={NAACL},
    paper_url = {https://arxiv.org/abs/2310.08795},
    rank = 30,
    year=2024
}

@inproceedings{liu2024casa,
    title={CASA: Causality-driven Argument Sufficiency Assessment},
    author={Xiao Liu and Yansong Feng and Md. Rizwan Parvez},
    booktitle={NAACL},
    rank = 30,
    paper_url={https://arxiv.org/abs/2401.05249},
    year=2024
}

@inproceedings{parekh2024contextual,
    title={Contextual Label Projection for Cross-Lingual Structured Prediction},
    author={Tanmay Parekh and I-Hung Hsu and Kuan-Hao Huang and Md. Rizwan Parvez and Nanyun Peng},
    booktitle={NAACL},
    rank = 30,
    paper_url={https://arxiv.org/abs/2309.08943},
    year=2024
}
@inproceedings{parekh2024event,
    title={Event Detection from Social Media for Epidemic Prediction},
    author={Tanmay Parekh and Anh Mac and Jiarui Yu and Yuxuan Dong and Syed Shahriar and Bonnie Liu and Eric J Yang and Kuan-Hao Huang and Wei Wang and Nanyun Peng and Md. Rizwan Parvez},
    booktitle={NAACL},
    paper_url={https://arxiv.org/abs/2404.01679},
    rank = 30,
    year=2024
}

@inproceedings{wu2024leveraging,
booktitle={LREC-COLING},
rank = 32,
year = 2024, 
title = {On Leveraging Encoder-only Pre-trained Language Models for Effective Keyphrase Generation},
author = {Di Wu and Wasi Uddin Ahmad and Md. Rizwan Parvez}, 
abstract= {This study addresses the application of encoder-only Pre-trained Language Models (PLMs) in keyphrase generation (KPG) amidst the broader availability of domain-tailored encoder-only models compared to encoder-decoder models. We investigate three core inquiries: (1) the efficacy of encoder-only PLMs in KPG, (2) optimal architectural decisions for employing encoder-only PLMs in KPG, and (3) a performance comparison between in-domain encoder-only and encoder-decoder PLMs across varied resource settings. Our findings, derived from extensive experimentation in two domains reveal that with encoder-only PLMs, although KPE with Conditional Random Fields slightly excels in identifying present keyphrases, the KPG formulation renders a broader spectrum of keyphrase predictions. Additionally, prefix-LM fine-tuning of encoder-only PLMs emerges as a strong and data-efficient strategy for KPG, outperforming general-domain seq2seq PLMs. We also identify a favorable parameter allocation towards model depth rather than width when employing encoder-decoder architectures initialized with encoder-only PLMs. The study sheds light on the potential of utilizing encoder-only PLMs for advancing KPG systems and provides a groundwork for future KPG methods. },
code_url={https://github.com/uclanlp/DeepKPG},
paper_url={https://arxiv.org/abs/2402.14052}
}



@inproceedings{lee2024small,
    title={Can small language models help large language models reason better?: LM-guided chain-of-thought},
    author={Jooyoung Lee and Fan Yang and Thanh Tran and Qian Hu and Emre Barut and Md. Rizwan Parvez and Chengwei Su},
    paper_url={https://www.amazon.science/publications/can-small-language-models-help-large-language-models-reason-better-lm-guided-chain-of-thought},
    rank = 32,
    year = 2024,
    booktitle={LREC-COLING},
    abstract={We introduce a novel framework, LM-Guided CoT, that leverages a lightweight (i.e., <1B) LM for guiding a black-box large (i.e., >10B) LM in reasoning tasks. Specifically, the lightweight LM first generates a rationale for each input instance. The Frozen large LM is then prompted to predict a task output based on the rationale generated by the lightweight LM. Our approach is resource-efficient in the sense that it only requires training the lightweight LM. We optimize the model through 1) knowledge distillation and 2) reinforcement learning from rationale-oriented and task-oriented reward signals. We assess our method with multi-hop extractive question answering (QA) benchmarks, HotpotQA and 2WikiMultiHopQA. Experimental results show that our approach outperforms all baselines regarding answer prediction accuracy. We also find that reinforcement learning helps the model to produce higher-quality rationales with improved QA performance.}
}
@inproceedings{wang2024deepedit,
  title={DeepEdit: Knowledge Editing as Decoding with Constraints},
paper_url={https://arxiv.org/pdf/2401.10471v1.pdf},
  author={Wang, Yiwei and Chen, Muhao and Peng, Nanyun and Chang, Kai-Wei},
  pub_type=pre-print,
  year={2024},
  abstract={We develop a new perspective of knowledge editing for large language models (LLMs) as decoding with constraints. We propose DeepEdit (Depth-first Search based Progressive Decoding for Knowledge Editing), a neuro-symbolic method that improves knowledge editing with better coherence of reasoning, relevance to the question, and awareness of updated knowledge. DeepEdit can be flexibly applied to all black-box LLMs: it does not require any access to the model parameters, representations, or output vocabulary distributions. DeepEdit progressively produces the high-quality reasoning steps towards effective knowledge editing. It utilizes a depth-first search to revise the LLMs' output, which improves the output's informativeness to the input question and awareness of the updated knowledge. Qualitatively, DeepEdit effectively controls LLMs to produce more succinct reasoning in accord with knowledge editing. Quantitatively, DeepEdit yields significant gains on MQuaKE, a challenging multi-hop question-answering dataset with knowledge editing. We release the source code at https://github.com/wangywUST/DeepEdit.}
}

@inproceedings{bansal2023videocon,
author={Hritik Bansal and Yonatan Bitton and Idan Szpektor and Md. Rizwan Parvez and Aditya Grover},
title={VideoCon: Robust video-language alignment via contrast captions},
booktitle={CVPR},
keyword={robustness},
keynote={Best paper at DPFM workshop at ICLR},
year={2024},
rank = 35,
selected=true,
paper_url={https://arxiv.org/abs/2311.10111},
abstract={Despite being (pre)trained on a massive amount of data, state-of-the-art video-language alignment models are not robust to semantically-plausible contrastive changes in the video captions. Our work addresses this by identifying a broad spectrum of contrast misalignments, such as replacing entities, actions, and flipping event order, which alignment models should be robust against. To this end, we introduce the VideoCon, a video-language alignment dataset constructed by a large language model that generates plausible contrast video captions and explanations for differences between original and contrast video captions. Then, a generative video-language model is finetuned with VideoCon to assess video-language entailment and generate explanations. Our VideoCon-based alignment model significantly outperforms current models. It exhibits a 12-point increase in AUC for the video-language alignment task on human-generated contrast captions. Finally, our model sets new state of the art zero-shot performance in temporally-extensive video-language tasks such as text-to-video retrieval (SSv2-Temporal) and video question answering (ATP-Hard). Moreover, our model shows superior performance on novel videos and human-crafted captions and explanations.},
tweet={https://twitter.com/hbXNov/status/1726670647903072625},
code_url={https://github.com/Hritikbansal/videocon},
demo_url={https://huggingface.co/spaces/hbXNov/owl-con-demo},
}

@inproceedings{wadhawan2024contextual,
author={Rohan Wadhawan and Hritik Bansal and Md. Rizwan Parvez and Nanyun Peng},
title={ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models},
keyword={lmm_eval},
booktitle={ICML},
rank=24,
year={2024},
paper_url={https://arxiv.org/abs/2401.13311},
abstract={Recent advancements in AI have led to the development of large multimodal models (LMMs) capable of processing complex tasks involving joint reasoning over text and visual content in the image (e.g., navigating maps in public places). This paper introduces ConTextual, a novel benchmark comprising instructions designed explicitly to evaluate LMMs' ability to perform context-sensitive text-rich visual reasoning. ConTextual emphasizes diverse real-world scenarios (e.g., time-reading, navigation, shopping and more) demanding a deeper understanding of the interactions between textual and visual elements. Our findings reveal a significant performance gap of 30.8% between the best-performing LMM, GPT-4V(ision), and human capabilities using human evaluation indicating substantial room for improvement in context-sensitive text-rich visual reasoning. Notably, while GPT-4V excelled in abstract categories like meme and quote interpretation, its overall performance still lagged behind humans. In addition to human evaluations, we also employed automatic evaluation metrics using GPT-4, uncovering similar trends in performance disparities. We also perform a fine-grained evaluation across diverse visual contexts and provide qualitative analysis which provides a robust framework for future advancements in the LMM design.}
}

@inproceedings{lu2024mathvista,
  title={MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts},
  author={Lu, Pan and Bansal, Hritik and Xia, Tony and Liu, Jiacheng and Li, Chunyuan and Hajishirzi, Hannaneh and Cheng, Hao and Chang, Kai-Wei and Galley, Michel and Gao, Jianfeng},
  booktitle={ICLR},
rank= 36,
  year={2024},
tweet={https://twitter.com/lupantech/status/1717313355780964608},
  code_url={https://mathvista.github.io/},
paper_url= {https://arxiv.org/pdf/2310.02255.pdf},
demo_url={https://mathvista.github.io/#visualization},
  keynote={Oral, 85 out of 7200 submissions, top 1.2%},
  abstract={Although Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit impressive skills in various domains, their ability for mathematical reasoning within visual contexts has not been formally examined. Equipping LLMs and LMMs with this capability is vital for general-purpose AI assistants and showcases promising potential in education, data analysis, and scientific discovery. To bridge this gap, we present MathVista, a benchmark designed to amalgamate challenges from diverse mathematical and visual tasks. We first taxonomize the key task types, reasoning skills, and visual contexts from the literature to guide our selection from 28 existing math-focused and visual question answering datasets. Then, we construct three new datasets, IQTest, FunctionQA, and PaperQA, to accommodate for missing types of visual contexts. The problems featured often require deep visual understanding beyond OCR or image captioning, and compositional reasoning with rich domain-specific tools, thus posing a notable challenge to existing models. We conduct a comprehensive evaluation of 11 prominent open-source and proprietary foundation models (LLMs, LLMs augmented with tools, and LMMs). The best-performing model, Multimodal Bard, achieves only 58% of human performance (34.8% vs 60.3%), indicating ample room for further improvement. Given this significant gap, MathVista fuels future research in the development of general-purpose AI agents capable of tackling mathematically intensive and visually rich real-world tasks.},
}

@inproceedings{chew2024understanding,
title={Understanding and Mitigating Spurious Correlations in Text Classification with Neighborhood Analysis},
author={Oscar Chew and Hsuan-Tien Lin and Md. Rizwan Parvez and Kuan-Hao Huang},
booktitle = {EACL-Findings},
year={2024},
rank=37,
paper_url={https://arxiv.org/abs/2305.13654}
}

@inproceedings{you2024cobit,
  title={CoBIT: A Contrastive Bi-directional Image-Text Generation Model},
  author={You, Haoxuan and Guo, Mandy and Wang, Zhecan and Chang, Kai-Wei and Baldridge, Jason Michael and Yu, Jiahui},
  booktitle={ICLR},
  paper_url={https://arxiv.org/abs/2303.13455},
  year={2024},
rank = 36,
  month={Jan},
  day={16},
  note={Poster presentation},
  abstract={The field of Vision-and-Language (VL) has witnessed a proliferation of pretrained foundation models. Current techniques typically employ only one type of training objective, whether it's (1) contrastive objectives (like CLIP), (2) image-to-text generative objectives (like PaLI), or (3) text-to-image generative objectives (like Parti). However, all these three objectives are mutually relevant and are all based on image-text pairs. Intuitively, the first two objectives can be considered as complementary projections between two modalities, and contrastive learning can preserve global alignment and generations facilitate fine-grained understanding. Inspired by this, we present a Contrastive Bi-directional Image-Text generation model (CoBIT) to first time unify the three pre-training objectives in one framework. Specifically, CoBIT employs a novel unicoder-decoder structure consisting of an image unicoder, a text unicoder, and a cross-modal decoder. The image/text unicoders can switch between encoding and decoding in different tasks, enabling flexibility and shared knowledge that benefits}
}


@inproceedings{li2024steerability,
title={The steerability of large language models toward data-driven personas},
author = {Junyi Li and Ninareh Mehrabi and Charith Peris and Palash Goyal and Md. Rizwan Parvez and Aram Galstyan and Richard Zemel and Rahul Gupta},
abstract = {The recent surge in Large Language Model (LLM) related applications has led to a concurrent escalation in expectations for LLMs to accommodate a myriad of personas and encompass a broad spectrum of perspectives. An important first step towards addressing this demand is to align language models with specific personas, be it groups of users or individuals. Towards this goal, we first present a new conceptualization of a ¡¥persona¡¦. Moving beyond the traditional reliance on demographics like age, gender, or political party affiliation, we introduce a data-driven persona definition methodology built on collaborative-filtering. In this methodology, users are embedded into a continuous vector space based on their opinions and clustered into cohorts that manifest coherent views across specific inquiries. This methodology allows for a more nuanced understanding of different latent social groups present in the overall population (as opposed to simply using demographic groups) and enhances the applicability of model steerability. Finally, we present an efficient method to steer LLMs towards a particular persona. We learn a soft-prompting model to map the continuous representation of users into sequences of virtual tokens which, when prepended to the LLM input, enables the LLM to produce responses aligned with a given user. Our results show that our steerability algorithm is superior in performance compared to a collection of baselines.}, 
paper_url = https://arxiv.org/pdf/2311.04978.pdf,
booktitle = {NAACL},
rank = 30,
year = {2024}
}

@inproceedings{chien2024aiassisted,
title={AI-Assisted Summarization of Radiologic Reports: Evaluating GPT3davinci, BARTcnn, LongT5booksum, LEDbooksum, LEDlegal, and LEDclinical},
author={Aichi Chien and  Hubert Tang and  Bhavita Jagessar and  Kai-wei Chang and  Nanyun Peng and  Kambiz Nael and  Noriko Salamon},
year = {2024},
rank =35,
booktitle={American Journal of Neuroradiology},
paper_url={https://pubmed.ncbi.nlm.nih.gov/38238092/} 
}


@inproceedings{ahmed2023neuro,
title={	A Pseudo-Semantic Loss for Deep Generative Models with Logical Constraints},
author={Kareem Ahmed and Md. Rizwan Parvez and Guy Van den Broeck},	
booktitle={NeurIPS},
paper_url={https://openreview.net/attachment?id=hVAla2O73O&name=pdf},
abstract={Neuro-symbolic approaches bridge the gap between purely symbolic and neural approaches to learning. This often requires maximizing the probability of a symbolic constraint in the neural network's output. However, output distributions are typically assumed to be fully-factorized, which prohibits the application of neurosymbolic learning to more expressive output distributions, such as autoregressive deep generative models. There, such probability computation is #P-hard, even for simple constraints. Instead, we propose to locally approximate the probability of the symbolic constraint under the pseudolikelihood distribution -- the product of its full conditionals given a sample from the model. This allows our pseudo-semantic loss function to enforce the symbolic constraint. Our method bears relationship to several classical approximation schemes, including hogwild Gibbs sampling, consistent pseudolikelihood learning, and contrastive divergence. We test our proposed approach on three distinct settings: Sudoku, shortest-path prediction, and detoxifying large language models. Experiments show that pseudo-semantic loss greatly improves upon the base model's ability to satisfy the desired logical constraint in its output distribution.},
keyword={constraint},
year=2023,
rank=10
}
@inproceedings{hu2023avis,
 author = {Ziniu Hu and  Ahmet Iscen and Chen Sun and Md. Rizwan Parvez and Yizhou Sun and Cordelia Schmid and David A Ross and Alireza Fathi},
 booktitle = {NeurIPS},
title={AVIS: Autonomous Visual Information Seeking with Large Language Models},
 paper_url = {https://arxiv.org/abs/2306.08129},
keyword={reasoning},
 abstract = {In this paper, we propose an autonomous information seeking visual question answering framework, AVIS. Our method leverages a Large Language Model (LLM) to dynamically strategize the utilization of external tools and to investigate their outputs, thereby acquiring the indispensable knowledge needed to provide answers to the posed questions. Responding to visual questions that necessitate external knowledge, such as "What event is commemorated by the building depicted in this image?", is a complex task. This task presents a combinatorial search space that demands a sequence of actions, including invoking APIs, analyzing their responses, and making informed decisions. We conduct a user study to collect a variety of instances of human decision-making when faced with this task. This data is then used to design a system comprised of three components: an LLM-powered planner that dynamically determines which tool to use next, an LLM-powered reasoner that analyzes and extracts key information from the tool outputs, and a working memory component that retains the acquired information throughout the process. The collected user behavior serves as a guide for our system in two key ways. First, we create a transition graph by analyzing the sequence of decisions made by users. This graph delineates distinct states and confines the set of actions available at each state. Second, we use examples of user decision-making to provide our LLM-powered planner and reasoner with relevant contextual instances, enhancing their capacity to make informed decisions. We show that AVIS achieves state-of-the-art results on knowledge-intensive visual question answering benchmarks such as Infoseek and OK-VQA.},
 year=2023,
rank=10
} 


@inproceedings{lu2023chameleon,
  author = {Pan Lu and Baolin Peng and Hao Cheng and Michel Galley and Md. Rizwan Parvez and Ying Nian Wu and Song-Chun Zhu and Jianfeng Gao},
  title = {Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models},
  booktitle = {NeurIPS},
selected=true,
keyword={reasoning},
  paper_url = {https://arxiv.org/abs/2304.09842},
  abstract = {Large language models (LLMs) have achieved remarkable progress in solving various natural language processing tasks due to emergent reasoning abilities. However, LLMs have inherent limitations as they are incapable of accessing up-to-date information (stored on the Web or in task-specific knowledge bases), using external tools, and performing precise mathematical and logical reasoning. In this paper, we present Chameleon, an AI system that mitigates these limitations by augmenting LLMs with plug-and-play modules for compositional reasoning. Chameleon synthesizes programs by composing various tools (e.g., LLMs, off-the-shelf vision models, web search engines, Python functions, and heuristic-based modules) for accomplishing complex reasoning tasks. At the heart of Chameleon is an LLM-based planner that assembles a sequence of tools to execute to generate the final response. We showcase the effectiveness of Chameleon on two multi-modal knowledge-intensive reasoning tasks: ScienceQA and TabMWP. Chameleon, powered by GPT-4, achieves an 86.54% overall accuracy on ScienceQA, improving the best published few-shot result by 11.37%. On TabMWP, GPT-4-powered Chameleon improves the accuracy by 17.0%, lifting the state of the art to 98.78%. Our analysis also shows that the GPT-4-powered planner exhibits more consistent and rational tool selection via inferring potential constraints from instructions, compared to a ChatGPT-powered planner.},
  code_url = {https://chameleon-llm.github.io},	
  year = {2023}, 
rank=10
}

@inproceedings{yin2023dynosaur,
  author = {Da Yin and Xiao Liu and Fan Yin and Ming Zhong and Hritik Bansal and Jiawei Han and Md. Rizwan Parvez},
  title = {Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation},
  booktitle = {EMNLP},
selected=true,
keyword={instruct},
  paper_url = {https://arxiv.org/abs/2305.14327},
  abstract = {Instruction tuning has emerged to enhance the capabilities of large language models (LLMs) in providing appropriate outputs based on input instructions. However, existing methods for collecting instruction-tuning data suffer from limitations in scalability and affordability. In this paper, we propose Dynosaur, a dynamic growth paradigm for instruction-tuning data curation. Built upon the metadata of existing NLP datasets, we generate multiple task instructions applicable to various NLP datasets and determine the relevant data fields for constructing instruction-tuning data with LLMs. Dynosaur offers several advantages: 1) lower generation costs (less than $12 for generating 800K instruction-tuning data), 2) good quality of instruction-tuning data (better performance than Alpaca and Instruction GPT-4 on Super-NI with comparable data sizes), and 3) the ability to grow dynamically by incorporating new datasets from Huggingface Datasets Platform. We further investigate continual learning as an approach to learning with the ever-growing instruction-tuning dataset. We demonstrate that replay methods not only help mitigate forgetting issues but help generalize to unseen tasks better. As a novel continual learning scenario for instruction tuning, selecting tasks based on instruction representations can be an effective replaying strategy. },
code_url={https://dynosaur-it.github.io/},
year = {2023}, 
rank = 15
}

@inproceedings{kamath2023text,
  author = {Amita Kamath and Jack Hessel and Md. Rizwan Parvez},
  title = {Text Encoders are Performance Bottlenecks in Contrastive Vision-Language Models},
  booktitle = {EMNLP},
  paper_url = {https://arxiv.org/abs/2305.14897},
  abstract = {Performant vision-language (VL) models like CLIP represent captions using a single vector. How much information about language is lost in this bottleneck? We first curate CompPrompts, a set of increasingly compositional image captions that VL models should be able to capture (e.g., single object, to object+property, to multiple interacting objects). Then, we train text-only recovery probes that aim to reconstruct captions from single-vector text representations produced by several VL models. This approach doesn't require images, allowing us to test on a broader range of scenes compared to prior work. We find that: 1) CLIP's text encoder falls short on object relationships, attribute-object association, counting, and negations; 2) some text encoders work significantly better than others; and 3) text-only recovery performance predicts multi-modal matching performance on ControlledImCaps: a new evaluation benchmark we collect+release consisting of fine-grained compositional images+captions. Specifically -- our results suggest text-only recoverability is a necessary (but not sufficient) condition for modeling compositional factors in contrastive vision+language models. },	  
  year = {2023}, 
keyword={vlmodel},
  rank=15
}

@inproceedings{shi2023red,
  author = {Zhouxing Shi and Yihan Wang and Fan Yin and Xiangning Chen and Md. Rizwan Parvez and Cho-Jui Hsieh},
  title = {Red Teaming Language Model Detectors with Language Models},
  booktitle = {TACL},
keyword={robustness},
code_url={https://github.com/shizhouxing/LLM-Detector-Robustness/},
  paper_url = {https://arxiv.org/abs/2305.19713},
  abstract = {The prevalence and high capacity of large language models (LLMs) present significant safety and ethical risks when malicious users exploit them for automated content generation. To prevent the potentially deceptive usage of LLMs, recent works have proposed several algorithms to detect machine-generated text. In this paper, we systematically test the reliability of the existing detectors, by designing two types of attack strategies to fool the detectors: 1) replacing words with their synonyms based on the context; 2) altering the writing style of generated text. These strategies are implemented by instructing LLMs to generate synonymous word substitutions or writing directives that modify the style without human involvement, and the LLMs leveraged in the attack can also be protected by detectors. Our research reveals that our attacks effectively compromise the performance of all tested detectors, thereby underscoring the urgent need for the development of more robust machine-generated text detection systems.},
  year = {2023}
}

@inproceedings{li2023desco,
author = {Liunian Harold Li and Zi-Yi Dou and Nanyun Peng and Md. Rizwan Parvez},
title = {DesCo: Learning Object Recognition with Rich Language Descriptions},
booktitle = {NeurIPS},
abstract = {Recent development in vision-language approaches has instigated a paradigm shift in learning visual recognition models from language supervision. These approaches align objects with language queries (e.g. "a photo of a cat") and improve the models' adaptability to identify novel objects and domains. Recently, several studies have attempted to query these models with complex language expressions that include specifications of fine-grained semantic details, such as attributes, shapes, textures, and relations. However, simply incorporating language descriptions as queries does not guarantee accurate interpretation by the models. In fact, our experiments show that GLIP, the state-of-the-art vision-language model for object detection, often disregards contextual information in the language descriptions and instead relies heavily on detecting objects solely by their names. To tackle the challenges, we propose a new description-conditioned (DesCo) paradigm of learning object recognition models with rich language descriptions consisting of two major innovations: 1) we employ a large language model as a commonsense knowledge engine to generate rich language descriptions of objects based on object names and the raw image-text caption; 2) we design context-sensitive queries to improve the model's ability in deciphering intricate nuances embedded within descriptions and enforce the model to focus on context rather than object names alone. On two novel object detection benchmarks, LVIS and OminiLabel, under the zero-shot detection setting, our approach achieves 34.8 APr minival (+9.1) and 29.3 AP (+3.6), respectively, surpassing the prior state-of-the-art models, GLIP and FIBER, by a large margin.},
tweet={https://twitter.com/LiLiunian/status/1676622733944422400},
paper_url = {https://arxiv.org/abs/2306.14060},
selected=true,
demo_url={https://huggingface.co/spaces/zdou0830/desco},
keynote = {<i class="fa fa-trophy"></i> Ranks 1st at the #OmniLabel Challenge of CVPR2023}, 
keyword={vlmodel},
year = {2023}, 
rank=10
}




@inproceedings{ovalle2023factoring,
      title={Factoring the Matrix of Domination: A Critical Review and Reimagination of Intersectionality in AI Fairness}, 
      author={Anaelia Ovalle and Arjun Subramonian and Vagrant Gautam and Gilbert Gee and Md. Rizwan Parvez},
      year={2023},
booktitle={AIES},      
paper_url="https://arxiv.org/abs/2303.17555",
abstract={Intersectionality is a critical framework that, through inquiry and praxis, allows us to examine how social inequalities persist through domains of structure and discipline. Given AI fairness' raison detre of "fairness," we argue that adopting intersectionality as an analytical framework is pivotal to effectively operationalizing fairness. Through a critical review of how intersectionality is discussed in 30 papers from the AI fairness literature, we deductively and inductively: 1) map how intersectionality tenets operate within the AI fairness paradigm and 2) uncover gaps between the conceptualization and operationalization of intersectionality. We find that researchers overwhelmingly reduce intersectionality to optimizing for fairness metrics over demographic subgroups. They also fail to discuss their social context and when mentioning power, they mostly situate it only within the AI pipeline. We: 3) outline and assess the implications of these gaps for critical inquiry and praxis, and 4) provide actionable recommendations for AI fairness researchers to engage with intersectionality in their work by grounding it in AI epistemology},
rank=37
}

@inproceedings{zhang2023on,
title={On the Paradox of Learning to Reason from Data},
author={Honghua Zhang and Liunian Harold Li and Tao Meng and Md. Rizwan Parvez and Guy Van den Broeck.},
booktitle={IJCAI},
keyword={reasoning},
keynote = {Top-10 cited paper at IJCAI 23},
tweet={https://twitter.com/HonghuaZhang2/status/1528963938825580544},
year={2023},
code_url={https://github.com/joshuacnf/paradox-learning2reason},
paper_url={https://arxiv.org/abs/2205.11502},
abstract={Logical reasoning is needed in a wide range of NLP tasks. Can a BERT model be trained end-to-end to solve logical reasoning problems presented in natural language? We attempt to answer this question in a confined problem space where there exists a set of parameters that perfectly simulates logical reasoning. We make observations that seem to contradict each other: BERT attains near-perfect accuracy on in-distribution test examples while failing to generalize to other data distributions over the exact same problem space. Our study provides an explanation for this paradox: instead of learning to emulate the correct reasoning function, BERT has in fact learned statistical features that inherently exist in logical reasoning problems. We also show that it is infeasible to jointly remove statistical features from data, illustrating the difficulty of learning to reason in general. Our result naturally extends to other neural models and unveils the fundamental difference between learning to reason and learning to achieve high performance on NLP benchmarks using statistical features.},
rank=36
}
@inproceedings{li2023symbolic,
  title={Symbolic Chain-of-Thought Distillation: Small Models Can Also "Think" Step-by-Step},
  author={Liunian Harold Li and Jack Hessel and Youngjae Yu and Xiang Ren and Md. Rizwan Parvez and Yejin Choi},
  booktitle={ACL},
keyword={reasoning},
  presentation_time={POSTER SESSION 1, 7/10 11:00AM-12:30AM},
  presentation_id={https://underline.io/events/395/posters/15197/poster/77090-symbolic-chain-of-thought-distillation-small-models-can-also-think-step-by-step?tab=poster},
paper_url={https://arxiv.org/abs/2306.14050},
abstract={Chain-of-thought prompting (e.g., "Let's think step-by-step") primes large language models to verbalize rationalization for their predictions. While chain-of-thought can lead to dramatic performance gains, benefits appear to emerge only for sufficiently large models (beyond 50B parameters). We show that orders-of-magnitude smaller models (125M -- 1.3B parameters) can still benefit from chain-of-thought prompting. To achieve this, we introduce Symbolic Chain-of-Thought Distillation (SCoTD), a method to train a smaller student model on rationalizations sampled from a significantly larger teacher model. Experiments across several commonsense benchmarks show that: 1) SCoTD enhances the performance of the student model in both supervised and few-shot settings, and especially for challenge sets; 2) sampling many reasoning chains per instance from the teacher is paramount; and 3) after distillation, student chain-of-thoughts are judged by humans as comparable to the teacher, despite orders of magnitude fewer parameters. We test several hypotheses regarding what properties of chain-of-thought samples are important, e.g., diversity vs. teacher likelihood vs. open-endedness. We release our corpus of chain-of-thought samples and code.},
  year={2023},
rank=30
}	


@inproceedings{parekh2023geneva,
  title={GENEVA: Pushing the Limit of Generalizability for Event Argument Extraction with 100+ Event Types},
  author={Parekh, Tanmay and Hsu, I-Hung and Huang, Kuan-Hao and Chang, Kai-Wei and Peng, Nanyun},
  booktitle={ACL},
abstract={Recent works in Event Argument Extraction (EAE) have focused on improving model generalizability to cater to new events and domains. However, standard benchmarking datasets like ACE and ERE cover less than 40 event types and 25 entity-centric argument roles. Limited diversity and coverage hinder these datasets from adequately evaluating the generalizability of EAE models. In this paper, we first contribute by creating a large and diverse EAE ontology. This ontology is created by transforming FrameNet, a comprehensive semantic role labeling (SRL) dataset for EAE, by exploiting the similarity between these two tasks. Then, exhaustive human expert annotations are collected to build the ontology, concluding with 115 events and 220 argument roles, with a significant portion of roles not being entities. We utilize this ontology to further introduce GENEVA, a diverse generalizability benchmarking dataset comprising four test suites, aimed at evaluating models' ability to handle limited data and unseen event type generalization. We benchmark six EAE models from various families. The results show that owing to non-entity argument roles, even the best-performing model can only achieve 39% F1 score, indicating how GENEVA provides new challenges for generalization in EAE. Overall, our large and diverse EAE ontology can aid in creating more comprehensive future resources, while GENEVA is a challenging benchmarking dataset encouraging further research for improving generalizability in EAE.},
  presentation_time={POSTER SESSION 6, 7/12 9:00AM-10:30AM},
  presentation_id={https://underline.io/events/395/posters/15264/poster/77026-geneva-benchmarking-generalizability-for-event-argument-extraction-with-hundreds-of-event-types-and-argument-roles},
  code_url={https://github.com/PlusLabNLP/GENEVA/tree/main},
  paper_url={https://arxiv.org/abs/2205.12505},
  year={2023},
keyword={IE},
rank=30
}


@inproceedings{sun2023unifine,
author="Rui Sun and Zhecan Wang and Haoxuan You and Noel Codella and Md. Rizwan Parvez and Shih-Fu Chang",
title="UniFine: A Unified and Fine-grained Approach for Zero-shot Vision-Language Understanding",
booktitle={ACL-Finding},
year={2023},
presentation_id={https://underline.io/events/395/posters/15279/poster/78004-unifine-a-unified-and-fine-grained-approach-for-zero-shot-vision-language-understanding},
presentation_time={VIRTUAL POSTER SESSION 3: July 12 11:00 AM - July 12 12:30 AM},
paper_url={https://arxiv.org/abs/2307.00862},
abstract={Vision-language tasks, such as VQA, SNLI-VE, and VCR are challenging because they require the model's reasoning ability to understand the semantics of the visual world and natural language. Supervised methods working for vision-language tasks have been well-studied. However, solving these tasks in a zero-shot setting is less explored. Since Contrastive Language-Image Pre-training (CLIP) has shown remarkable zero-shot performance on image-text matching, previous works utilized its strong zero-shot ability by converting vision-language tasks into an image-text matching problem, and they mainly consider global-level matching (e.g., the whole image or sentence). However, we find visual and textual fine-grained information, e.g., keywords in the sentence and objects in the image, can be fairly informative for semantics understanding. Inspired by this, we propose a unified framework to take advantage of the fine-grained information for zero-shot vision-language learning, covering multiple tasks such as VQA, SNLI-VE, and VCR. Our experiments show that our framework outperforms former zero-shot methods on VQA and achieves substantial improvement on SNLI-VE and VCR. Furthermore, our ablation studies confirm the effectiveness and generalizability of our proposed method.},
rank=33
}



@inproceedings{hsu2023tagprime,
author="I-Hung Hsu and Kuan-Hao Huang and Shuning Zhang and Wenxin Cheng and Prem Natarajan and Md. Rizwan Parvez and Nanyun Peng",
title="TAGPRIME: A Unified Framework for Relational Structure Extraction",
booktitle={ACL},
  presentation_time={INFORMATION EXTRACTION 1, July 11 16:15 PM}, 
  presentation_id={https://underline.io/events/395/sessions/15250/lecture/76330-tagprime-a-unified-framework-for-relational-structure-extraction},
paper_url="https://arxiv.org/pdf/2205.12585.pdf",
abstract={Many tasks in natural language processing require the extraction of relationship information for a given condition, such as event argument extraction, relation extraction, and task-oriented semantic parsing. Recent works usually propose sophisticated models for each task independently and pay less attention to the commonality of these tasks and to have a unified framework for all the tasks. In this work, we propose to take a unified view of all these tasks and introduce TAGPRIME to address relational structure extraction problems. TAGPRIME is a sequence tagging model that appends priming words about the information of the given condition (such as an event trigger) to the input text. With the self-attention mechanism in pre-trained language models, the priming words make the output contextualized representations contain more information about the given condition, and hence become more suitable for extracting specific relationships for the condition. Extensive experiments and analyses on three different tasks that cover ten datasets across five different languages demonstrate the generality and effectiveness of TAGPRIME.},
year={2023},
rank=30
}

@inproceedings{wan2023pip,
author="Yixin Wan and Kuan-Hao Huang and Md. Rizwan Parvez",
title="PIP: Parse-Instructed Prefix for Syntactically Controlled Paraphrase Generation",
booktitle={ACL-Finding (short)},
  presentation_time={VIRTUAL POSTER SESSION 3: July 12 11:00 AM - July 12 12:30 AM},
  presentation_id={https://underline.io/events/395/posters/15279/poster/77944-pip-parse-instructed-prefix-for-syntactically-controlled-paraphrase-generation},
paper_url={https://arxiv.org/abs/2305.16701},
abstract={Syntactically controlled paraphrase generation requires language models to generate paraphrases for sentences according to specific syntactic structures. Existing fine-tuning methods for this task are costly as all the parameters of the model need to be updated during the training process. Inspired by recent studies on parameter-efficient learning, we propose Parse-Instructed Prefix (PIP), a novel adaptation of prefix-tuning to tune large pre-trained language models on syntactically controlled paraphrase generation task in a low-data setting with significantly less training cost. We introduce two methods to instruct a model's encoder prefix to capture syntax-related knowledge: direct initiation (PIP-Direct) and indirect optimization (PIP-Indirect). In contrast to traditional fine-tuning methods for this task, PIP is a compute-efficient alternative with 10 times less learnable parameters. Compared to existing prefix-tuning methods, PIP excels at capturing syntax control information, achieving significantly higher performance at the same level of learnable parameter count.},
year={2023},
rank=32
}



@inproceedings{monajatipoor2023metavl,
author="Masoud Monajatipoor and Liunian Harold Li and Mozhdeh Rouhsedaghat and Lin Yang and Md. Rizwan Parvez",
title="MetaVL: Transferring In-Context Learning Ability From Language Models to Vision-Language Models",
booktitle={ACL (short)},
presentation_id={https://underline.io/events/395/posters/15337/poster/76709-metavl-transferring-in-context-learning-ability-from-language-models-to-vision-language-models},
presentation_time={POSTER SESSION 2: July 10 14:00 AM - July 10 15:30 PM},
paper_url={https://arxiv.org/abs/2306.01311},
abstract={Large-scale language models have shown the ability to adapt to a new task via conditioning on a few demonstrations (i.e., in-context learning). However, in the vision-language domain, most large-scale pre-trained vision-language (VL) models do not possess the ability to conduct in-context learning. How can we enable in-context learning for VL models? In this paper, we study an interesting hypothesis: can we transfer the in-context learning ability from the language domain to VL domain? Specifically, we first meta-trains a language model to perform in-context learning on NLP tasks (as in MetaICL); then we transfer this model to perform VL tasks by attaching a visual encoder. Our experiments suggest that indeed in-context learning ability can be transferred cross modalities: our model considerably improves the in-context learning capability on VL tasks and can even compensate for the size of the model significantly. On VQA, OK-VQA, and GQA, our method could outperform the baseline model while having 20 times fewer parameters.},
year={2023},
rank=31
}

@inproceedings{chi2023plue,
author="Jianfeng Chi and Wasi Uddin Ahmad and Yuan Tian and Md. Rizwan Parvez",
title="PLUE: Language Understanding Evaluation Benchmark for Privacy Policies in English",
presentation_id={https://underline.io/events/395/posters/15279/poster/76751-plue-language-understanding-evaluation-benchmark-for-privacy-policies-in-english},
presentation_time={VIRTUAL POSTER SESSION 3: July 12 11:00 AM - July 12 09:30 AM}, 
booktitle={ACL (short)},
abstract={Privacy policies provide individuals with information about their rights and how their personal information is handled. Natural language understanding (NLU) technologies can support individuals and practitioners to understand better privacy practices described in lengthy and complex documents. However, existing efforts that use NLU technologies are limited by processing the language in a way exclusive to a single task focusing on certain privacy practices. To this end, we introduce the Privacy Policy Language Understanding Evaluation (PLUE) benchmark, a multi-task benchmark for evaluating the privacy policy language understanding across various tasks. We also collect a large corpus of privacy policies to enable privacy policy domain-specific language model pre-training. We evaluate several generic pre-trained language models and continue pre-training them on the collected corpus. We demonstrate that domain-specific continual pre-training offers performance improvements across all tasks.},
paper_url="https://arxiv.org/abs/2212.10011",
year={2023},
rank=31
}

@inproceedings{roashan2023tail,
author= "Nikil Roashan Selvam and Sunipa Dev and Daniel Khashabi and Tushar Khot and Md. Rizwan Parvez",
title="The Tail Wagging the Dog: Dataset Construction Biases of Social Bias Benchmarks",
presentation_id={https://underline.io/events/395/posters/15337/poster/76963-the-tail-wagging-the-dog-dataset-construction-biases-of-social-bias-benchmarks},
presentation_time={POSTER SESSION 2: July 10 14:00 AM - July 10 15:30 PM},
booktitle={ACL (short)},
paper_url={https://arxiv.org/abs/2210.10040},
year={2023},
keynote = {<i class="fa fa-trophy"></i> Outstanding Paper Award}, 
abstract={How reliably can we trust the scores obtained from social bias benchmarks as faithful indicators of problematic social biases in a given language model? In this work, we study this question by contrasting social biases with non-social biases stemming from choices made during dataset construction that might not even be discernible to the human eye. To do so, we empirically simulate various alternative constructions for a given benchmark based on innocuous modifications (such as paraphrasing or random-sampling) that maintain the essence of their social bias. On two well-known social bias benchmarks (Winogender and BiasNLI) we observe that these shallow modifications have a surprising effect on the resulting degree of bias across various models. We hope these troubling observations motivate more robust measures of social biases.},
rank=31
}



@inproceedings{ling2023enhancing,
author={Zixuan Ling and Xiaoqing Zheng and Jianhan Xu and Jinshu Lin and Md. Rizwan Parvez and Cho-Jui Hsieh and Xuanjing Huang},
title="Enhancing Unsupervised Semantic Parsing with Distributed Contextual Representations",
booktitle={ACL-Finding},
presentation_id={https://underline.io/events/395/posters/15279/poster/77281-enhancing-unsupervised-semantic-parsing-with-distributed-contextual-representations?tab=video},
presentation_time={VIRTUAL POSTER SESSION 3: July 12 11:00 AM - July 12 12:30 AM},
abstract={We extend a non-parametric Bayesian model of (Titov and Klementiev, 2011) to deal with homonymy and polysemy by leveraging distributed contextual word and phrase representations pre-trained on a large collection of unlabelled texts. Then, unsupervised semantic parsing is performed by decomposing sentences into fragments, clustering the fragments to abstract away syntactic variations of the same meaning, and predicting predicate-argument relations between the fragments. To better model the statistical dependencies between predicates and their arguments, we further conduct a hierarchical Pitman-Yor process. An improved Metropolis-Hastings merge-split sampler is proposed to speed up the mixing and convergence of Markov chains by leveraging pre-trained distributed representations. The experimental results show that the models achieve better accuracy on both question-answering and relation extraction tasks.},
year={2023},
rank=32
}



@inproceedings{huang2023paraarm,
author={Kuan-Hao Huang and Varun Iyer and I-Hung Hsu and Anoop Kumar and Md. Rizwan Parvez and Aram Galstyan},
title="ParaAMR: A Large-Scale Syntactically Diverse Paraphrase Dataset by AMR Back-Translation",
booktitle={ACL},
  presentation_time={POSTER SESSION 3: July 11 09:00 AM - July 11 10:30 AM},
  presentation_id={https://underline.io/events/395/posters/15227/poster/76600-paraamr-a-large-scale-syntactically-diverse-paraphrase-dataset-by-amr-back-translation},
paper_url={https://arxiv.org/abs/2305.16585},
keynote = {<i class="fa fa-trophy"></i> Area Chair's Award}, 
abstract={Paraphrase generation is a long-standing task in natural language processing (NLP). Supervised paraphrase generation models, which rely on human-annotated paraphrase pairs, are cost-inefficient and hard to scale up. On the other hand, automatically annotated paraphrase pairs (e.g., by machine back-translation), usually suffer from the lack of syntactic diversity -- the generated paraphrase sentences are very similar to the source sentences in terms of syntax. In this work, we present ParaAMR, a large-scale syntactically diverse paraphrase dataset created by abstract meaning representation back-translation. Our quantitative analysis, qualitative examples, and human evaluation demonstrate that the paraphrases of ParaAMR are syntactically more diverse compared to existing large-scale paraphrase datasets while preserving good semantic similarity. In addition, we show that ParaAMR can be used to improve on three NLP tasks: learning sentence embeddings, syntactically controlled paraphrase generation, and data augmentation for few-shot learning. Our results thus showcase the potential of ParaAMR for improving various NLP applications.},
year={2023},
rank= 30
}
@inproceedings{you2023idealgpt,
author={Haoxuan You and  Rui Sun and  Zhecan Wang and  Long Chen and  Gengyu Wang and  Hammad Ayyubi and  Md. Rizwan Parvez and  Shih-Fu Chang },
booktitle = {EMNLP-Finding},
title = "IdealGPT: Iteratively Decomposing Vision and Language Reasoning via Large Language Models",
abstract = {The field of vision-and-language (VL) understanding has made unprecedented progress with end-to-end large pre-trained VL models (VLMs). However, they still fall short in zero-shot reasoning tasks that require multi-step inferencing. To achieve this goal, previous works resort to a divide-and-conquer pipeline. In this paper, we argue that previous efforts have several inherent shortcomings: 1) They rely on domain-specific sub-question decomposing models. 2) They force models to predict the final answer even if the sub-questions or sub-answers provide insufficient information. We address these limitations via IdealGPT, a framework that iteratively decomposes VL reasoning using large language models (LLMs). Specifically, IdealGPT utilizes an LLM to generate sub-questions, a VLM to provide corresponding sub-answers, and another LLM to reason to achieve the final answer. These three modules perform the divide-and-conquer procedure iteratively until the model is confident about the final answer to the main question. We evaluate IdealGPT on multiple challenging VL reasoning tasks under a zero-shot setting. In particular, our IdealGPT outperforms the best existing GPT-4-like models by an absolute 10% on VCR and 15% on SNLI-VE.},
year = 2023,
paper_url={https://arxiv.org/abs/2305.14985},
rank=16
}

@inproceedings{wu2023rethinking,
author = {Di Wu and Wasi Uddin Ahmad and Md. Rizwan Parvez},
title = "Rethinking Model Selection and Decoding for Keyphrase Generation with Pre-trained Sequence-to-Sequence Models",
abstract = "Keyphrase Generation (KPG) is a longstanding task in NLP with broad applications. The advent of pre-trained language models (PLMs) has recently led to a significant improvement in KPG. Nonetheless, several design choices are arbitrary and have not been comprehensively studied. This paper presents a systematic study aimed at benchmarking the impact of model choice and decoding strategies on PLM-based KPG. Specifically, we first reflect on why sequence-to-sequence (seq2seq) PLMs are suitable for KPG via an attention-based hypothesis. Then, we reveal that the conventional wisdom for selecting seq2seq PLMs is incomplete: (1) scaling up model size or task adaptation alone is parameter inefficient; (2) while in-domain pre-training combined with task adaptation significantly benefits KPG, they also compromise generalization to some extent. For decoding, we show that although greedy search achieves strong F1 scores, its recall has large rooms for improvement compared to sampling-based approaches. Based on the findings, we introduce DeSel, a probability-based decode-select algorithm that improves greedy search by an average of 4.7% semantic F1 over five datasets. Together, our results set a solid foundation for future exploration and study of KPG.",
booktitle="EMNLP",
year=2023,
code_url={https://github.com/uclanlp/deepkpg},
paper_url={https://arxiv.org/abs/2310.06374},
rank=15
}

@inproceedings{wan2023personalized,
author="Yixin Wan and  Jieyu Zhao and  Aman Chadha and  Nanyun Peng and  Md. Rizwan Parvez ",
title="Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona Biases in Dialogue Systems",
booktitle="EMNLP-Finding",
keyword={fairnlg},
abstract="Recent advancements in Large Language Models empower them to follow freeform instructions, including imitating generic or specific demographic personas in conversations. Generic personas refer to a demographic group (e.g. an Asian person), whereas specific personas can be actual names of historical figures. While the adoption of personas allows dialogue systems to be more engaging and approachable to users, it also carries the potential risk of exacerbating social biases in model responses, further causing societal harms through interactions with users. In this paper, we systematically study ``persona biases'', which we define to be the sensitivity of harmful dialogue model behaviors to different persona adoptions.We categorize persona biases into biases in harmful expression and harmful agreement, as well as establish a comprehensive evaluation framework to measure persona biases in five aspects: Offensiveness, Toxic Continuation, Regard, Stereotype Agreement, and Toxic Agreement. Additionally, we propose to comprehensively investigate persona biases through experimenting with UniversalPersona, a systematized persona dataset with a comprehensive list of both generic and specific model personas. Through benchmarking on four different models, including Blender, ChatGPT, Alpaca, and Vicuna, our study uncovers significant persona biases in dialogue systems. Findings of our study underscores the immediate need to revisit the use of persona traits in dialogue agents to ensure their safe application.",
year=2023,
paper_url={https://arxiv.org/abs/2310.05280},
rank=16
}

@inproceedings{yang2023lacma,
  title={LACMA: Language-Aligning Contrastive Learning with Meta-Actions for Embodied Instruction Following},
  author={Yang, Cheng-Fu and Chen, Yen-Chun and Yang, Jianwei and Dai, Xiyang and Yuan, Lu and Wang, Yu-Chiang Frank and Chang, Kai-Wei},
  booktitle={EMNLP},
paper_url={https://arxiv.org/abs/2310.12344},
  year={2023},
  abstract={End-to-end Transformers has demonstrated impressive success rate for Embodied Instruction Following when the environment has been seen in the training time. However, they tend to struggle when deploying into a new environment. We discover this lack of generalizability is due to ignorance of the natural language instruction. To mitigate this, we first propose to explicitly align the agent's hidden states to the instructions via contrastive learning. Nevertheless, the semantic gap between high-level language instructions and the agent's low-level action space remains an obstacle. We further bridge this gap via a novel concept of meta-actions. Meta-actions are ubiquitous action patterns that can be parsed from the original action sequence. These patterns represents higher-level semantics that are intuitively more similar to the instructions. When meta-actions are further applied as additional training signals, the agent generalizes even better to unseen environments. Compared to a strong multi-modal Transformer baseline, we achieve a significant 4.5% absolute gain in success rate at the unseen environments of ALFRED Embodied Instruction Following. Additional analysis shows that the contrastive objective and meta-actions are complementary for achieving the best result, and the resulting agent better aligns its states to corresponding instructions, hence is more favorable for real-world embodied agents.},
rank = 15
}

@inproceedings{kung2023active,
  title={Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks},
  author={Kung, Po-Nien and Yin, Fan and Wu, Di and Chang, Kai-Wei and Peng, Nanyun},
  booktitle="EMNLP",
code_url={https://github.com/pluslabnlp/active-it},
  year={2023},
  paper_url={https://arxiv.org/abs/2311.00288},
  abstract={Instruction tuning (IT) achieves impressive zero-shot generalization results by training large language models (LLMs) on a massive amount of diverse tasks with instructions. However, how to select new tasks to improve the performance and generalizability of IT models remains a challenge. Training on all existing tasks is impractical due to prohibiting computation requirements, and randomly selecting tasks can lead to suboptimal performance. In this work, we propose active instruction tuning base on prompt uncertainty, a novel framework to actively identify and train on informative tasks by assessing models' sensitivity against prompts perturbations. Our experiments on NIV2 and Self-Instruct datasets demonstrate that our method consistently outperforms other baseline strategies for task selection, achieving better out-of-distribution generalization with fewer training tasks. Additionally, we introduce a task map that categorizes and diagnoses tasks based on prompt uncertainty and generation perplexity, and discover that training on ambiguous (prompt-uncertain) tasks improves generalization while training on difficult (prompt-certain and low-probability) tasks offers no benefit, underscoring the importance of task selection for instruction tuning.},
 rank = 15
}

@inproceedings{kamath2023whatsup,
  title={"What's 'up' with vision-language models? Investigating their struggle to understand spatial relations."},
  author={Kamath, Amita and Hessel, Jack and Chang, Kai-Wei},
  booktitle={EMNLP},
paper_url={https://arxiv.org/abs/2310.19785},
  year={2023},
keyword={vlmodel},
  abstract={Recent vision-language (VL) models have reached human parity on VQAv2 --- but does that mean they can distinguish "left" from "right"? We curate three new corpora to precisely quantify model ability to comprehend basic spatial relations: COCO-prep from COCO, GQA-prep from GQA, and RealCLEVR from images we capture ourselves with even tighter controls. Compared to prior evaluations which conflate several types of reasoning, our three tests offer precise evaluations of spatial relations, e.g., our RealCLEVR benchmark is controlled, with only the preposition changing between images within a set, e.g. mug on/under/left of/right of a table. This enables us to evaluate model performance on pairs or sets of prepositions. We evaluate 18 VL models, finding that all fall far behind human performance (despite surpassing human performance on VQAv2, as in the case of BLIP2); most only achieve a few points above random chance across all benchmarks. We then study the LAION-2B dataset, which was used to train OpenCLIP models, to investigate if pre-training data can provide clues as to why spatial relation understanding doesn't emerge. We find that prepositions are infrequent and often ambiguous in LAION 2B. Based on this corpus analysis, we investigate a few training strategies to address this shortcoming. While up-weighting preposition-containing instances and fine-tuning on IID data improve accuracy slightly, our three spatial relation benchmarks remain challenging for all VL models we test. We will release code and data.},
rank=15
}
@inproceedings{wang2023datasetbias,
  title={Dataset Bias Mitigation in Multiple-Choice Visual Question Answering and Beyond},
  author={Wang, Zhecan and Chen, Long and You, Haoxuan and Xu, Keyang and Codella, Noel C and Chang, Kai-Wei and Chang, Shih-Fu},
  booktitle={EMNLP-Findings},
paper_url={https://arxiv.org/abs/2310.14670},
  year={2023},
  abstract={Vision-language (VL) understanding tasks evaluate models' comprehension of complex visual scenes through multiple-choice questions. However, we have identified two dataset biases that models can exploit as shortcuts to resolve various VL tasks correctly without proper understanding. The first type of dataset bias is Unbalanced Matching bias, where the correct answer overlaps the question and image more than the incorrect answers. The second type of dataset bias is Distractor Similarity bias, where incorrect answers are overly dissimilar to the correct answer but significantly similar to other incorrect answers within the same sample. To address these dataset biases, we first propose Adversarial Data Synthesis (ADS) to generate synthetic training and debiased evaluation data. We then introduce Intra-sample Counterfactual Training (ICT) to assist models in utilizing the synthesized training data, particularly the counterfactual data, via focusing on intra-sample differentiation. Extensive experiments demonstrate the effectiveness of ADS and ICT in consistently improving model performance across different benchmarks, even in domain-shifted scenarios.},
rank=16
}

@inproceedings{wan2023kelly,
  title={Kelly is a Warm Person, Joseph is a Role Model: Gender Biases in LLM-Generated Reference Letters},
  author={Wan, Yixin and Pu, George and Sun, Jiao and Garimella, Aparna and Chang, Kai-Wei and Peng, Nanyun},
  booktitle={EMNLP-Findings},
keyword={fairnlg},
  year={2023},
selected=true,
paper_url={https://arxiv.org/pdf/2310.09219},
  abstract={As generative language models advance, users have started to utilize Large Language Models (LLMs) to assist in writing various types of content, including professional documents such as recommendation letters. Despite their convenience, these applications introduce unprecedented fairness concerns. As generated reference letter might be directly utilized by users in professional or academic scenarios, it has the potential to cause direct harm such as lowering success rates for female applicants. Therefore, it is imminent and necessary to comprehensively study fairness issues and associated harms in such real-world use cases for future mitigation and monitoring. In this paper, we critically examine gender bias in LLM-generated reference letters. Inspired by findings in social science, we specifically design evaluation methods to manifest gender biases in LLM-generated letters through two dimensions: biases in language style and biases in lexical content. Furthermore, we investigate the extent of bias propagation by separately analyze bias amplification in model-hallucinated contents, which we define to be hallucination bias of model-generated documents. Through benchmarking evaluation on 4 popular LLMs, including ChatGPT, Alpaca, Vicuna and StableLM, our study reveal significant gender biases in LLM-generated recommendation letters. Our findings further point towards the importance and imminence to recognize bias in LLM-generated professional documents.},
rank=16
}

@inproceedings{mehrabi2023resolving, 
author = {Ninareh Mehrabi and Palash Goyal and Apurv Verma and Jwala Dhamala and Varun Kumar and Qian Hu and Md. Rizwan Parvez and Richard Zemel and Aram Galstyan and Rahul Gupta},
booktitle={ACL},
title={Resolving Ambiguities in Text-to-Image Generative Models},
  presentation_time={POSTER SESSION 4:July 11 11:00 AM - July 11 12:30 AM},
  presentation_id={https://underline.io/events/395/posters/15237/poster/76575-resolving-ambiguities-in-text-to-image-generative-models},
year = {2023},
paper_url="https://arxiv.org/abs/2211.12503",
abstract={Natural language often contains ambiguities that can lead to misinterpretation and miscommunication. While humans can handle ambiguities effectively by asking clarifying questions and/or relying on contextual cues and common-sense knowledge, resolving ambiguities can be notoriously hard for machines. In this work, we study ambiguities that arise in text-to-image generative models. We curate a benchmark dataset covering different types of ambiguities that occur in these systems. We then propose a framework to mitigate ambiguities in the prompts given to the systems by soliciting clarifications from the user. Through automatic and human evaluations, we show the effectiveness of our framework in generating more faithful images aligned with human intention in the presence of ambiguities.},
rank=30
}


@inproceedings{lu2023survey,
author = {Pan Lu and Liang Qiu and Wenhao Yu and Sean Welleck and Md. Rizwan Parvez}, 
title={A Survey of Deep Learning for Mathematical Reasoning},
booktitle = {ACL},
keyword={reasoning},
year = {2023},
  presentation_time={POSTER SESSION 2: July 10 14:00 AM - July 10 15:30 PM},
  presentation_id={https://underline.io/events/395/posters/15337/poster/76360-a-survey-of-deep-learning-for-mathematical-reasoning},
paper_url = "https://arxiv.org/abs/2212.10535",
abstract = "Mathematical reasoning is a fundamental aspect of human intelligence and is applicable in various fields, including science, engineering, finance, and everyday life. The development of artificial intelligence (AI) systems capable of solving math problems and proving theorems has garnered significant interest in the fields of machine learning and natural language processing. For example, mathematics serves as a testbed for aspects of reasoning that are challenging for powerful deep learning models, driving new algorithmic and modeling advances. On the other hand, recent advances in large-scale neural language models have opened up new benchmarks and opportunities to use deep learning for mathematical reasoning. In this survey paper, we review the key tasks, datasets, and methods at the intersection of mathematical reasoning and deep learning over the past decade. We also evaluate existing benchmarks and methods, and discuss future research directions in this domain.",
rank=30
}

@inproceedings{yang2023efficient,
title={Efficient Shapley Values Estimation by Amortization for Text Classification},
author={Chenghao Yang and Fan Yin and He He and Md. Rizwan Parvez and Xiaofei Ma and Bing Xiang},
year={2023},
presentation_time={Interpretability and Analysis of Models for NLP 2: 7/11 5:45PM},
presentation_id={https://underline.io/events/395/sessions/15249/lecture/76179-efficient-shapley-values-estimation-by-amortization-for-text-classification},
keyword={explaination},
booktitle = {ACL},
abstract= {Despite the popularity of Shapley Values in explaining neural text classification models, computing them is prohibitive for large pretrained models due to a large number of model evaluations as it needs to perform multiple model evaluations over various perturbed text inputs. In practice, Shapley Values are often estimated stochastically with a smaller number of model evaluations. However, we find that the estimated Shapley Values are quite sensitive to random seeds -- the top-ranked features often have little overlap under two different seeds, especially on examples with the longer input text. As a result, a much larger number of model evaluations is needed to reduce the sensitivity to an acceptable level. To mitigate the trade-off between stability and efficiency, we develop an amortized model that directly predicts Shapley Values of each input feature without additional model evaluation. It is trained on a set of examples with Shapley Values estimated from a large number of model evaluations to ensure stability. Experimental results on two text classification datasets demonstrate that, the proposed amortized model can estimate black-box explanation scores in milliseconds per sample in inference time and is up to 60 times more efficient than traditional methods.},
paper_url={https://arxiv.org/abs/2305.19998},
rank=30
}

@inproceedings{ahmed2023semantic,
  author 	= {Ahmed, Kareem and Chang, Kai-Wei and Van den Broeck, Guy},
  title     = {Semantic Strengthening of Neuro-Symbolic Learning},
  booktitle = {AISTATS},
  year      = {2023},
keyword={constraint},
  paper_url       = "http://starai.cs.ucla.edu/papers/AhmedAISTATS23.pdf",
  code_url 		= "https://github.com/UCLA-StarAI/Semantic-Strengthening",
  abstract ={Numerous neuro-symbolic approaches have recently been proposed typically with the goal of adding symbolic knowledge to the output layer of a neural network. Ideally, such losses maximize the probability that the neural network's predictions satisfy the underlying domain. Unfortunately, this type of probabilistic inference is often computationally infeasible. Neuro-symbolic approaches therefore commonly resort to fuzzy approximations of this probabilistic objective, sacrificing sound probabilistic semantics, or to sampling which is very seldom feasible. We approach the problem by first assuming the constraint decomposes conditioned on the features learned by the network. We iteratively strengthen our approximation, restoring the dependence between the constraints most responsible for degrading the quality of the approximation. This corresponds to computing the mutual information between pairs of constraints conditioned on the network's learned features, and may be construed as a measure of how well aligned the gradients of two distributions are. We show how to compute this efficiently for tractable circuits. We test our approach on three tasks: predicting a minimum-cost path in Warcraft, predicting a minimum-cost perfect matching, and solving Sudoku puzzles, observing that it improves upon the baselines while sidestepping intractability.},
rank=37
}

@inproceedings{bansal2023cleanclip,
author={Hritik Bansal and Nishad Singhi and Yu Yang and Fan Yin and Aditya Grover and Md. Rizwan Parvez},
title={CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning},
booktitle={ICCV},
code_url={https://github.com/nishadsinghi/CleanCLIP},
keyword={robustness},
note={An eariler version appears at ICLR workshop on Reliable and Trustworthy Large Scale Machine Learning},
keynote = {<i class="fa fa-trophy"></i> Best Paper Award at ICLR Workshop, Oral at ICCV (195 out of 8088 submissions, top 2.5\%)}, 
year={2023},
selected=true,
paper_url={https://arxiv.org/abs/2303.03323},
abstract={Multimodal contrastive pretraining has been used to train multimodal representation models, such as CLIP, on large amounts of paired image-text data. However, previous studies have revealed that such models are vulnerable to backdoor attacks. Specifically, when trained on backdoored examples, CLIP learns spurious correlations between the embedded backdoor trigger and the target label, aligning their representations in the joint embedding space. Injecting even a small number of poisoned examples, such as 75 examples in 3 million pretraining data, can significantly manipulate the model's behavior, making it difficult to detect or unlearn such correlations. To address this issue, we propose CleanCLIP, a finetuning framework that weakens the learned spurious associations introduced by backdoor attacks by independently re-aligning the representations for individual modalities. We demonstrate that unsupervised finetuning using a combination of multimodal contrastive and unimodal self-supervised objectives for individual modalities can significantly reduce the impact of the backdoor attack. We show empirically that CleanCLIP maintains model performance on benign examples while erasing a range of backdoor attacks on multimodal contrastive learning.},
rank=39
}


@inproceedings{hu2023reveal,
author={Ziniu Hu and Ahmet Iscen and Chen Sun and Zirui Wang and Md. Rizwan Parvez and Yizhou Sun and Cordelia Schmid and David A. Ross and Alireza Fathi},
title={REVEAL: Retrieval-Augmented Visual-Language Pre-Training with Multi-Source Multimodal Knowledge},
keyword={vlmodel},
booktitle={CVPR},
year={2023},
paper_url={https://arxiv.org/abs/2212.05221},
rank=35, 
abstract={In this paper, we propose an end-to-end Retrieval-Augmented Visual Language Model (REVEAL) that learns to encode world knowledge into a large-scale memory, and to retrieve from it to answer knowledge-intensive queries. REVEAL consists of four key components: the memory, the encoder, the retriever and the generator. The large-scale memory encodes various sources of multimodal world knowledge (e.g. image-text pairs, question answering pairs, knowledge graph triplets, etc) via a unified encoder. The retriever finds the most relevant knowledge entries in the memory, and the generator fuses the retrieved knowledge with the input query to produce the output. A key novelty in our approach is that the memory, encoder, retriever and generator are all pre-trained end-to-end on a massive amount of data. Furthermore, our approach can use a diverse set of multimodal knowledge sources, which is shown to result in significant gains. We show that REVEAL achieves state-of-the-art results on visual question answering and image captioning.},
}


@inproceedings{yin2023givl,
author={Da Yin and Feng Gao and Govind Thattai and Michael Johnston and Md. Rizwan Parvez},
title={GIVL: On Improving Geographical Inclusivity of Vision-and-Language Models with Pre-Training Methods},
booktitle = {CVPR},
keyword={inclusive},
paper_url={https://arxiv.org/abs/2301.01893},
year={2023},
rank = 35, 
abstract= {A key goal for the advancement of AI is to develop technologies that serve the needs not just of one group but of all communities regardless of their geographical region. In fact, a significant proportion of knowledge is locally shared by people from certain regions but may not apply equally in other regions because of cultural differences. If a model is unaware of regional characteristics, it may lead to performance disparity across regions and result in bias against underrepresented groups. We propose GIVL, a Geographically Inclusive Vision-and-Language Pre-trained model. There are two attributes of geo-diverse visual concepts which can help to learn geo-diverse knowledge: 1) concepts under similar categories have unique knowledge and visual characteristics, 2) concepts with similar visual features may fall in completely different categories. Motivated by the attributes, we design new pre-training objectives Image Knowledge Matching (IKM) and Image Edit Checking (IEC) to pre-train GIVL. Compared with similar-size models pre-trained with similar scale of data, GIVL achieves state-of-the-art (SOTA) and more balanced performance on geo-diverse V&L tasks.}
}

@inproceedings{lu2023dynamic,
  author = {Lu, Pan and Qiu, Liang and Chang, Kai-Wei and Wu, Ying Nian and Zhu, Song-Chun and Rajpurohit, Tanmay and Clark, Peter and Kalyan, Ashwin},
keyword={reasoning},
  title = {Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning},
  booktitle = {ICLR},
  year = {2023},
  rank = 40,
paper_url={https://arxiv.org/abs/2209.14610},
abstract={Mathematical reasoning, a core ability of human intelligence, presents unique challenges for machines in abstract thinking and logical reasoning. Recent large pre-trained language models such as GPT-3 have achieved remarkable progress on mathematical reasoning tasks written in text form, such as math word problems (MWP). However, it is unknown if the models can handle more complex problems that involve math reasoning over heterogeneous information, such as tabular data. To fill the gap, we present Tabular Math Word Problems (TabMWP), a new dataset containing 38,431 open-domain grade-level problems that require mathematical reasoning on both textual and tabular data. Each question in TabMWP is aligned with a tabular context, which is presented as an image, semi-structured text, and a structured table. There are two types of questions: free-text and multi-choice, and each problem is annotated with gold solutions to reveal the multi-step reasoning process. We evaluate different pre-trained models on TabMWP, including the GPT-3 model in a few-shot setting. As earlier studies suggest, since few-shot GPT-3 relies on the selection of in-context examples, its performance is unstable and can degrade to near chance. The unstable issue is more severe when handling complex problems like TabMWP. To mitigate this, we further propose a novel approach, PromptPG, which utilizes policy gradient to learn to select in-context examples from a small amount of training data and then constructs the corresponding prompt for the test example. Experimental results show that our method outperforms the best baseline by 5.31% on the accuracy metric and reduces the prediction variance significantly compared to random selection, which verifies its effectiveness in the selection of in-context examples.} 
}



@inproceedings{arseniev2022aggression,
 title={Integrating topic modeling and word embedding to characterize violent deaths},
 author={Arseniev-Koehler, Alina and Susan D Cochran and Vickie Mays and Md. Rizwan Parvez and Jacob Foster },
 rank = {37},
 paper_url={https://www.pnas.org/doi/abs/10.1073/pnas.2108801119},
 abstract={There is an escalating need for methods to identify latent patterns in text data from many domains. We introduce a method to identify topics in a corpus and represent documents as topic sequences. Discourse atom topic modeling (DATM) draws on advances in theoretical machine learning to integrate topic modeling and word embedding, capitalizing on their distinct capabilities. We first identify a set of vectors (discourse atoms) that provide a sparse representation of an embedding space. Discourse atoms can be interpreted as latent topics; through a generative model, atoms map onto distributions over words. We can also infer the topic that generated a sequence of words. We illustrate our method with a prominent example of underutilized text: the US National Violent Death Reporting System (NVDRS). The NVDRS summarizes violent death incidents with structured variables and unstructured narratives. We identify 225 latent topics in the narratives (e.g., preparation for death and physical aggression); many of these topics are not captured by existing structured variables. Motivated by known patterns in suicide and homicide by gender and recent research on gender biases in semantic space, we identify the gender bias of our topics (e.g., a topic about pain medication is feminine). We then compare the gender bias of topics to their prevalence in narratives of female versus male victims. Results provide a detailed quantitative picture of reporting about lethal violence and its gendered nature. Our method offers a flexible and broadly applicable approach to model topics in text data.},
 booktitle={Proceedings of the National Academy of Sciences},
 year={2022}
}



@inproceedings{hu2022empowering,
  title={Empowering Language Models with Knowledge Graph Reasoning for Open-Domain Question Answering},
  author={Ziniu Hu and Yichong Xu and Wenhao Yu and Shuohang Wang and Ziyi Yang and Chenguang Zhu and Md. Rizwan Parvez and Yizhou Sun},
  rank=25,
  paper_url={https://arxiv.org/abs/2211.08380},
  booktitle={EMNLP},
  year=2022
}

@inproceedings{you2022find,
  title={Find Someone Who: Visual Commonsense Understanding in Human-Centric Grounding},
  author={Haoxuan You and Rui Sun and Zhecan Wang and Md. Rizwan Parvez and Shih-Fu Chang},
  paper_url={https://aclanthology.org/2022.findings-emnlp.399.pdf},
  rank=29,
  booktitle={EMNLP-Finding},
  year=2022
}

@inproceedings{you2022find,
  title={Understanding ME? Multimodal Evaluation for Fine-grained Visual Commonsense},
  author={Zhecan Wang and Haoxuan You and Yicheng He and Wenhao Li and Md. Rizwan Parvez and Shih-Fu Chang},
  rank=20,
  paper_url={https://arxiv.org/abs/2211.05895},
  booktitle={EMNLP},
  year=2022
}




@inproceedings{zhao2022investigating,
  title={	Investigating Ensemble Methods for Model Robustness Improvement of Text Classifiers},
  author={Jieyu Zhao and Xuezhi Wang and Yao Qin and Jilin Chen and Md. Rizwan Parvez},
  rank=29,
  booktitle={EMNLP-Finding (short)},
  year=2022,
  keyword={robustness},
  paper_url={https://arxiv.org/abs/2210.16298}
}


@inproceedings{chi2022conditional,
  title={Conditional Supervised Contrastive Learning for Fair Text Classification},
  author={Jianfeng Chi and William Shand and Yaodong Yu and Md. Rizwan Parvez and Han Zhao and Yuan Tian},
  rank=29,
  booktitle={EMNLP-Finding},
  paper_url={https://arxiv.org/abs/2205.11485},
  year=2022,
}

@inproceedings{yin2022addmu,
  title={ADDMU: Detection of Far-Boundary Adversarial Examples with Data and Model Uncertainty Estimation},
  author={Fan Yin and Yao Li and Cho-Jui Hsieh and Md. Rizwan Parvez},
  rank=20,
  booktitle={EMNLP},
  year=2022,
keyword={robustness},
  paper_url={https://arxiv.org/abs/2210.12396},
  abstract={Adversarial Examples Detection (AED) is a crucial defense technique against adversarial attacks and has drawn increasing attention from the Natural Language Processing (NLP) community. Despite the surge of new AED methods, our studies show that existing methods heavily rely on a shortcut to achieve good performance. In other words, current search-based adversarial attacks in NLP stop once model predictions change, and thus most adversarial examples generated by those attacks are located near model decision boundaries. To surpass this shortcut and fairly evaluate AED methods, we propose to test AED methods with Far Boundary (FB) adversarial examples. Existing methods show worse than random guess performance under this scenario. To overcome this limitation, we propose a new technique, ADDMU, adversary detection with data and model uncertainty, which combines two types of uncertainty estimation for both regular and FB adversarial example detection. Our new method outperforms previous methods by 3.6 and 6.0 AUC points under each scenario. Finally, our analysis shows that the two types of uncertainty provided by ADDMU can be leveraged to characterize adversarial examples and identify the ones that contribute most to model's robustness in adversarial training.},
}

@inproceedings{wu2022representation,
  title={Representation Learning for Resource-Constrained Keyphrase Generation},
  author={Di Wu and Wasi Uddin Ahmad and Sunipa Dev and Md. Rizwan Parvez},
keyword={keyphrase},
  rank=29,
  booktitle={EMNLP-Finding},
  abstract={State-of-the-art keyphrase generation methods generally depend on large annotated datasets, limiting their performance in domains with limited annotated data. To overcome this challenge, we design a data-oriented approach that first identifies salient information using unsupervised corpus-level statistics, and then learns a task-specific intermediate representation based on a pre-trained language model. We introduce salient span recovery and salient span prediction as denoising training objectives that condense the intra-article and inter-article knowledge essential for keyphrase generation. Through experiments on multiple keyphrase generation benchmarks, we show the effectiveness of the proposed approach for facilitating low-resource and zero-shot keyphrase generation. We further observe that the method especially benefits the generation of absent keyphrases, approaching the performance of models trained with large training sets.},
  paper_url={https://arxiv.org/abs/2203.08118}, 
  year=2022,
  code_url={https://github.com/xiaowu0162/low-resource-kpgen}
}


@inproceedings{huang2022unsupervised,
  title={Unsupervised Syntactically Controlled Paraphrase Generation with Abstract Meaning Representations},
  author={Kuan-Hao Huang and Varun Iyer and Anoop Kumar and Sriram Venkatapathy and Md. Rizwan Parvez and Aram Galstyan},
  rank=29,
  booktitle={EMNLP-Finding (short)},
  paper_url={https://arxiv.org/abs/2211.00881},
keyword={robustness},
  year=2022,
}

@inproceedings{yin2022geomlama,
    title={GeoMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models},
    author={Da Yin and Hritik Bansal and Masoud Monajatipoor and Liunian Harold Li and Md. Rizwan Parvez},
    rank=20,
keyword={inclusive},
    paper_url={https://arxiv.org/abs/2205.12247},
    booktitle={EMNLP},
    abstract={Recent work has shown that Pre-trained Language Models (PLMs) have the ability to store the relational knowledge from pre-training data in their model parameters. However, it is not clear up to what extent do PLMs store geo-diverse commonsense knowledge, the knowledge associated with a culture and only shared locally. For instance, the color of bridal dress is white in American weddings whereas it is red in Chinese weddings. Here, we wish to probe if PLMs can predict red and white as the color of the bridal dress when queried for American and Chinese weddings, respectively. To this end, we introduce a framework for geo-diverse commonsense probing on multilingual PLMs (mPLMs) and introduce a corresponding benchmark Geo-diverse Commonsense Multilingual Language Model Analysis (GeoMLAMA) dataset. GeoMLAMA contains 3125 prompts in English, Chinese, Hindi, Persian, and Swahili, with a wide coverage of concepts shared by people from American, Chinese, Indian, Iranian and Kenyan cultures. We benchmark 11 standard mPLMs which include variants of mBERT, XLM, mT5, and XGLM on GeoMLAMA. Interestingly, we find that 1) larger mPLM variants do not necessarily store geo-diverse concepts better than its smaller variant; 2) mPLMs are not intrinsically biased towards knowledge from the Western countries (the United States); 3) the native language of a country may not be the best language to probe its knowledge and 4) a language may better probe knowledge about a non-native country than its native country. },
    year=2022,
    code_url={https://github.com/wadeyin9712/geomlama}
}

@inproceedings{bansal2022how ,
    title={How well can Text-to-Image Generative Models understand Ethical Natural Language Interventions?},
keyword={fairnlg},
    author={Hritik Bansal and Da Yin and Masoud Monajatipoor and Md. Rizwan Parvez},
    rank=25,
    paper_url={https://arxiv.org/abs/2210.15230},
    booktitle={EMNLP (Short)},
    abstract={Text-to-image generative models have achieved unprecedented success in generating high-quality images based on natural language descriptions. However, it is shown that these models tend to favor specific social groups when prompted with neutral text descriptions (e.g., 'a photo of a lawyer'). Following Zhao et al. (2021), we study the effect on the diversity of the generated images when adding ethical intervention that supports equitable judgment (e.g., 'if all individuals can be a lawyer irrespective of their gender') in the input prompts. To this end, we introduce an Ethical NaTural Language Interventions in Text-to-Image GENeration (ENTIGEN) benchmark dataset to evaluate the change in image generations conditional on ethical interventions across three social axes -- gender, skin color, and culture. Through ENTIGEN framework, we find that the generations from minDALL.E, DALL.E-mini and Stable Diffusion cover diverse social groups while preserving the image quality. Preliminary studies indicate that a large change in the model predictions is triggered by certain phrases such as 'irrespective of gender' in the context of gender bias in the ethical interventions. We release code and annotated data at https://github.com/Hritikbansal/entigen_emnlp.},
    year=2022,
    code_url={https://github.com/Hritikbansal/entigen_emnlp}
}


@inproceedings{meng2022controllable,
    title={Controllable Text Generation with Neurally-Decomposed Oracle},
    keyword={constraint},
    author={Tao Meng and Sidi Lu and Nanyun Peng and Md. Rizwan Parvez},
    rank=30,

   selected=true,
    paper_url={https://arxiv.org/abs/2205.14219},
    booktitle={NeurIPS},
    code_url={https://github.com/MtSomeThree/constrDecoding},
    abstract={We propose a general and efficient framework to control auto-regressive generation models with NeurAlly-Decomposed Oracle (NADO). Given a pre-trained base language model and a sequence-level boolean oracle function, we propose to decompose the oracle function into token-level guidance to steer the base model in text generation. Specifically, the token-level guidance is approximated by a neural model trained with examples sampled from the base model, demanding no additional auxiliary labeled data. We present the closed-form optimal solution to incorporate the token-level guidance into the base model for controllable generation. We further provide a theoretical analysis of how the approximation quality of NADO affects the controllable generation results. Experiments conducted on two applications: (1) text generation with lexical constraints and (2) machine translation with formality control demonstrate that our framework efficiently guides the base model towards the given oracle while maintaining high generation quality.},
keynote={Oral Presentation, 201 out of 10411, top 1.9%},    
year=2022
}


@inproceedings{lu2022learn,
    title={Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering},
    author={Pan Lu and Swaroop Mishra and Tony Xia and Liang Qiu and Md. Rizwan Parvez and Song-Chun Zhu and Oyvind Tafjord and Peter Clark and Ashwin Kalyan},
keyword={reasoning},
    rank=30,
    paper_url={https://arxiv.org/pdf/2209.09513.pdf},
    booktitle={NeurIPS},
    keynote = {Top-15 cited paper at NeurIPS 22},
    github_url={https://github.com/lupantech/ScienceQA},
    year=2022
}

@inproceedings{subramonian2022on,
    title={On the Discrimination Risk of Mean Aggregation Feature Imputation in Graphs},
    author={Arjun Subramonian and Md. Rizwan Parvez and Yizhou Sun},
    rank=30,
    paper_url={https://openreview.net/forum?id=maSvlkPHc-k},
    booktitle={NeurIPS},
    year=2022
}

@inproceedings{ahmed2022semantic,
    title={Semantic Probabilistic Layers for Neuro-Symbolic Learning},
keyword={reasoning},
    paper_url={https://arxiv.org/abs/2206.00426},
    author={Kareem Ahmed and Stefano Teso and Md. Rizwan Parvez and Guy Van den Broeck and Antonio Vergari},
    rank=30,
    booktitle={NeurIPS},
    year=2022
}


@inproceedings{ahmadneuro2022,
    title={Neuro-Symbolic Entropy Regularization},
keyword={reasoning},
    author={Kareem Ahmed and Eric Wang and Md. Rizwan Parvez and Guy Van den Broeck},
    rank=39,
    paper_url={https://arxiv.org/abs/2201.11250},
    booktitle={UAI},
    abstract={In structured prediction, the goal is to jointly predict many output variables that together encode a structured object -- a path in a graph, an entity-relation triple, or an ordering of objects. Such a large output space makes learning hard and requires vast amounts of labeled data. Different approaches leverage alternate sources of supervision. One approach -- entropy regularization -- posits that decision boundaries should lie in low-probability regions. It extracts supervision from unlabeled examples, but remains agnostic to the structure of the output space. Conversely, neuro-symbolic approaches exploit the knowledge that not every prediction corresponds to a valid structure in the output space. Yet, they does not further restrict the learned output distribution. This paper introduces a framework that unifies both approaches. We propose a loss, neuro-symbolic entropy regularization, that encourages the model to confidently predict a valid object. It is obtained by restricting entropy regularization to the distribution over only valid structures. This loss is efficiently computed when the output constraint is expressed as a tractable logic circuit. Moreover, it seamlessly integrates with other neuro-symbolic losses that eliminate invalid predictions. We demonstrate the efficacy of our approach on a series of semi-supervised and fully-supervised structured-prediction experiments, where we find that it leads to models whose predictions are more accurate and more likely to be valid.},
    year=2022
}
@inproceedings{ahmad2022pylon,
    title={PYLON: A PyTorch Framework for Learning with Constraints},
    author={Kareem Ahmed and  Tao Li and  Thy Ton and  Quan Guo and  Md. Rizwan Parvez and  Parisa Kordjamshidi and  Vivek Srikumar and  Guy Van den Broeck and Sameer Singh},
    rank=50,
    paper_url={http://starai.cs.ucla.edu/papers/AhmedAAAI22.pdf},
    booktitle={AAAI (demo)},
    year = 2022
}
 
@inproceedings{malik2022socially,
    title={Socially Aware Bias Measurements for Hindi Language Representations},
    author={ Vijit Malik and Sunipa Dev and Akihiro Nishi and Nanyun Peng and Md. Rizwan Parvez},
    rank=40,
    paper_url={https://arxiv.org/pdf/2110.07871.pdf},
    booktitle={NAACL (short)},
    year=2022
}
            

@inproceedings{li2022grounded,
    title={Grounded Language-Image Pre-training},
    author={Liunian Harold Li and Pengchuan Zhang and  Haotian Zhang and Jianwei Yang and  Chunyuan Li and  Yiwu Zhong and  Lijuan Wang and Lu Yuan and Lei Zhang and Jenq-Neng Hwang and Md. Rizwan Parvez and  Jianfeng Gao},
    rank = {57},
    abstract={This paper presents a grounded language-image pre-training (GLIP) model for learning object-level, language-aware, and semantic-rich visual representations. GLIP unifies object detection and phrase grounding for pre-training. The unification brings two benefits: 1) it allows GLIP to learn from both detection and grounding data to improve both tasks and bootstrap a good grounding model; 2) GLIP can leverage massive image-text pairs by generating grounding boxes in a self-training fashion, making the learned representation semantic-rich. In our experiments, we pre-train GLIP on 27M grounding data, including 3M human-annotated and 24M web-crawled image-text pairs. The learned representations demonstrate strong zero-shot and few-shot transferability to various object-level recognition tasks. 1) When directly evaluated on COCO and LVIS (without seeing any images in COCO during pre-training), GLIP achieves 49.8 AP and 26.9 AP, respectively, surpassing many supervised baselines. 2) After fine-tuned on COCO, GLIP achieves 60.8 AP on val and 61.5 AP on test-dev, surpassing prior SoTA. 3) When transferred to 13 downstream object detection tasks, a 1-shot GLIP rivals with a fully-supervised Dynamic Head.},
    code_url={https://github.com/microsoft/GLIP},
    paper_url={https://arxiv.org/pdf/2112.03857.pdf},
    booktitle = {CVPR},
keyword={vlmodel},
    keynote = {<i class="fa fa-trophy"></i> Best Paper Finallist, 33 out of 8161 submissions, top 0.4%}, 
    year={2022}
}

@inproceedings{trista2022evaluation,
    title={On the Intrinsic and Extrinsic Fairness Evaluation Metrics for Contextualized Language Representations},
keyword={fairnlg},    
author={Yang Trista Cao and  Yada Pruksachatkun and  Md. Rizwan Parvez and  Rahul Gupta and  Varun Kumar and  Jwala Dhamala and  Aram Galstyan},
    rank = {54},
    abstract={Multiple metrics have been introduced to measure fairness in various natural language processing tasks. These metrics can be roughly categorized into two categories: 1) \emph{extrinsic metrics} for evaluating fairness in downstream applications and 2) \emph{intrinsic metrics} for estimating fairness in upstream contextualized language representation models. In this paper, we conduct an extensive correlation study between intrinsic and extrinsic metrics across bias notions using 19 contextualized language models. We find that intrinsic and extrinsic metrics do not necessarily correlate in their original setting, even when correcting for metric misalignments, noise in evaluation datasets, and confounding factors such as experiment configuration for extrinsic metrics.},
    booktitle = {ACL (short)},
    paper_url={https://arxiv.org/abs/2203.13928},
    year={2022}
}

@inproceedings{huang2022multilingual,
    title={Multilingual Generative Language Models for Zero-Shot Cross-Lingual Event Argument Extraction},
    author={Kuan-Hao Huang and I-Hung Hsu and Prem Natarajan and Md. Rizwan Parvez and Nanyun Peng},
    rank = {50},
keyword={crosslingual},
    booktitle = {ACL},
    abstract={We present a study on leveraging multilingual pre-trained generative language models for zero-shot cross-lingual event argument extraction (EAE). By formulating EAE as a language generation task, our method effectively encodes event structures and captures the dependencies between arguments. We design language-agnostic templates to represent the event argument structures, which are compatible with any language, hence facilitating the cross-lingual transfer. Our proposed model finetunes multilingual pre-trained generative language models to generate sentences that fill in the language-agnostic template with arguments extracted from the input passage. The model is trained on source languages and is then directly applied to target languages for event argument extraction. Experiments demonstrate that the proposed model outperforms the current state-of-the-art models on zero-shot cross-lingual EAE. Comprehensive studies and error analyses are presented to better understand the advantages and the current limitations of using generative language models for zero-shot cross-lingual transfer EAE.},
    paper_url={https://arxiv.org/pdf/2203.08308.pdf},
    code_url={https://github.com/PlusLabNLP/X-Gear},
    year={2022}
}
@inproceedings{zhang2022improving,
    title={Improving the Adversarial Robustness of NLP Models by Information Bottleneck},
    author={Cenyuan Zhang and  Xiang Zhou and  Yixin Wan and  Xiaoqing Zheng and  Md. Rizwan Parvez and  Cho-Jui Hsieh},
    rank = {55},
    booktitle = {ACL-Finding},
    abstract={Existing studies have demonstrated that adversarial examples can be directly attributed to the presence of non-robust features, which are highly predictive, but can be easily manipulated by adversaries to fool NLP models. In this study, we explore the feasibility of capturing task-specific robust features, while eliminating the non-robust ones by using the information bottleneck theory. Through extensive experiments, we show that the models trained with our information bottleneck-based method are able to achieve a significant improvement in robust accuracy, exceeding performances of all the previously reported defense methods while suffering almost no performance drop in clean accuracy on SST-2, AGNEWS and IMDB datasets.},
    paper_url={https://aclanthology.org/2022.findings-acl.284.pdf},
    year={2022},
keyword={robustness}
}
@inproceedings{krishna2022measuring,
    title={Measuring Fairness of Text Classifiers via Prediction Sensitivity},
    author={Satyapriya Krishna and  Rahul Gupta and  Apurv Verma and  Jwala Dhamala and  Yada Pruksachatkun and  Md. Rizwan Parvez},
    rank = {50},
    paper_url={https://arxiv.org/abs/2203.08670},
    abstract={With the rapid growth in language processing applications, fairness has emerged as an important consideration in data-driven solutions. Although various fairness definitions have been explored in the recent literature, there is lack of consensus on which metrics most accurately reflect the fairness of a system. In this work, we propose a new formulation : ACCUMULATED PREDICTION SENSITIVITY, which measures fairness in machine learning models based on the model's prediction sensitivity to perturbations in input features. The metric attempts to quantify the extent to which a single prediction depends on a protected attribute, where the protected attribute encodes the membership status of an individual in a protected group. We show that the metric can be theoretically linked with a specific notion of group fairness (statistical parity) and individual fairness. It also correlates well with humans' perception of fairness. We conduct experiments on two text classification datasets : JIGSAW TOXICITY, and BIAS IN BIOS, and evaluate the correlations between metrics and manual annotations on whether the model produced a fair outcome. We observe that the proposed fairness metric based on prediction sensitivity is statistically significantly more correlated with human annotation than the existing counterfactual fairness metric.},
    booktitle = {ACL},
keyword={fairnlp},
    year={2022}
}

@inproceedings{yin2022on,
    title={On the Sensitivity and Stability of Model Interpretations},
    author={Fan Yin and Zhouxing Shi and Cho-Jui Hsieh and Md. Rizwan Parvez},
    paper_url={https://arxiv.org/abs/2104.08782},
    abstract={Recent years have witnessed the emergence of a variety of post-hoc interpretations that aim to uncover how natural language processing (NLP) models make predictions. Despite the surge of new interpretation methods, it remains an open problem how to define and quantitatively measure the faithfulness of interpretations, i.e., to what extent interpretations reflect the reasoning process by a model. We propose two new criteria, sensitivity and stability, that provide complementary notions of faithfulness to the existed removal-based criteria. Our results show that the conclusion for how faithful interpretations are could vary substantially based on different notions. Motivated by the desiderata of sensitivity and stability, we introduce a new class of interpretation methods that adopt techniques from adversarial robustness. Empirical results show that our proposed methods are effective under the new criteria and overcome limitations of gradient-based methods on removal-based criteria. Besides text classification, we also apply interpretation methods and metrics to dependency parsing. Our results shed light on understanding the diverse set of interpretations.},
    rank = {50},
    booktitle = {ACL},
keyword={explanation},
    year={2022}
}


@inproceedings{xu2022towards,
    title={Towards Adversarially Robust Text Classifiers by Learning to Reweight Clean Examples},
    author={Jianhan Xu and  Cenyuan Zhang and  Xiaoqing Zheng and  Linyang Li and  Cho-Jui Hsieh and  Md. Rizwan Parvez and  Xuanjing Huang}, 
    rank = {55},
    abstract={Most of the existing defense methods improve the adversarial robustness by making the models adapt to the training set augmented with some adversarial examples. However, the augmented adversarial examples may not be natural, which might distort the training distribution, resulting in inferior performance both in clean accuracy and adversarial robustness. In this study, we explore the feasibility of introducing a reweighting mechanism to calibrate the training distribution to obtain robust models. We propose to train text classifiers by a sample reweighting method in which the example weights are learned to minimize the loss of a validation set mixed with the clean examples and their adversarial ones in an online learning manner. Through extensive experiments, we show that there exists a reweighting mechanism to make the models more robust against adversarial attacks without the need to craft the adversarial examples for the entire training set.},
    paper_url={https://aclanthology.org/2022.findings-acl.134.pdf},
    booktitle = {ACL Finding},
    year={2022}
}


@inproceedings{gupta2022equitable,
    title={Mitigating Gender Bias in Distilled Language Models via Counterfactual Role Reversal},
    author={Umang Gupta and  Jwala Dhamala and  Varun Kumar and  Apurv Verma and  Yada Pruksachatkun and  Satyapriya Krishna and  Rahul Gupta and  Md. Rizwan Parvez and  Greg Ver Steeg and  Aram Galstyan},
    rank = {55},
    paper_url={https://arxiv.org/abs/2203.12574},
    abstract={Language models excel at generating coherent text, and model compression techniques such as knowledge distillation have enabled their use in resource-constrained settings. However, these models can be biased in multiple ways, including the unfounded association of male and female genders with gender-neutral professions. Therefore, knowledge distillation without any fairness constraints may preserve or exaggerate the teacher model's biases onto the distilled model. To this end, we present a novel approach to mitigate gender disparity in text generation by learning a fair model during knowledge distillation. We propose two modifications to the base knowledge distillation based on counterfactual role reversal -- modifying teacher probabilities and augmenting the training set. We evaluate gender polarity across professions in open-ended text generated from the resulting distilled and finetuned GPT-2models and demonstrate a substantial reduction in gender disparity with only a minor compromise in utility. Finally, we observe that language models that reduce gender polarity in language generation do not improve embedding fairness or downstream classification fairness.},
    booktitle = {ACL Finding},
keyword={fairrep},
    year={2022}
}



@inproceedings{shen2022how,
    title={ How Much Can CLIP Benefit Vision-and-Language Tasks? },
    author={Sheng Shen and Liunian Harold Li and Hao Tan and Mohit Bansal and Anna Rohrbach and Md. Rizwan Parvez and Zhewei Yao and Kurt Keutz},
    rank = {59},
    paper_url={https://arxiv.org/pdf/2107.06383.pdf},
keynote_url = {https://www.paperdigest.org/2023/04/most-influential-iclr-papers-2023-04/}, 
keynote = {Top-10 cited paper at ICLR 22},
    abstract={Most existing Vision-and-Language (V&L) models rely on pre-trained visual encoders, using a relatively small set of manually-annotated data (as compared to web-crawled data), to perceive the visual world. However, it has been observed that large-scale pretraining usually can result in better generalization performance, e.g., CLIP (Contrastive Language-Image Pre-training), trained on a massive amount of image-caption pairs, has shown a strong zero-shot capability on various vision tasks. To further study the advantage brought by CLIP, we propose to use CLIP as the visual encoder in various V&L models in two typical scenarios: 1) plugging CLIP into task-specific fine-tuning; 2) combining CLIP with V&L pre-training and transferring to downstream tasks. We show that CLIP significantly outperforms widely-used visual encoders trained with in-domain annotated data, such as BottomUp-TopDown. We achieve competitive or better results on diverse V&L tasks, while establishing new state-of-the-art results on Visual Question Answering, Visual Entailment, and V&L Navigation tasks.},
    code_url={https://github.com/clip-vil/CLIP-ViL},
    booktitle = {ICLR},
keyword={vlmodel},
    year={2022}
}

@inproceedings{wang2022sgeitl,
    title={SGEITL: Scene Graph Enhanced Image-Text Learning for Visual Commonsense Reasoning},
    author={Zhecan Wang and Haoxuan You and Liunian Harold Li and Alireza Zareian and Suji Park and Yiqing Liang and Md. Rizwan Parvez and Shih-Fu Chang},
    rank = {60},
    paper_url={https://arxiv.org/abs/2112.08587},
    abstract={Answering complex questions about images is an ambitious goal for machine intelligence, which requires a joint understanding of images, text, and commonsense knowledge, as well as a strong reasoning ability. Recently, multimodal Transformers have made a great progress in the task of Visual Commonsense Reasoning (VCR), by jointly understanding visual objects and text tokens through layers of cross-modality attention. However, these approaches do not utilize the rich structure of the scene and the interactions between objects which are essential in answering complex commonsense questions. We propose a Scene Graph Enhanced Image-Text Learning ({\bf SGEITL}) framework to incorporate visual scene graph in commonsense reasoning. In order to exploit the scene graph structure, at the model structure level, we propose a multihop graph transformer for regularizing attention interaction among hops. As for pre-training, a scene-graph-aware pre-training method is proposed to leverage structure knowledge extracted in visual scene graph. Moreover, we introduce a method to train and generate domain relevant visual scene graph using textual annotations in a weakly-supervised manner. Extensive experiments on VCR and other tasks show significant performance boost compared with the state-of-the-art methods, and prove the efficacy of each proposed component.},
    booktitle = {AAAI},
    year={2022}
}

@inproceedings{monajatipoor2021berthop,
    title={BERTHop: An Effective Vision-and-Language Model for Chest X-ray Disease Diagnosis},
    author={ Masoud Monajatipoor and Mozhdeh Rouhsedaghat and Liunian Harold Li and Aichi Chien and C. -C. Jay Kuo and Fabien Scalzo and Md. Rizwan Parvez},
    rank = {28},
    paper_url={https://arxiv.org/pdf/2108.04938.pdf},
    abstract={Vision-and-language(V&L) models take image and text as input and learn to capture the associations between them. Prior studies show that pre-trained V&L models can significantly improve the model performance for downstream tasks such as Visual Question Answering (VQA). However, V&L models are less effective when applied in the medical domain (e.g., on X-ray images and clinical notes) due to the domain gap. In this paper, we investigate the challenges of applying pre-trained V&L models in medical applications. In particular, we identify that the visual representation in general V&L models is not suitable for processing medical data. To overcome this limitation, we propose BERTHop, a transformer-based model based on PixelHop++ and VisualBERT, for better capturing the associations between the two modalities. Experiments on the OpenI dataset, a commonly used thoracic disease diagnosis benchmark, show that BERTHop achieves an average Area Under the Curve (AUC) of 98.12% which is 1.62% higher than state-of-the-art (SOTA) while it is trained on a 9 times smaller dataset.},
    booktitle={ICCV workshop on Computer Vision for Automated Medical Diagnosis},
    year={2021}
}

@inproceedings{hsu2021degree,
    title={DEGREE: A Data-Efficient Generative Event Extraction Model},
    author={I-Hung Hsu and Kuan-Hao Huang and Elizabeth Boschee and Scott Miller and Prem Natarajan and Md. Rizwan Parvez and Nanyun Peng},
    paper_url={https://arxiv.org/pdf/2108.12724.pdf},
    abstract={Event extraction (EE), the task that identifies event triggers and their arguments in text, is usually formulated as a classification or structured prediction problem. Such models usually reduce labels to numeric identifiers, making them unable to take advantage of label semantics (e.g. an event type named Arrest is related to words like arrest, detain, or apprehend). This prevents the generalization to new event types. In this work, we formulate EE as a natural language generation task and propose GenEE, a model that not only captures complex dependencies within an event but also generalizes well to unseen or rare event types. Given a passage and an event type, GenEE is trained to generate a natural sentence following a predefined template for that event type. The generated output is then decoded into trigger and argument predictions. The autoregressive generation process naturally models the dependencies among the predictions -- each new word predicted depends on those already generated in the output sentence. Using carefully designed input prompts during generation, GenEE is able to capture label semantics, which enables the generalization to new event types. Empirical results show that our model achieves strong performance on event extraction tasks under all zero-shot, few-shot, and high-resource scenarios. Especially, in the high-resource setting, GenEE outperforms the state-of-the-art model on argument extraction and gets competitive results with the current best on end-to-end EE tasks.},
    booktitle={NAACL},
    keyword={ie},
    year={2022},
    rank=40
}

@inproceedings{ahmad2021avatar,
    title={AVATAR: A Parallel Corpus for Java-Python Program Translation},
    author={Wasi Ahmad and Md Golam Rahman Tushar and Saikat Chakraborty, and Md. Rizwan Parvez},
    paper_url={https://arxiv.org/abs/2108.11590},
    code_url={https://github.com/wasiahmad/AVATAR},
    abstract={Program translation refers to migrating source code from one programming language to another. It has a tremendous practical value in software development as porting software across different languages is time-consuming and costly. Automating program translation is of paramount importance in software migration, and recently researchers explored unsupervised approaches due to the unavailability of parallel corpora. However, the availability of pre-trained language models for programming languages enable supervised fine-tuning with a small amount of labeled examples. In this work, we present a corpus of 8,475 programming problems and their solutions written in two popular languages, Java and Python. We collect the dataset from competitive programming sites, online platforms, and open source repositories. We present several baselines, including models trained from scratch or pre-trained on large-scale source code collection and fine-tuned on our proposed dataset. Experiment results show that while the models perform relatively well in terms of the lexical match, they lack in generating code that is accurate in terms of syntax and data-flow match.},
    booktitle={ACL-Finding (short)},
    keyword={codelang},
rank=34,
    year={2023}
}



@inproceedings{hu2021relation,
    title={Relation-Guided Pre-Training for Open-Domain Question Answering},
    author={Ziniu Hu and Yizhou Sun and Md. Rizwan Parvez},
    rank = {21},
    presentation_time={FINDINGS PAPERS - QUESTION ANSWERING},
    presentation_id={https://underline.io/events/192/sessions/7932/lecture/38507-relation-guided-pre-training-for-open-domain-question-answering},
    paper_url={https://arxiv.org/abs/2109.10346},
    abstract={Answering complex open-domain questions requires understanding the latent relations between involving entities. However, we found that the existing QA datasets are extremely imbalanced in some types of relations, which hurts the generalization performance over questions with long-tail relations. To remedy this problem, in this paper, we propose a Relation-Guided Pre-Training (RGPT-QA) framework. We first generate a relational QA dataset covering a wide range of relations from both the Wikidata triplets and Wikipedia hyperlinks. We then pre-train a QA model to infer the latent relations from the question, and then conduct extractive QA to get the target answer entity. We demonstrate that by pretraining with propoed RGPT-QA techique, the popular open-domain QA model, Dense Passage Retriever (DPR), achieves 2.2%, 2.4%, and 6.3% absolute improvement in Exact Match accuracy on Natural Questions, TriviaQA, and WebQuestions. Particularly, we show that RGPT-QA improves significantly on questions with long-tail relations},
    booktitle={EMNLP-Finding},
    keyword={lwll},
    year={2021}
}

@inproceedings{yuan2021on,
    title={On the Transferability of Adversarial Attacks against Neural Text Classifier},
    author={Liping Yuan and Xiaoqing Zheng and Yi Zhou and Cho-Jui Hsieh and Md. Rizwan Parvez},
    paper_url={https://arxiv.org/abs/2011.08558},
    rank = {20},
    presentation_time={VIRTUAL POSTER SESSION I: INTERPRETABILITY AND ANALYSIS OF MODELS FOR NLP},
    presentation_id={https://underline.io/events/192/posters/8223/poster/38067-on-the-transferability-of-adversarial-attacks-against-neural-text-classifier},
    booktitle={EMNLP},
    abstract={Deep neural networks are vulnerable to adversarial attacks, where a small perturbation to an input alters the model prediction. In many cases, malicious inputs intentionally crafted for one model can fool another model. In this paper, we present the first study to systematically investigate the transferability of adversarial examples for text classification models and explore how various factors, including network architecture, tokenization scheme, word embedding, and model capacity, affect the transferability of adversarial examples. Based on these studies, we propose a genetic algorithm to find an ensemble of models that can be used to induce adversarial examples to fool almost all existing models. Such adversarial examples reflect the defects of the learning process and the data bias in the training set. Finally, we derive word replacement rules that can be used for model diagnostics from these adversarial examples.},
    keyword={robustness},
    year={2021}
}

@inproceedings{li2021searching,
    title={Searching for an Effiective Defender: Benchmarking Defense against Adversarial Word Substitution},
    author={Zongyi Li and Jianhan Xu and Jiehang Zeng and Linyang Li and Xiaoqing Zheng and Qi Zhang and Md. Rizwan Parvez and Cho-Jui Hsieh},
    rank = {20},
    presentation_time={VIRTUAL POSTER SESSION I: MACHINE LEARNING FOR NLP},
    presentation_id={https://underline.io/events/192/posters/8225/poster/38025-searching-for-an-effective-defender-benchmarking-defense-against-adversarial-word-substitution},
    abstract={Recent studies have shown that deep neural networks are vulnerable to intentionally crafted adversarial examples, and various methods have been proposed to defend against adversarial word-substitution attacks for neural NLP models. However, there is a lack of systematic study on comparing different defense approaches under the same attacking setting. In this paper, we seek to fill the gap of systematic studies through comprehensive researches on understanding the behavior of neural text classifiers trained by various defense methods under representative adversarial attacks. In addition, we propose an effective method to further improve the robustness of neural text classifiers against such attacks and achieved the highest accuracy on both clean and adversarial examples on AGNEWS and IMDB datasets by a significant margin.},
    paper_url={https://arxiv.org/pdf/2108.12777.pdf},
    booktitle={EMNLP},
    keyword={robustness},
    year={2021}
}

@inproceedings{huang2021improving,
    title={Improving Zero-Shot Cross-Lingual Transfer Learning via Robust Training},
    author={Kuan-Hao Huang and Wasi Ahmad and Nanyun Peng and Md. Rizwan Parvez},
    rank = {20},
    paper_url={https://arxiv.org/pdf/2104.08645.pdf},
    code_url={https://github.com/uclanlp/Robust-XLT},
    presentation_time={3G - IN PERSON POSTER SESSION},
    presentation_id={https://underline.io/events/192/posters/7783/poster/40656-improving-zero-shot-cross-lingual-transfer-learning-via-robust-training},
    abstract={Pre-trained multilingual language encoders, such as multilingual BERT and XLM-R, show great potential for zero-shot cross-lingual transfer. However, these multilingual encoders do not precisely align words and phrases across languages. Especially, learning alignments in the multilingual embedding space usually requires sentence-level or word-level parallel corpora, which are expensive to be obtained for low-resource languages. An alternative is to make the multilingual encoders more robust; when fine-tuning the encoder using downstream task, we train the encoder to tolerate noise in the contextual embedding spaces such that even if the representations of different languages are not aligned well, the model can still achieve good performance on zero-shot cross-lingual transfer. In this work, we propose a learning strategy for training robust models by drawing connections between adversarial examples and the failure cases of zero-shot cross-lingual transfer. We adopt two widely used robust training methods, adversarial training and randomized smoothing, to train the desired robust model. The experimental results demonstrate that robust training improves zero-shot cross-lingual transfer on text classification tasks. The improvement is more significant in the generalized cross-lingual transfer setting, where the pair of input sentences belong to two different languages.},
    booktitle={EMNLP},
    keyword={crosslingual},
    year={2021}
}

@inproceedings{yin2021broaden,
    title={	Broaden the Vision: Geo-Diverse Visual Commonsense Reasoning},
    author={	Da Yin and Liunian Harold Li and Ziniu Hu and Nanyun Peng and Md. Rizwan Parvez},
    rank = {20},
    booktitle={EMNLP},
    keyword={multirep},
    paper_url={https://arxiv.org/abs/2109.06860},
    selected = true,
    abstract={Commonsense is defined as the knowledge that is shared by everyone. However, certain types of commonsense knowledge are correlated with culture and geographic locations and they are only shared locally. For example, the scenarios of wedding ceremonies vary across regions due to different customs influenced by historical and religious factors. Such regional characteristics, however, are generally omitted in prior work. In this paper, we construct a Geo-Diverse Visual Commonsense Reasoning dataset (GD-VCR) to test vision-and-language models' ability to understand cultural and geo-location-specific commonsense. In particular, we study two state-of-the-art Vision-and-Language models, VisualBERT and ViLBERT trained on VCR, a standard multimodal commonsense benchmark with images primarily from Western regions. We then evaluate how well the trained models can generalize to answering the questions in GD-VCR. We find that the performance of both models for non-Western regions including East Asia, South Asia, and Africa is significantly lower than that for Western region. We analyze the reasons behind the performance disparity and find that the performance gap is larger on QA pairs that: 1) are concerned with culture-related scenarios, e.g., weddings, religious activities, and festivals; 2) require high-level geo-diverse commonsense reasoning rather than low-order perception and recognition.},
    code_url={https://github.com/WadeYin9712/GD-VCR},
    presentation_time={4F: SPEECH, VISION, ROBOTICS, MULTIMODAL GROUNDING 1},
    presentation_id={https://underline.io/events/192/sessions/7790/lecture/37514-broaden-the-vision-geo-diverse-visual-commonsense-reasoning},
    year={2021}
}

@inproceedings{dev2021harms,
    title={Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies},
    author={Sunipa Dev and Masoud Monajatipoor and Anaelia Ovalle and Arjun Subramonian and Jeff Phillips and Md. Rizwan Parvez},
    rank = {20},
    presentation_time={4D: ETHICS AND NLP},
    presentation_id={https://underline.io/events/192/sessions/7788/lecture/37320-harms-of-gender-exclusivity-and-challenges-in-non-binary-representation-in-language-technologies},
    blog_url={https://uclanlp.medium.com/harms-of-gender-exclusivity-and-challenges-in-non-binary-representation-in-language-technologies-5f89891b5aee},
    paper_url={https://arxiv.org/pdf/2108.12084.pdf},
    slides_url={https://docs.google.com/presentation/d/e/2PACX-1vQ1qpvt7u7mf51ChlzMICLdLk0YYTxsYAO19gP-HLnMDIf9XlZ-pE-O8gZzzamYgOJ6lXBPZbjW6Ot3/pub?start=false&loop=false&delayms=3000},
    abstract={Gender is widely discussed in the context of language tasks and when examining the stereotypes propagated by language models. However, current discussions primarily treat gender as binary, which can perpetuate harms such as the cyclical erasure of non-binary gender identities. These harms are driven by model and dataset biases, which are consequences of the non-recognition and lack of understanding of non-binary genders in society. In this paper, we explain the complexity of gender and language around it, and survey non-binary persons to understand harms associated with the treatment of gender as binary in English language technologies. We also detail how current language representations (e.g., GloVe, BERT) capture and perpetuate these harms and related challenges that need to be acknowledged and addressed for representations to equitably encode gender information.},
    booktitle={EMNLP},
    selected = true,
    tweet={https://twitter.com/arjunsubgraph/status/1439965202783490056},
    poster_url={https://docs.google.com/presentation/d/e/2PACX-1vRY7megZAcAsPqs5MKzsEWTAEp2McDtkVFL4-4BCeLslwgZ6xosgncKCmZD4J3iQ6maK1ApszYS1311/pub?start=true&loop=true&delayms=60000&slide=id.p},
    keyword={fairrep},
    year={2021}
}
@inproceedings{parvez2021retrieval,
    title={Retrieval Augmented Code Generation and Summarization},
    author={Md Rizwan Parvez and Wasi Ahmad and Saikat Chakraborty and Baishakhi Ray and Md. Rizwan Parvez},
    rank = {21},
    abstract={Software developers write a lot of source code and documentation during software development. Intrinsically, developers often recall parts of source code or code summaries that they had written in the past while implementing software or documenting them. To mimic developers' code or summary generation behavior, we propose a retrieval augmented framework, \tool, that retrieves relevant code or summaries from a retrieval database and provides them as a supplement to code generation or summarization models. \tool has a couple of uniqueness. First, it extends the state-of-the-art dense retrieval technique to search for relevant code or summaries. Second, it can work with retrieval databases that include unimodal (only code or natural language description) or bimodal instances (code-description pairs). We conduct experiments and extensive analysis on two benchmark datasets of code generation and summarization in Java and Python, and the promising results endorse the effectiveness of our proposed retrieval augmented framework.},
    paper_url={https://arxiv.org/pdf/2108.11601.pdf},
    booktitle={EMNLP-Finding},
    presentation_time={FINDINGS PAPERS - GENERATION},
    presentation_id={https://underline.io/events/192/sessions/7923/lecture/38314-retrieval-augmented-code-generation-and-summarization},
    keyword={codelang},
    year={2021}
}


@inproceedings{arseniev2021aggression,
 title={Aggression, escalation, and other latent themes in legal intervention deaths of non-Hispanic Black and White men: Results from the 2003-2017 NVDRS},
 author={Arseniev-Koehler, Alina and Jacob Foster and Vickie Mays and Md. Rizwan Parvez and Susan Cochran},
 rank = {37},
 paper_url={https://ajph.aphapublications.org/doi/pdf/10.2105/AJPH.2021.306312},
 abstract={Objectives. To investigate racial/ethnic differences in legal intervention-related deaths using state-of-theart topic modeling of law enforcement and coroner text summaries drawn from the 2003-2017 US National Violent Death Reporting System (NVDRS). Methods. Employing advanced topic modeling, we identified 8 topics consistent with dangerousness in death incidents in the NVDRS death narratives written by public health workers (PHWs). Using logistic regression, we then evaluated racial/ethnic differences in PHW-coded variables and narrative topics among 4981 males killed by legal intervention, while adjusting for age, county-level characteristics, and year. Results. Black, as compared with White, decedents were younger and their deaths were less likely to include PHW-coded mental health or substance use histories, weapon use, or positive toxicology for alcohol or psychoactive drugs, but more likely to include gangs-as-an-incident-precipitant coding. Topic modeling revealed less frequent thematic representation of physical aggression or escalation but more of gangs or criminal networks among Black versus White decedents. Conclusions. While Black males were more likely to be victims of legal intervention deaths, PHW-coded variables in the NVDRS and death narratives suggest lower threat profiles among Black versus similar White decedents. The source of this greater risk remains undetermined.},
 booktitle={American Journal of Public Health},
 year={2021}
}

@inproceedings{ahmad2021syntax,
    title={Syntax-augmented Multilingual BERT for Cross-lingual Transfer},
    author={Wasi Ahmad and Haoran Li and Md. Rizwan Parvez and Yashar Mehdad},
    rank = {31},
    booktitle={ACL},
    youtube_id={G03p6oe_Lz0},
    code_url={https://github.com/wasiahmad/Syntax-MBERT},    
    abstract={In recent years, we have seen a colossal effort
in pre-training multilingual text encoders using large-scale corpora in many languages to
facilitate cross-lingual transfer learning. However, due to typological differences across languages, the cross-lingual transfer is challenging. Nevertheless, language syntax, e.g., syntactic dependencies, can bridge the typological gap. Previous works have shown that pretrained multilingual encoders, such as mBERT
(Devlin et al., 2019), capture language syntax, helping cross-lingual transfer. This work
shows that explicitly providing language syntax and training mBERT using an auxiliary
objective to encode the universal dependency
tree structure helps cross-lingual transfer. We
perform rigorous experiments on four NLP
tasks, including text classification, question answering, named entity recognition, and taskoriented semantic parsing. The experiment results show that syntax-augmented mBERT improves cross-lingual transfer on popular benchmarks, such as PAWS-X and MLQA, by 1.4
and 1.6 points on average across all languages.
In the generalized transfer setting, the performance boosted significantly, with 3.9 and 3.1
points on average in PAWS-X and MLQA.},
    paper_url={https://arxiv.org/pdf/2106.02134.pdf},
    keyword={crosslingual},
    year={2021}
}

@inproceedings{ahmad2021select,
    title={Select, Extract and Generate: Neural Keyphrase Generation with Layer-wise Coverage Attention},
    author={Wasi Ahmad and Xiao Bai and Soomin Lee and Md. Rizwan Parvez},
    paper_url={https://arxiv.org/abs/2008.01739},
    abstract={In recent years, deep neural sequence-to-sequence framework has demonstrated promising results in keyphrase generation. However, processing long documents using such deep neural networks requires high computational resources. To reduce the computational cost, the documents are typically truncated before given as inputs. As a result, the models may miss essential points conveyed in a document. Moreover, most of the existing methods are either extractive (identify important phrases from the document) or generative (generate phrases word by word), and hence they do not benefit from the advantages of both modeling techniques. To address these challenges, we propose \emph{SEG-Net}, a neural keyphrase generation model that is composed of two major components, (1) a selector that selects the salient sentences in a document, and (2) an extractor-generator that jointly extracts and generates keyphrases from the selected sentences. SEG-Net uses a self-attentive architecture, known as, \emph{Transformer} as the building block with a couple of uniqueness. First, SEG-Net incorporates a novel \emph{layer-wise} coverage attention to summarize most of the points discussed in the target document. Second, it uses an \emph{informed} copy attention mechanism to encourage focusing on different segments of the document during keyphrase extraction and generation. Besides, SEG-Net jointly learns keyphrase generation and their part-of-speech tag prediction, where the later provides syntactic supervision to the former. The experimental results on seven keyphrase generation benchmarks from scientific and web documents demonstrate that SEG-Net outperforms the state-of-the-art neural generative methods by a large margin in both domains.},
    rank = {31},
    booktitle={ACL},
keyword={keyphrase},
    year={2021}
}

@inproceedings{sheng2021societal,
    title={Societal Biases in Language Generation: Progress and Challenges},
    author={Emily Sheng and Md. Rizwan Parvez and Prem Natarajan and Nanyun Peng},
    rank = {31},
    abstract= {Technology for language generation has advanced rapidly, spurred by advancements in pre-training large models on massive amounts of data and the need for intelligent agents to communicate in a natural manner. While techniques can effectively generate fluent text, they can also produce undesirable societal biases that can have a disproportionately negative impact on marginalized populations. Language generation presents unique challenges for biases in terms of direct user interaction and the structure of decoding techniques. To better understand these challenges, we present a survey on societal biases in language generation, focusing on how data and techniques contribute to biases and progress towards reducing biases. Motivated by a lack of studies on biases from decoding techniques, we also conduct experiments to quantify the effects of these techniques. By further discussing general trends and open challenges, we call to attention promising directions for research and the importance of fairness and inclusivity considerations for language generation applications.},
    booktitle={ACL},
    keyword = {fairnlg},
    paper_url={https://arxiv.org/abs/2105.04054},
    tweet={https://twitter.com/ewsheng/status/1392175214591496194},
    year={2021}
}

@inproceedings{ahmad2021intent,
    title={Intent Classification and Slot Filling for Privacy Policies},
    author={Wasi Ahmad and Jianfeng Chi and Tu Le and Thomas Norton and Yuan Tian and Md. Rizwan Parvez},
    rank = {31},
    booktitle={ACL},
    code_url={https://github.com/wasiahmad/PolicyIE},
    paper_url={https://arxiv.org/abs/2101.00123},
    abstract={Understanding privacy policies is crucial for users as it empowers them to learn about the information that matters to them. Sentences written in a privacy policy document explain privacy practices, and the constituent text spans convey further specific information about that practice. We refer to predicting the privacy practice explained in a sentence as intent classification and identifying the text spans sharing specific information as slot filling. In this work, we propose PolicyIE, a corpus consisting of 5,250 intent and 11,788 slot annotations spanning 31 privacy policies of websites and mobile applications. PolicyIE corpus is a challenging benchmark with limited labeled examples reflecting the cost of collecting large-scale annotations. We present two alternative neural approaches as baselines: (1) formulating intent classification and slot filling as a joint sequence tagging and (2) modeling them as a sequence-to-sequence (Seq2Seq) learning task. Experiment results show that both approaches perform comparably in intent classification, while the Seq2Seq method outperforms the sequence tagging approach in slot filling by a large margin. Error analysis reveals the deficiency of the baseline approaches, suggesting room for improvement in future works. We hope the PolicyIE corpus will stimulate future research in this domain.},
    keyword = {ie},
    youtube_id={7oQbMqEiESE},
    year={2021}
}

@inproceedings{zhou2021defense,
    title={Defense against Synonym Substitution-based Adversarial Attacks via Dirichlet Neighborhood Ensemble},
    author={Yi Zhou and Xiaoqing Zheng and Cho-Jui Hsieh and Md. Rizwan Parvez and Xuanjing Huang},
    rank = {31},
    booktitle={ACL},
    keyword= {robustness},
    paper_url={https://arxiv.org/abs/2006.11627},
    code_url={https://github.com/dugu9sword/dne},
    abstract={Although deep neural networks have achieved prominent performance on many NLP tasks, they are vulnerable to adversarial examples. We propose Dirichlet Neighborhood Ensemble (DNE), a randomized method for training a robust model to defense synonym substitutionbased attacks. During training, DNE forms virtual sentences by sampling embedding vectors for each word in an input sentence from a convex hull spanned by the word and its synonyms, and it augments them with the training data. In such a way, the model is robust to adversarial attacks while maintaining the performance on the original clean data. DNE is agnostic to the network architectures and scales to large models (e.g., BERT) for NLP applications. Through extensive experimentation, we demonstrate that our method consistently outperforms recently proposed defense methods by a significant margin across different network architectures and multiple data sets.},
    year={2021}
}

@inproceedings{pruksachatkun2021robustness,
    title={Does Robustness Improve Fairness? Approaching Fairness with Word Substitution Robustness Methods for Text Classification},
    author={Yada Pruksachatkun and Satyapriya Krishna and Jwala Dhamala and Rahul Gupta and Md. Rizwan Parvez},
    rank = {33},
    booktitle={ACL-Finding},
    keyword = {fairnlp},
    code_url = {https://github.com/allenai/ethical-interventions},
    abstract={Existing bias mitigation methods to reduce disparities in model outcomes across cohorts have focused on data augmentation, debiasing model embeddings, or adding fairness-based optimization objectives during training. Separately, certified word substitution robustness methods have been developed to decrease the impact of spurious features and synonym substitutions on model predictions. While their end goals are different, they both aim to encourage models to make the same prediction for certain changes in the input. In this paper, we investigate the utility of certified word substitution robustness methods to improve equality of odds and equality of opportunity on multiple text classification tasks. We observe that certified robustness methods improve fairness, and using both robustness and bias mitigation methods in training results in an improvement in both fronts.},
    paper_url={https://www.amazon.science/publications/does-robustness-improve-fairness-approaching-fairness-with-word-substitution-robustness-methods-for-text-classification},
    year={2021}
}

@inproceedings{zhao2021ethical,
    title={Ethical-Advice Taker: Do Language Models Understand Natural Language Interventions?},
    author={Jieyu Zhao and Daniel Khashabi and Tushar Khot and Ashish Sabharwal and Md. Rizwan Parvez},
    rank = {33},
    booktitle={ACL-Finding (short)},
    paper_url={https://arxiv.org/abs/2106.01465},
    tweet={https://twitter.com/jieyuzhao11/status/1401041612621312000}, 
    abstract={Is it possible to use natural language to intervene in a model's behavior and alter its prediction in a desired way? We investigate the effectiveness of natural language interventions for reading-comprehension systems, studying this in the context of social stereotypes. Specifically, we propose a new language understanding task, Linguistic Ethical Interventions (LEI), where the goal is to amend a question-answering (QA) model's unethical behavior by communicating context-specific principles of ethics and equity to it. To this end, we build upon recent methods for quantifying a system's social stereotypes, augmenting them with different kinds of ethical interventions and the desired model behavior under such interventions. Our zero-shot evaluation finds that even today's powerful neural language models are extremely poor ethical-advice takers, that is, they respond surprisingly little to ethical interventions even though these interventions are stated as simple sentences. Few-shot learning improves model behavior but remains far from the desired outcome, especially when evaluated for various types of generalization. Our new task thus poses a novel language understanding challenge for the community.},
    year={2021}
}


@inproceedings{uppunda2021adapting,
title  = {Adapting Coreference Resolution for Processing Violent Death Narratives},
author = {Ankith Uppunda and Susan Cochran and Jacob Foster and Alina Arseniev-Koehler and Vickie Mays and Md. Rizwan Parvez},
rank = {41},
tweet={https://twitter.com/kaiwei_chang/status/1401237542280654848},
paper_url={https://arxiv.org/abs/2104.14703},
video_url={https://underline.io/lecture/19662-adapting-coreference-resolution-for-processing-violent-death-narratives},
abstract={Coreference resolution is an important component in analyzing narrative text from administrative data (e.g., clinical or police sources). However, existing coreference models trained on general language corpora suffer from poor transferability due to domain gaps, especially when they are applied to gender-inclusive data with lesbian, gay, bisexual, and transgender (LGBT) individuals. In this paper, we analyzed the challenges of coreference resolution in an exemplary form of administrative text written in English: violent death narratives from the USA's Centers for Disease Control's (CDC) National Violent Death Reporting System. We developed a set of data augmentation rules to improve model performance using a probabilistic data programming framework. Experiments on narratives from an administrative database, as well as existing gender-inclusive coreference datasets, demonstrate the effectiveness of data augmentation in training coreference models that can better handle text data about LGBT individuals.},
booktitle={NAACL (short)},
presentation_time={13A-Oral: NLP Applications},
presentation_id={https://underline.io/events/122/sessions/4249/lecture/19662-adapting-coreference-resolution-for-processing-violent-death-narratives},
year = {2021}
}

@inproceedings {parvez2021evaluating,
title = {Evaluating the Values of Sources in Transfer Learning},
author = {Md Rizwan Parvez and Md. Rizwan Parvez},
booktitle={NAACL},
keyword={crosslingual},
video_url={https://underline.io/lecture/19707-evaluating-the-values-of-sources-in-transfer-learning},
code_url={https://github.com/rizwan09/NLPDV},
paper_url={https://arxiv.org/abs/2104.12567},
presentation_time={14C-ORAL: INTERPRETABILITY AND ANALYSIS OF MODELS FOR NLP},
presentation_id={https://underline.io/events/122/sessions/4261/lecture/19707-evaluating-the-values-of-sources-in-transfer-learning},
tweet={https://twitter.com/kaiwei_chang/status/1401203077047259139},
abstract={Transfer learning that adapts a model trained on data-rich sources to low-resource targets has been widely applied in natural language processing (NLP). However, when training a transfer model over multiple sources, not every source is equally useful for the target. To better transfer a model, it is essential to understand the values of the sources. In this paper, we develop SEAL-Shap, an efficient source valuation framework for quantifying the usefulness of the sources (e.g., domains/languages) in transfer learning based on the Shapley value method. Experiments and comprehensive analyses on both cross-domain and cross-lingual transfers demonstrate that our framework is not only effective in choosing useful transfer sources but also the source values match the intuitive source-target similarity.},
rank = {40}, 
year = {2021}
}
@inproceedings {huang2021disentangling,
title = {Disentangling Semantics and Syntax in Sentence Embeddings with Pre-trained Language Models},
author = {James Y. Huang and Kuan-Hao Huang and Md. Rizwan Parvez},
booktitle={NAACL (short)},
abstract = {Pre-trained language models have achieved huge success on a wide range of NLP tasks. However, contextual representations from pre-trained models contain entangled semantic and syntactic information, and therefore cannot be directly used to derive useful semantic sentence embeddings for some tasks. Paraphrase pairs offer an effective way of learning the distinction between semantics and syntax, as they naturally share semantics and often vary in syntax. In this work, we present ParaBART, a semantic sentence embedding model that learns to disentangle semantics and syntax in sentence embeddings obtained by pre-trained language models. ParaBART is trained to perform syntax-guided paraphrasing, based on a source sentence that shares semantics with the target paraphrase, and a parse tree that specifies the target syntax. In this way, ParaBART learns disentangled semantic and syntactic representations from their respective inputs with separate encoders. Experiments in English show that ParaBART outperforms state-of-the-art sentence embedding models on unsupervised semantic similarity tasks. Additionally, we show that our approach can effectively remove syntactic information from semantic sentence embeddings, leading to better robustness against syntactic variation on downstream semantic tasks.},
paper_url={https://arxiv.org/pdf/2104.05115.pdf},
tweet={https://twitter.com/kuanhao_/status/1382494068547022852},
code_url={https://github.com/uclanlp/ParaBART},
video_url={https://underline.io/lecture/19910-disentangling-semantics-and-syntax-in-sentence-embeddings-with-pre-trained-language-models},
rank = {41},
presentation_time={4C-ORAL: SEMANTICS: SENTENCE-LEVEL SEMANTICS AND TEXTUAL INFERENCE},
presentation_id={https://underline.io/events/122/sessions/4151/lecture/19910-disentangling-semantics-and-syntax-in-sentence-embeddings-with-pre-trained-language-models},
year = {2021}   
}

@inproceedings {ahmad2021unified,
title = {Unified Pre-training for Program Understanding and Generation},
author = {Wasi Ahmad and Saikat Chakraborty and Baishakhi Ray and Md. Rizwan Parvez},
paper_url={https://arxiv.org/pdf/2103.06333.pdf},
video_url={https://underline.io/lecture/20024-unified-pre-training-for-program-understanding-and-generation},
keynote_url = {https://www.paperdigest.org/2023/04/most-influential-naacl-papers-2023-04/}, 
keynote = {Top-10 cited paper at NAACL 21},
abstract={Code summarization nd generation empower conversion between programming language (PL) and natural language (NL), while code translation avails the migration of legacy code from one PL to another. This paper introduces PLBART, a sequence-to-sequence model capable of performing a broad spectrum of program and language understanding and generation tasks. PLBART is pre-trained on an extensive collection of Java and Python functions and associated NL text via denoising autoencoding. Experiments on code summarization in the English language, code generation, and code translation in seven programming languages show that PLBART outperforms or rivals state-of-the-art models. Moreover, experiments on discriminative tasks, e.g., program repair, clone detection, and vulnerable code detection, demonstrate PLBART's effectiveness in program understanding. Furthermore, analysis reveals that PLBART learns program syntax, style (e.g., identifier naming convention), logical flow (e.g., if block inside an else block is equivalent to else if block) that are crucial to program semantics and thus excels even with limited annotations.},
booktitle={NAACL},
presentation_time={8A-ORAL: MACHINE LEARNING FOR NLP: LANGUAGE MODELING AND SEQUENCE TO SEQUENCE MODELS},
presentation_id={https://underline.io/events/122/sessions/4197/lecture/20024-unified-pre-training-for-program-understanding-and-generation},
code_url={https://github.com/wasiahmad/PLBART},
keyword = {codelang},
rank = {40},
tweet={https://twitter.com/baishakhir/status/1370559112950468609},
year = {2021}
}
        
@inproceedings {sheng2021nice,
title = {"Nice Try, Kiddo": Investigating Ad Hominems in Dialogue Responses},
booktitle={NAACL},
author = {	Emily Sheng and Md. Rizwan Parvez and Prem Natarajan and Nanyun Peng},
abstract={Ad hominem attacks are those that target some feature of a person's character instead of the position the person is maintaining. These attacks are harmful because they propagate implicit biases and diminish a person's credibility. Since dialogue systems respond directly to user input, it is important to study ad hominems in dialogue responses. To this end, we propose categories of ad hominems, compose an annotated dataset, and build a classifier to analyze human and dialogue system responses to English Twitter posts. We specifically compare responses to Twitter topics about marginalized communities (#BlackLivesMatter, #MeToo) versus other topics (#Vegan, #WFH), because the abusive language of ad hominems could further amplify the skew of power away from marginalized populations. Furthermore, we propose a constrained decoding technique that uses salient n-gram similarity as a soft constraint for top-k sampling to reduce the amount of ad hominems generated. Our results indicate that 1) responses from both humans and DialoGPT contain more ad hominems for discussions around marginalized communities, 2) different quantities of ad hominems in the training data can influence the likelihood of generating ad hominems, and 3) we can use constrained decoding techniques to reduce ad hominems in generated dialogue responses.},
presentation_time={3A-ORAL: DIALOGUE AND INTERACTIVE SYSTEMS},
presentation_id={https://underline.io/events/122/sessions/4137/lecture/19854-%27nice-try,-kiddo%27-investigating-ad-hominems-in-dialogue-responses},
code_url={https://github.com/ewsheng/ad-hom-in-dialogue},
video_url={https://underline.io/lecture/19854-%27nice-try,-kiddo%27-investigating-ad-hominems-in-dialogue-responses},
paper_url={https://arxiv.org/abs/2010.12820},
rank = {40},
tweet={https://twitter.com/ewsheng/status/1382417367116902402},
keyword = {fairnlg},
year = {2021}
}

@inproceedings{zhang2021double,
    title= {	Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation},
    booktitle = {NAACL},
    author = {Chong Zhang and  Jieyu Zhao and  Huan Zhang and  Md. Rizwan Parvez and Cho-Jui Hsieh},
    rank = {40},
    year = {2021},
presentation_time={11B-ORAL: INTERPRETABILITY AND ANALYSIS OF MODELS FOR NLP},
presentation_id={https://underline.io/events/122/sessions/4229/lecture/19609-double-perturbation-on-the-robustness-of-robustness-and-counterfactual-bias-evaluation},
    tweet={https://twitter.com/jieyuzhao11/status/1401040925783052289},
    video_url={https://underline.io/lecture/19609-double-perturbation-on-the-robustness-of-robustness-and-counterfactual-bias-evaluation},
    paper_url={https://arxiv.org/pdf/2104.05232.pdf},
    code_url={https://github.com/chong-z/nlp-second-order-attack},
    abstract={Robustness and counterfactual bias are usually evaluated on a test dataset. However, are these evaluations robust? If the test dataset is perturbed slightly, will the evaluation results keep the same? In this paper, we propose a "double perturbation" framework to uncover model weaknesses beyond the test dataset. The framework first perturbs the test dataset to construct abundant natural sentences similar to the test data, and then diagnoses the prediction change regarding a single-word substitution. We apply this framework to study two perturbation-based approaches that are used to analyze models' robustness and counterfactual bias in English. (1) For robustness, we focus on synonym substitutions and identify vulnerable examples where prediction can be altered. Our proposed attack attains high success rates (96.0%-99.8%) in finding vulnerable examples on both original and robustly trained CNNs and Transformers. (2) For counterfactual bias, we focus on substituting demographic tokens (e.g., gender, race) and measure the shift of the expected prediction among constructed sentences. Our method is able to reveal the hidden model biases not directly shown in the test dataset.},
    keyword= {robustness}
}

@inproceedings{li2021unsupervised,
author = {Liunian Harold Li and Haoxuan You and Zhecan Wang and Alireza Zareian and Shih-Fu Chang and Md. Rizwan Parvez}, 
       title = {Unsupervised Vision-and-Language Pre-training Without Parallel Images and Captions},
       booktitle = {NAACL},
       abstract = {Pre-trained contextual vision-and-language (V&L) models have brought impressive performance improvement on various benchmarks. However, the paired text-image data required for pre-training are hard to collect and scale up. We investigate if a strong V&L representation model can be learned without text-image pairs. We propose Weakly-supervised VisualBERT with the key idea of conducting "mask-and-predict" pre-training on language-only and image-only corpora. Additionally, we introduce the object tags detected by an object recognition model as anchor points to bridge two modalities. Evaluation on four V&L benchmarks shows that Weakly-supervised VisualBERT achieves similar performance with a model pre-trained with paired data. Besides, pre-training on more image-only data further improves a model that already has access to aligned data, suggesting the possibility of utilizing billions of raw images available to enhance V&L models.},
presentation_time={15A-ORAL: LANGUAGE GROUNDING TO VISION, ROBOTICS AND BEYOND},
presentation_id={https://underline.io/events/122/sessions/4269/lecture/19725-unsupervised-vision-and-language-pre-training-without-parallel-images-and-captions},
       rank = {40},
       tweet={https://twitter.com/LiLiunian/status/1383070255304495107},
       video_url = {https://underline.io/lecture/19725-unsupervised-vision-and-language-pre-training-without-parallel-images-and-captions},
       paper_url = {https://arxiv.org/abs/2010.12831},
       year = {2021}, 
       keyword = {multirep}
}

@inproceedings{meng2020integer,
author = {Tao Meng and Md. Rizwan Parvez},
title = {An Integer Linear Programming Framework for Mining Constraints from Data},
booktitle = {ICML}, 
abstract = {Various structured output prediction problems (e.g., sequential tagging) involve constraints over the output space. By identifying these constraints, we can filter out infeasible solutions and build an accountable model.
To this end, we present a general integer linear programming (ILP) framework for mining constraints from data. We model the inference of structured output prediction as an ILP problem. Then, given the coefficients of the objective function and the corresponding solution, we mine the underlying constraints by estimating the outer and inner polytopes of the feasible set. We verify the proposed constraint mining algorithm in various synthetic and real-world applications and demonstrate that the proposed approach successfully identifies the feasible set at scale.
In particular, we show that our approach can learn to solve 9x9 Sudoku puzzles and minimal spanning tree problems from examples without providing the underlying rules. We also demonstrate results on hierarchical multi-label classification and conduct a theoretical analysis on how close the mined constraints are from the ground truth.},
rank = {30},
youtube_id={8KUwOKaQ8Uw},
tweet={https://twitter.com/TaoMeng10/status/1405567807303995396},
code_url={https://github.com/uclanlp/ILPLearning},
paper_url = {https://arxiv.org/pdf/2006.10836.pdf},
year = {2021},
keyword={lwll}
}



@inproceedings{dhamala2021bold,
author = { Jwala Dhamala and Tony Sun and Varun Kumar and Satyapriya Krishna and Yada Pruksachatkun and Md. Rizwan Parvez and Rahul Gupta},
title = {BOLD: Dataset and metrics for measuring biases in open-ended language generation},
booktitle = {FAccT},
rank = {48},
year = {2021},
code_url={https://github.com/amazon-research/bold},
tweet={https://twitter.com/AmazonScience/status/1374728699510161418},
abstract= {Recent advances in deep learning techniques have enabled machines to generate cohesive open-ended text when prompted with a sequence of words as context. While these models now empower many downstream applications from conversation bots to automatic storytelling, they have been shown to generate texts that exhibit social biases. To systematically study and benchmark social biases in open-ended language generation, we introduce the Bias in Open-Ended Language Generation Dataset (BOLD), a large-scale dataset that consists of 23,679 English text generation prompts for bias benchmarking across five domains: profession, gender, race, religion, and political ideology. We also propose new automated metrics for toxicity, psycholinguistic norms, and text gender polarity to measure social biases in open-ended text generation from multiple angles. An examination of text generated from three popular language models reveals that the majority of these models exhibit a larger social bias than human-written Wikipedia text across all domains. With these results we highlight the need to benchmark biases in open-ended language generation and caution users of language generation models on downstream tasks to be cognizant of these embedded prejudices.},
paper_url={https://www.amazon.science/publications/bold-dataset-and-metrics-for-measuring-biases-in-open-ended-language-generation},
keyword = {fairnlg}
}

@inproceedings{huang2021generating,
author = {Kuan-Hao Huang and Md. Rizwan Parvez},
title = {Generating Syntactically Controlled Paraphrases without Using Annotated Parallel Pairs},
booktitle = {EACL},
rank = {49}, 
year = {2021},
code_url={https://github.com/uclanlp/synpg},
slides_url={https://khhuang.me/docs/eacl2021synpg_handout.pdf},
poster_url={https://khhuang.me/docs/eacl2021synpg_poster.pdf},
paper_url={https://arxiv.org/pdf/2101.10579.pdf},
tweet={https://twitter.com/kaiwei_chang/status/1359578833091874816},
abstract={Paraphrase generation plays an essential role in natural language process (NLP), and it has many downstream applications. However, training supervised paraphrase models requires many annotated paraphrase pairs, which are usually costly to obtain. On the other hand, the paraphrases generated by existing unsupervised approaches are usually syntactically similar to the source sentences and are limited in diversity. In this paper, we demonstrate that it is possible to generate syntactically various paraphrases without the need for annotated paraphrase pairs. We propose Syntactically controlled Paraphrase Generator (SynPG), an encoder-decoder based model that learns to disentangle the semantics and the syntax of a sentence from a collection of unannotated texts. The disentanglement enables SynPG to control the syntax of output paraphrases by manipulating the embedding in the syntactic space. Extensive experiments using automatic metrics and human evaluation show that SynPG performs better syntactic control than unsupervised baselines, while the quality of the generated paraphrases is competitive. We also demonstrate that the performance of SynPG is competitive or even better than supervised models when the unannotated data is large. Finally, we show that the syntactically controlled paraphrases generated by SynPG can be utilized for data augmentation to improve the robustness of NLP models.},
keyword = {lwll}
}


@inproceedings{zhou2021clinical,
author = {Yichao Zhou and Yu Yan  and Rujun Han and J. Harry Caufield and Md. Rizwan Parvez  and Yizhou Sun  and Peipei Ping and Wei Wang},
title = "Clinical Temporal Relation Extraction with Probabilistic Soft Logic Regularization and Global Inference",
booktitle = {AAAI},
code_url={https://github.com/yuyanislearning/CTRL-PG},
abstract = {There  has  been  a  steady  need  in  the  medical  community to  precisely  extract  the  temporal  relations  between  clinical events. In particular, temporal information can facilitate a variety of downstream applications such as case report retrieval and medical question answering. However, existing methods either require expensive feature engineering or are incapable of  modeling  the  global  relational  dependencies  among  theevents. In this paper, we propose Clinical Temporal Relation Exaction  with  Probabilistic  Soft  Logic  Regularization  and Global Inference (CTRL-PG), a novel method to tackle the problem at the document level. Extensive experiments on two benchmark datasets, I2B2-2012 and TB-Dense, demonstrate that CTRL-PG significantly  outperforms  baseline  methodsfor temporal relation extraction.},
paper_url={https://arxiv.org/pdf/2012.08790.pdf},
rank = {50}, 
year = {2021},
keyword={lwll}
}


@inproceedings{ahmad2021gate,
author = {Wasi Ahmad and Nanyun Peng and Md. Rizwan Parvez},
title = "GATE: Graph Attention Transformer Encoder for Cross-lingual Relation and Event Extraction",
booktitle = {AAAI}, 
tweet={https://twitter.com/kaiwei_chang/status/1357272065963745280},
code_url={https://github.com/wasiahmad/GATE},
paper_url={https://arxiv.org/abs/2010.03009},
abstract={Prevalent approaches in cross-lingual relation and event extraction use graph convolutional networks (GCNs) with universal dependency parses to learn language-agnostic representations such that models trained on one language can be applied to other languages. However, GCNs lack in modeling long-range dependencies or disconnected words in the dependency tree. To address this challenge, we propose to utilize the self-attention mechanism where we explicitly fuse structural information to learn the dependencies between words at different syntactic distances. We introduce GATE, a {\bf G}raph {\bf A}ttention {\bf T}ransformer {\bf E}ncoder, and test its cross-lingual transferability on relation and event extraction tasks. We perform rigorous experiments on the widely used ACE05 dataset that includes three typologically different languages: English, Chinese, and Arabic. The evaluation results show that GATE outperforms three recently proposed methods by a large margin. Our detailed analysis reveals that due to the reliance on syntactic dependencies, GATE produces robust representations that facilitate transfer across languages.},
rank = {50}, 
year = {2021},
keyword={crosslingual}
}

@inproceedings{xu2020provable,
author = {Kaidi Xu and Zhouxing Shi and Huan Zhang and Yihan Wang and Md. Rizwan Parvez and Minlie Huang and Bhavya Kailkhura and Xue Lin and Cho-Jui Hsieh},
title = "Provable, Scalable and Automatic Perturbation Analysis on General Computational Graphs",
booktitle = {NeurIPS}, 
code_url={https://github.com/KaidiXu/auto_LiRPA},
paper_url={https://arxiv.org/abs/2002.12920},
abstract = {Linear relaxation based perturbation analysis (LiRPA) for neural networks, which computes provable linear bounds of output neurons given a certain amount of input perturbation, has become a core component in robustness verification and certified defense. The majority of LiRPA-based methods only consider simple feed-forward networks and it needs particular manual derivations and implementations when extended to other architectures. In this paper, we develop an automatic framework to enable perturbation analysis on any neural network structures, by generalizing exiting LiRPA algorithms such as CROWN to operate on general computational graphs. The flexibility, differentiability and ease of use of our framework allow us to obtain state-of-the-art results on LiRPA based certified defense on fairly complicated networks like DenseNet, ResNeXt and Transformer that are not supported by prior work. Our framework also enables loss fusion, a technique that significantly reduces the computational complexity of LiRPA for certified defense. For the first time, we demonstrate LiRPA based certified defense on Tiny ImageNet and Downscaled ImageNet where previous approaches cannot scale to due to the relatively large number of classes. Our work also yields an open-source library for the community to apply LiRPA to areas beyond certified defense without much LiRPA expertise, e.g., we create a neural network with a provably flat optimization landscape. Our open source library is available at https://github.com/KaidiXu/auto_LiRPA},
rank = {19}, 
year = {2020},
keyword={robustness}
}



@inproceedings{zhao2020logan,
author = {Jieyu Zhao and Md. Rizwan Parvez},
title = "LOGAN: Local Group Bias Detection by Clustering",
abstract={Machine learning techniques have been widely used in natural language processing (NLP). However, as revealed by many recent studies, machine learning models often inherit and amplify the societal biases in data. Various metrics have been proposed to quantify biases in model predictions. In particular, several of them evaluate disparity in model performance between protected groups and advantaged groups in the test corpus. However, we argue that evaluating bias at the corpus level is not enough for understanding how biases are embedded in a model. In fact, a model with similar aggregated performance between different groups on the entire data may behave differently on instances in a local region. To analyze and detect such local bias, we propose LOGAN, a new bias detection technique based on clustering. Experiments on toxicity classification and object classification tasks show that LOGAN identifies bias in a local region and allows us to better analyze the biases in model predictions.},
booktitle = {EMNLP (short)}, 
paper_url={https://arxiv.org/pdf/2010.02867.pdf},
rank = {20},
presentation_time={Gather-1I: Nov 17, 02:00-04:00 UTC / 18:00-20:00 PST -1d },
presentation_id={https://virtual.2020.emnlp.org/paper_main.2886.html},
tweet={https://twitter.com/jieyuzhao11/status/1328403679091650560},
code_url={https://github.com/uclanlp/clusters},
year = {2020},
keyword={fairnlp}
}


@inproceedings{sheng2020towards,
  title = {Towards Controllable Biases in Language Generation},
  author = {Sheng, Emily and Chang, Kai-Wei and Natarajan, Premkumar and Peng, Nanyun},
  booktitle = {EMNLP-Finding},
  abstract={We present a general approach towards controllable societal biases in natural language generation (NLG). Building upon the idea of adversarial triggers, we develop a method to induce societal biases in generated text when input prompts contain mentions of specific demographic groups. We then analyze two scenarios: 1) inducing negative biases for one demographic and positive biases for another demographic, and 2) equalizing biases between demographics. The former scenario enables us to detect the types of biases present in the model. Specifically, we show the effectiveness of our approach at facilitating bias analysis by finding topics that correspond to demographic inequalities in generated text and comparing the relative effectiveness of inducing biases for different demographics. The second scenario is useful for mitigating biases in downstream applications such as dialogue generation. In our experiments, the mitigation technique proves to be effective at equalizing the amount of biases across demographics while simultaneously generating less negatively biased text overall.},
  rank = {23},
  paper_url={https://arxiv.org/abs/2005.00268}, 
      tweet={https://twitter.com/ewsheng/status/1314260689901424640},
  year = {2020},
  code_url={https://github.com/ewsheng/controllable-nlg-biases},
  keyword={fairnlg}
}



@inproceedings{liu2020cross-lingual,
author = {Lu Liu and Yi Zhou and Jianhan Xu and Xiaoqing Zheng and Md. Rizwan Parvez and Xuanjing Huang},
title = "Cross-Lingual Dependency Parsing by POS-Guided Word Reordering",
abstract={We propose a novel approach to cross-lingual dependency parsing based on word reordering. The words in each sentence of a source language corpus are rearranged to meet the word order in a target language under the guidance of a part-of-speech based language model (LM). To obtain the highest reordering score under the LM, a population-based optimization algorithm and its genetic operators are designed to deal with the combinatorial nature of such word reordering. A parser trained on the reordered corpus then can be used to parse sentences in the target language. We demonstrate through extensive experimentation that our approach achieves better or comparable results across 25 target languages (1.73% increase in average), and outperforms a baseline by a significant margin on the languages that are greatly different from the source one. For example, when transferring the English parser to Hindi and Latin, our approach outperforms the baseline by 15.3% and 6.7% respectively.},
booktitle = {EMNLP-Finding}, 
rank = {23},
paper_url={https://www.aclweb.org/anthology/2020.findings-emnlp.265.pdf},
year = {2020},
keyword={crosslingual}
}



@inproceedings{ahmad2020policyqa,
author = {Wasi Ahmad and Jianfeng Chi and Yuan Tian and Md. Rizwan Parvez},
title = "PolicyQA: A Reading Comprehension Dataset for Privacy Policies",
booktitle = {EMNLP-Finding (short)}, 
abstract={Privacy policy documents are long and verbose. A question answering (QA) system can assist users in finding the information that is relevant and important to them. Prior studies in this domain frame the QA task as retrieving the most relevant text segment or a list of sentences from the policy document given a question. On the contrary, we argue that providing users with a short text span from policy documents reduces the burden of searching the target information from a lengthy text segment. In this paper, we present PolicyQA, a dataset that contains 25,017 reading comprehension style examples curated from an existing corpus of 115 website privacy policies. PolicyQA provides 714 human-annotated questions written for a wide range of privacy practices. We evaluate two existing neural QA models and perform rigorous analysis to reveal the advantages and challenges offered by PolicyQA.},
paper_url={https://arxiv.org/abs/2010.02557},
rank = {23}, 
year = {2020},
code_url={https://github.com/wasiahmad/PolicyQA},
keyword={lwll}
}


@inproceedings{huang2020generating,
author = {Kuan-Hao Huang and Chen Li and Md. Rizwan Parvez},
title = "Generating Sports News from Live Commentary: A Chinese Dataset for Sports Game Summarization",
booktitle = {AACL (short)}, 
paper_url={https://khhuang.me/docs/aacl2020sportssum.pdf},
rank = {24}, 
year = {2020},
}



@inproceedings{hu2020gptgnn,
author = {Ziniu Hu and Yuxiao Dong and Kuansan Wang and Md. Rizwan Parvez and Yizhou Sun},
title = "GPT-GNN: Generative Pre-Training of Graph Neural Networks",
booktitle = {KDD},
 keynote_url = {https://www.paperdigest.org/2023/04/most-influential-kdd-papers-2023-04/}, 
keynote = {Top-10 cited paper at KDD 20},
abstract = {Graph neural networks (GNNs) have been demonstrated to besuccessful in modeling graph-structured data. However, training GNNs requires abundant task-specific labeled data, which is often arduously expensive to obtain. One effective way to reduce labeling effort is to pre-train an expressive GNN model on unlabelled data with self-supervision and then transfer the learned knowledge to downstream models. In this paper, we present the GPT-GNN's framework to initialize GNNs by generative pre-training. GPT-GNN introduces a self-supervised attributed graph generation task to pre-train a GNN,which allows the GNN to capture the intrinsic structural and semantic properties of the graph. We factorize the likelihood of graph generation into two components: 1) attribute generation, and 2) edgegeneration. By modeling both components, GPT-GNN captures the inherent dependency between node attributes and graph structure during the generative process. Comprehensive experiments on thebillion-scale academic graph and Amazon recommendation data demonstrate that GPT-GNN significantly outperforms state-of-the-art base GNN models without pre-training by up to 9.1% across different downstream tasks.},
paper_url={https://arxiv.org/pdf/2006.15437.pdf},
code_url={https://github.com/acbull/GPT-GNN},
youtube_id={YkLo1JhVdIc},
slide_url={https://acbull.github.io/pdf/gpt.pptx},
rank = {30}, 
year = {2020},
keyword={lwll}
}



@inproceedings{yin2020sentibert,
author = {Da Yin and Tao Meng and Md. Rizwan Parvez},
title = "SentiBERT: A Transferable Transformer-Based Architecture for Compositional Sentiment Semantics",
booktitle = {ACL}, 
abstract = {We propose SentiBERT, a variant of BERT that effectively captures compositional sentiment semantics. The model incorporates contextualized representation with binary constituency parse tree to capture semantic composition. Comprehensive experiments demonstrate that SentiBERT achieves competitive performance on phrase-level sentiment classification. We further demonstrate that the sentiment composition learned from the phrase-level annotations on SST can be transferred to other sentiment analysis tasks as well as related tasks, such as emotion classification tasks. Moreover, we conduct ablation studies and design visualization methods to understand SentiBERT. We show that SentiBERT is better than baseline approaches in capturing negation and the contrastive relation and model the compositional sentiment semantics.},
rank = {38},
youtube_id={XJ80BqguiAE},
year = {2020},
slides_url={http://kwchang.net/documents/slides/yin2020sentibert_slide.pdf},
paper_url={https://arxiv.org/pdf/2005.04114.pdf},
presentation_time={6B Sentiment Analysis, 8A Sentiment Analysis},
presentation_id={https://virtual.acl2020.org/paper_main.341.html},
code_url={https://github.com/WadeYin9712/SentiBERT},
keyword={lwll},
}


@inproceedings{yin2020robustness,
author = {Fan Yin and Quanyu Long and Tao Meng and Md. Rizwan Parvez},
title = {On the Robustness of Language Encoders against Grammatical Errors},
booktitle = {ACL}, 
abstract = {We conduct a thorough study to diagnose the behaviors of pre-trained language encoders (ELMo, BERT, and RoBERTa) when confronted with natural grammatical errors. Specifically, we collect real grammatical errors from non-native speakers and conduct adversarial attacks to simulate these errors on clean text data. We use this approach to facilitate debugging models on downstream applications. Results confirm that the performance of all tested models is affected but the degree of impact varies. To interpret model behaviors, we further design a linguistic acceptability task to reveal their abilities in identifying ungrammatical sentences and the position of errors. We find that fixed contextual encoders with a simple classifier trained on the prediction of sentence correctness are able to locate error positions. We also design a cloze test for BERT and discover that BERT captures the interaction between errors and specific tokens in context. Our results shed light on understanding the robustness and behaviors of language encoders against grammatical errors.},
paper_url={https://arxiv.org/pdf/2005.05683.pdf},
tweet={https://twitter.com/kaiwei_chang/status/1271126822797709313},
youtube_id={Q5L8lCLOEHY},
rank = {37}, 
presentation_time={6B Interpretability, 8A Interpretability},
presentation_id={https://virtual.acl2020.org/paper_main.310.html},
slides_url={http://kwchang.net/documents/slides/yin2020robustness_slide.pdf},
code_url={https://github.com/uclanlp/ProbeGrammarRobustness},
year = {2020},
keyword={robustness},
}

@inproceedings{zhou2020boating,
author = {Yichao Zhou and  Jyun-Yu Jiang and  Jieyu Zhao and  Md. Rizwan Parvez and Wei Wang}, 
title = {"The Boating Store Had Its Best Sail Ever": Pronunciation-attentive Contextualized Pun Recognition}, 
booktitle = {ACL}, 
abstract = {Humor plays an important role in human languages and it is essential to model humor when building intelligence systems. Among different forms of humor, puns perform wordplay for humorous effects by employing words with double entendre and high phonetic similarity. However, identifying and modeling puns are challenging as puns usually involved implicit semantic or phonological tricks. In this paper, we propose Pronunciation-attentive Contextualized Pun Recognition (PCPR) to perceive human humor, detect if a sentence contains puns and locate them in the sentence. PCPR derives contextualized representation for each word in a sentence by capturing the association between the surrounding context and its corresponding phonetic symbols. Extensive experiments are conducted on two benchmark datasets. Results demonstrate that the proposed approach significantly outperforms the state-of-the-art methods in pun detection and location tasks. In-depth analyses verify the effectiveness and robustness of PCPR.},
paper_url={https://arxiv.org/pdf/2004.14457.pdf},
rank = {39},
youtube_id={x8v8D-x2cvo},
slides_url={http://kwchang.net/documents/slides/zhou2020boating_slide.pdf},
presentation_id={https://virtual.acl2020.org/paper_main.75.html},
code_url={https://github.com/joey1993/pun-recognition},
presentation_time={1B Application, 5B Application},
year = {2020},
keyword={humor}
}


@inproceedings{zhao2020gender,
author = {Jieyu Zhao and Subhabrata Mukherjee and Saghar Hosseini and Md. Rizwan Parvez and Ahmed Hassan Awadallah},
title = {Gender Bias in Multilingual Embeddings and Cross-Lingual Transfer},
booktitle = {ACL}, 
abstract = {Multilingual representations embed words from many languages into a single semantic space such that words with similar meanings are close to each other regardless of the language. These embeddings have been widely used in various settings, such as cross-lingual transfer, where a natural language processing (NLP) model trained on one language is deployed to another language. While the cross-lingual transfer techniques are powerful, they carry gender bias from the source to target languages. In this paper, we study gender bias in multilingual embeddings and how it affects transfer learning for NLP applications. We create a multilingual dataset for bias analysis and propose several ways for quantifying bias in multilingual representations from both the intrinsic and extrinsic perspectives. Experimental results show that the magnitude of bias in the multilingual representations changes differently when we align the embeddings to different target spaces and that the alignment direction can also have an influence on the bias in transfer learning. We further provide recommendations for using the multilingual word representations for downstream tasks.}, 
youtube_id={JZwMIwf1eZM},
presentation_time={6A Ethics, 10B Ethics},
rank = {37}, 
year = {2020},
presentation_id={https://virtual.acl2020.org/paper_main.260.html},
slides_url={http://kwchang.net/documents/slides/zhao2020gender_slide.pdf},
paper_url={https://arxiv.org/pdf/2005.00699.pdf},
tweet={https://twitter.com/jieyuzhao11/status/1258268537916780546},
keyword={fairrep}
}

@inproceedings{gaut2020towards,
author = {Andrew Gaut and  Tony Sun and  Shirlyn Tang and  Yuxin Huang and  Jing Qian and  Mai ElSherief and  Jieyu Zhao and  Diba Mirza and  Elizabeth Belding and  Md. Rizwan Parvez and William Yang Wang}, 
title = {Towards Understanding Gender Bias in Relation Extraction}, 
booktitle = {ACL},
presentation_time={6A Ethics, 7B Ethics},
tweet={https://twitter.com/mai_elsherief/status/1246468970384969730},
abstract = {Recent developments in Neural Relation Extraction (NRE) have made significant strides towards automated knowledge base construction. While much attention has been dedicated towards improvements in accuracy, there have been no attempts in the literature to evaluate social biases exhibited in NRE systems. In this paper, we create WikiGenderBias, a distantly supervised dataset composed of over 45,000 sentences including a 10% human annotated test set for the purpose of analyzing gender bias in relation extraction systems. We find that when extracting spouse and hypernym (i.e., occupation) relations, an NRE system performs differently when the gender of the target entity is different. However, such disparity does not appear when extracting relations such as birth date or birth place. We also analyze two existing bias mitigation techniques, word embedding debiasing and data augmentation. Unfortunately, due to NRE models relying heavily on surface level cues, we find that existing bias mitigation approaches have a negative effect on NRE. Our analysis lays groundwork for future quantifying and mitigating bias in relation extraction.},  rank = {40},  year = {2020},
keyword={fairnlp},
presentation_id={https://virtual.acl2020.org/paper_main.265.html},
paper_url={https://arxiv.org/pdf/1911.03642.pdf}
}

@inproceedings{li2020what,
author = {Liunian Harold Li and  Mark Yatskar and  Da Yin and  Cho-Jui Hsieh and Md. Rizwan Parvez},
title = {What Does BERT with Vision Look At?},
booktitle = {ACL (short)}, 
abstract = {Pre-trained visually grounded language models such as ViLBERT, LXMERT, and UNITER have achieved significant performance improvement on vision-and-language tasks but what they learn during pre-training remains unclear. In this work, we demonstrate that certain attention heads of a visually grounded language model actively ground elements of language to image regions. Specifically, some heads can map entities to image regions, performing the task known as entity grounding. Some heads can even detect the syntactic relations between non-entity words and image regions, tracking, for example, associations between verbs and regions corresponding to their arguments. We denote this ability as \emph{syntactic grounding}. We verify grounding both quantitatively and qualitatively, using Flickr30K Entities as a testbed.}, 
paper_url="http://kwchang.net/documents/pdf/li2020what.pdf",
code_url= {https://github.com/uclanlp/visualbert},
comment={See the <a href="http://web.cs.ucla.edu/%7Ekwchang/bibliography/li2019visualbert/"> 
     full version</a> of this paper.},
rank = {41},
presentation_id={https://virtual.acl2020.org/paper_main.469.html},
presentation_time={9A THEME-1, 10A THEME-2},
slides_url={http://kwchang.net/documents/slides/li2020what_slide.pdf},
tweet={https://twitter.com/yatskar/status/1160954739015557122},
youtube_id={Lhi1UFsXvpk},
year = {2020},
keyword={multirep}
}

@inproceedings{jia2020mitigating,
author = {Shengyu Jia and Tao Meng and Jieyu Zhao and Md. Rizwan Parvez},
title = {Mitigating Gender Bias Amplification in Distribution by Posterior Regularization},
booktitle = {ACL (short)}, 
abstract = {Advanced machine  learning  techniques  have boosted  the  performance  of  natural  language processing.  Nevertheless, recent studies, e.g., Zhao et al. (2017) show that these techniques inadvertently capture the societal bias hiddenin the corpus and further amplify it.  However,their analysis is conducted only on models' top predictions.   In this paper,  we investigate thegender  bias  amplification  issue  from  the  distribution perspective and demonstrate that thebias is amplified in the view of predicted probability distribution over labels. We further propose a bias mitigation approach based on posterior regularization.   With little performance loss,  our method can almost remove the bias amplification  in  the  distribution. Our study sheds the light on understanding the bias amplification.}, 
rank = {41}, 
year = {2020},
presentation_id={https://virtual.acl2020.org/paper_main.264.html},
code_url={https://github.com/uclanlp/reducingbias/tree/master/PosteriorBias},
paper_url={https://arxiv.org/pdf/2005.06251.pdf},
slides_url={http://kwchang.net/documents/slides/jia2020mitigating_slide.pdf},
keyword={fairnlp},
presentation_time={6A Ethics, 10B Ethics},
tweet={https://twitter.com/jieyuzhao11/status/1274186872047034369},
youtube_id={XeZMrb80Y8E}
}

@inproceedings{ahmad2020transformer,
author = {Wasi Ahmad and Saikat Chakraborty and Baishakhi Ray and Md. Rizwan Parvez},
title = {A Transformer-based Approach for Source Code Summarization},
booktitle = {ACL (short)}, 
abstract = {Generating a readable summary that describes the functionality of a program is known as source code summarization. In this task, learning code representation by modeling the pairwise relationship between code tokens to capture their long-range dependencies is crucial. To learn code representation for summarization, we explore the Transformer model that uses a self-attention mechanism and has shown to be effective in capturing long-range dependencies. In this work, we show that despite the approach is simple, it outperforms the state-of-the-art techniques by a significant margin. We perform extensive analysis and ablation studies that reveal several important findings, e.g., the absolute encoding of source code tokens' position hinders, while relative encoding significantly improves the summarization performance. We have made our code publicly available to facilitate future research.}, 
rank = {41}, 
paper_url={https://arxiv.org/pdf/2005.00653.pdf},
slides_url={http://kwchang.net/documents/slides/ahmad2020transformer_slide.pdf},
code_url={https://github.com/wasiahmad/NeuralCodeSum},
year = {2020},
presentation_id={https://virtual.acl2020.org/paper_main.449.html},
presentation_time={9A Summarization, 10B Summarization},
youtube_id={NN-ztuAfCes},
keyword={app},
}


@inproceedings{li2019visualbert,
author = {Liunian Harold Li and Mark Yatskar and Da Yin and Cho-Jui Hsieh and Md. Rizwan Parvez},
title = {VisualBERT: A Simple and Performant Baseline for Vision and Language},
booktitle = {Arxiv}, 
abstract = {We propose VisualBERT, a simple and flexible framework for modeling a broad range of vision-and-language tasks. VisualBERT consists of a stack of Transformer layers that implicitly align elements of an input text and regions in an associated input image with self-attention. We further propose two visually-grounded language model objectives for pre-training VisualBERT on image caption data. Experiments on four vision-and-language tasks including VQA, VCR, NLVR2, and Flickr30K show that VisualBERT outperforms or rivals with state-of-the-art models while being significantly simpler. Further analysis demonstrates that VisualBERT can ground elements of language to image regions without any explicit supervision and is even sensitive to syntactic relationships, tracking, for example, associations between verbs and image regions corresponding to their arguments.},
rank = {1}, 
tweet={https://twitter.com/yatskar/status/1160954739015557122},
pub_type=pre-print,
paper_url = {https://arxiv.org/pdf/1908.03557.pdf},
code_url= {https://github.com/uclanlp/visualbert},
keyword={multirep},
comment={<a href="http://kwchang.net/bibliography/li2020what/"> A short version</a> is publised at ACL 2020. <br>
VisualBERT is intergrated into <a href="https://github.com/facebookresearch/mmf/blob/ad32366285a804cf7694749960924335826a21c6/projects/pretrain_vl_right/README.md">Facebook MMF library</a><br>
Please see more anlaysis about VisualBERT in <a href="https://arxiv.org/abs/2004.08744"> a recent paper by A. Singh, V. Goswami, V., and D. Parikh (2019)</a><br>
VisualBERT is used as a baseline in <a href=https://ai.facebook.com/blog/hateful-memes-challenge-and-data-set/> Hateful Memes by Facebook Research </a>
},
year = {2019}
}


@inproceedings{shi2020robustness,
author = {Zhouxing Shi and Huan Zhang and Md. Rizwan Parvez and Minlie Huang and Cho-Jui Hsieh},
title = {Robustness Verification for Transformers},
booktitle = {ICLR}, 
abstract = {Robustness verification that aims to formally certify the prediction behavior of
neural networks has become an important tool for understanding the behavior of
a given model and for obtaining safety guarantees. However, previous methods
are usually limited to relatively simple neural networks. In this paper, we consider the robustness verification problem for Transformers. Transformers have
complex self-attention layers that pose many challenges for verification, including
cross-nonlinearity and cross-position dependency, which have not been discussed
in previous work. We resolve these challenges and develop the first verification
algorithm for Transformers. The certified robustness bounds computed by our
method are significantly tighter than those by naive Interval Bound Propagation.
These bounds also shed light on interpreting Transformers as they consistently
reflect the importance of words in sentiment analysis.},
rank = {50}, 
year = {2020},
keyword={robustness},
paper_url={https://arxiv.org/pdf/2002.06622.pdf},
video_url={https://iclr.cc/virtual_2020/poster_BJxwPJHFwS.html},
tweet={https://twitter.com/zhouxingshi/status/1229802456067952642},
code_url={https://github.com/shizhouxing/Robustness-Verification-for-Transformers}
}


@inproceedings{ahmad2019crosslingual,
author = {Wasi Ahmad and Zhisong Zhang and Xuezhe Ma and Md. Rizwan Parvez and Nanyun Peng},
title = {  Cross-lingual Dependency Parsing with Unlabeled Auxiliary Languages},
booktitle = {CoNLL}, 
abstract = {Cross-lingual transfer learning has become an important weapon to battle the unavailability of annotated resources for low-resource languages.  One of the fundamental techniques to transfer across languages is learning language-agnostic representations, in the form of word embeddings or contextual encodings. In this work, we propose to leverage unannotated sentences from auxiliary languages to help learning language-agnostic representations  Specifically, we explore adversarial training for learning contextual encoders that produce invariant representations across languages to facilitate cross-lingual transfer. We conduct experiments on cross-lingual dependency parsing where we train a dependency parser on a source language and transfer it to a wide range of target languages.  Experiments on 28 target languages demonstrate that adversarial training significantly improves the overall transfer performances under several different settings.  We conduct a careful analysis to evaluate the language-agnostic representations resulted from adversarial training.  }, rank = {1}, 
year = {2019},
keyword={crosslingual},
paper_url={https://arxiv.org/pdf/1909.09265.pdf},
code_url={https://github.com/wasiahmad/cross_lingual_parsing},
poster_url={http://kwchang.net/documents/poster/ahmad2019crosslingual_poster.pdf},
}

@inproceedings{chen2019leanring,
    author = {Muhao Chen and Yingtao Tian and Haochen Chen and  Md. Rizwan Parvez and Steve Skiena and Carlo Zaniolo},
    title = { Learning to Represent Bilingual Dictionaries},
    abstract = {Bilingual word embeddings have been widely used to capture the correspondence of lexical semantics in different human languages. However, the cross-lingual correspondence between sentences and words is less studied, despite that this correspondence can significantly benefit many applications such as cross-lingual semantic search and textual inference. To bridge this gap, we propose a neural embedding model that leverages bilingual dictionaries. The proposed model is trained to map the lexical definitions to the cross-lingual target words, for which we explore with different sentence encoding techniques. To enhance the learning process on limited resources, our model adopts several critical learning strategies, including multi-task learning on different bridges of languages, and joint learning of the dictionary model with a bilingual word embedding model. We conduct experiments on two new tasks. In the cross-lingual reverse dictionary retrieval task, we demonstrate that our model is capable of comprehending bilingual concepts based on descriptions, and the proposed learning strategies are effective. In the bilingual paraphrase identification task, we show that our model effectively associates sentences in different languages via a shared embedding space, and outperforms existing approaches in identifying bilingual paraphrases. },     
    paper_url={https://arxiv.org/pdf/1808.03726.pdf},
    rank = {1},
    booktitle={CoNLL},
    year = {2019}
}


@inproceedings{meng2019target,
author = {Tao Meng and Nanyun Peng and Md. Rizwan Parvez},
title = {Target Language-Aware Constrained Inference for Cross-lingual Dependency Parsing}, 
booktitle = {EMNLP}, 
abstract = {Prior work on cross-lingual dependency parsing often focuses on capturing the commonalities between source and target languages and overlooks the potential of leveraging linguistic properties of the languages to facilitate the transfer. In this paper, we show that weak supervisions of linguistic knowledge for the target languages can improve a cross-lingual graph-based dependency parser substantially. Specifically, we explore several types of corpus linguistic statistics and compile them into corpus-wise constraints to guide the inference process during the test time. We adapt two techniques, Lagrangian relaxation and posterior regularization, to conduct inference with corpus-statistics constraints. Experiments show that the Lagrangian relaxation and posterior regularization inference improve the performances on 15 and 17 out of 19 target languages, respectively. The improvements are especially significant for target languages that have different word order features from the source language.},
paper_url = {https://arxiv.org/pdf/1909.01482.pdf},
code_url= {https://github.com/MtSomeThree/CrossLingualDependencyParsing},
rank = {3},
poster_url = {http://kwchang.net/documents/poster/meng2019target_poster.pdf},
keyword={crosslingual},
year = {2019}
}
@inproceedings{zhou2019examining,
author = {Pei Zhou and Weijia Shi and Jieyu Zhao and Kuan-Hao Huang and Muhao Chen and Ryan Cotterell and Md. Rizwan Parvez},
title = {Examining Gender Bias in Languages with Grammatical Gender}, 
abstract={Recent studies have shown that word embeddings exhibit gender bias inherited from the training corpora. However, most studies to date have focused on quantifying and mitigating such bias only in English. These analyses cannot be directly extended to languages that exhibit morphological agreement on gender, such as Spanish and French. In this paper, we propose new metrics for evaluating gender bias in word embeddings of these languages and further demonstrate evidence of gender bias in bilingual embeddings which align these languages with English. Finally, we extend an existing approach to mitigate gender bias in word embeddings under both monolingual and bilingual settings. Experiments on modified Word Embedding Association Test, word similarity, word translation, and word pair translation tasks show that the proposed approaches effectively reduce the gender bias while preserving the utility of the embeddings.},
booktitle = {EMNLP}, 
paper_url = {https://arxiv.org/pdf/1909.02224.pdf},
code_url = {https://github.com/shaoxia57/Bias_in_Gendered_Languages},
rank = {5}, 
poster_url = {http://kwchang.net/documents/poster/zhou2019examining_poster.pdf},
tweet={https://twitter.com/peizNLP/status/1170074125739552768},
keyword={fairrep},
year = {2019}
}
@inproceedings{zhou2019learning,
author = {Yichao Zhou and Jyun-Yu Jiang and Md. Rizwan Parvez and Wei Wang},
title = {Learning to Discriminate Perturbations for Blocking Adversarial Attacks in Text Classification}, 
abstract= {Adversarial attacks against machine learning models have threatened various real-world applications such as spam filtering and sentiment analysis. In this paper, we propose a novel framework, learning to DIScriminate Perturbations (DISP), to identify and adjust malicious perturbations, thereby blocking adversarial attacks for text classification models. To identify adversarial attacks, a perturbation discriminator validates how likely a token in the text is perturbed and provides a set of potential perturbations. For each potential perturbation, an embedding estimator learns to restore the embedding of the original word based on the context and a replacement token is chosen based on approximate kNN search. DISP can block adversarial attacks for any NLP model without modifying the model structure or training procedure. Extensive experiments on two benchmark datasets demonstrate that DISP significantly outperforms baseline methods in blocking adversarial attacks for text classification. In addition, in-depth analysis shows the robustness of DISP across different situations.},
booktitle = {EMNLP},
code_url={https://github.com/joey1993/bert-defender},
paper_url={https://arxiv.org/pdf/1909.03084.pdf},
rank = {5}, 
keyword={robustness},
year = {2019}
}
@inproceedings{parvez2019robust,
author = {Md Rizwan Parvez and Tolga Bolukbasi and Md. Rizwan Parvez and Venkatesh Saligrama},
title = {Robust Text Classifier on Test-Time Budgets}, 
abstract={We propose a generic and interpretable learning framework for building robust text classification model that achieves accuracy comparable to full models under test-time budget constraints. Our approach learns a selector to identify words that are relevant to the prediction tasks and passes them to the classifier for processing. The selector is trained jointly with the classifier and directly learns to incorporate with the classifier. We further propose a data aggregation scheme to improve the robustness of the classifier. Our learning framework is general and can be incorporated with any type of text classification model. On real-world data, we show that the proposed approach improves the performance of a given classifier and speeds up the model with a mere loss in accuracy performance.},
booktitle = {EMNLP (short)}, 
paper_url={https://arxiv.org/pdf/1808.08270.pdf},
code_url={https://github.com/uclanlp/Fast-and-Robust-Text-Classification},
slides_url={http://kwchang.net/documents/slides/parvez2019robust_slide.pdf},
rank = {6}, 
keyword={effecient},
year = {2019}
}
@inproceedings{shi2019retrofitting,
author = {Weijia Shi and Muhao Chen and Pei Zhou and Md. Rizwan Parvez},
title = {Retrofitting Contextualized Word Embeddings with Paraphrases}, 
booktitle = {EMNLP (short)}, 
abstract={Contextualized word embedding models, such as ELMo, generate meaningful representations of words and their context. These models have been shown to have a great impact on downstream applications. However, in many cases, the contextualized embedding of a word changes drastically when the context is paraphrased. As a result, the downstream model is not robust to paraphrasing and other linguistic variations. To enhance the stability of contextualized word embedding models, we propose an approach to retrofitting contextualized embedding models with paraphrase contexts. Our method learns an orthogonal transformation on the input space, which seeks to minimize the variance of word representations on paraphrased contexts. Experiments show that the retrofitted model significantly outperforms the original ELMo on various sentence classification and language inference tasks.},
paper_url={https://arxiv.org/pdf/1909.09700.pdf},
slides_url={https://muhaochen.github.io/slides/PAR.pdf},
code_url={https://github.com/swj0419/retrofit},
rank = {7},
tweet={https://twitter.com/muhao_chen/status/1191629835543535616},
vimeo_id={430797636},
keyword={robustness},
year = {2019}
}
@inproceedings{sheng2019woman,
author = {Emily Sheng and Md. Rizwan Parvez and Premkumar Natarajan and Nanyun Peng},
title = {The Woman Worked as a Babysitter: On Biases in Language Generation}, 
booktitle = {EMNLP (short)}, 
paper_url={https://arxiv.org/pdf/1909.01326.pdf},
abstract={We present a systematic study of biases in natural language generation (NLG) by analyzing text generated from prompts that contain mentions of different demographic groups. In this work, we introduce the notion of the regard towards a demographic, use the varying levels of regard towards different demographics as a defining metric for bias in NLG, and analyze the extent to which sentiment scores are a relevant proxy metric for regard. To this end, we collect strategically-generated text from language models and manually annotate the text with both sentiment and regard scores. Additionally, we build an automatic regard classifier through transfer learning, so that we can analyze biases in unseen text. Together, these methods reveal the extent of the biased nature of language model generations. Our analysis provides a study of biases in NLG, bias metrics and correlated human judgments, and empirical evidence on the usefulness of our annotated dataset.},
code_url={https://github.com/ewsheng/nlg-bias},
rank = {7},
tweet={https://twitter.com/VioletNPeng/status/1191982282011230213},
slides_url={https://docs.google.com/presentation/d/1hDerANwiNuHCdmHZyvqMTDnvJ2jnIGkD3KI4PIz0wK8/edit#slide=id.p},
vimeo_id={426366363},
keyword={fairnlg},
year = {2019}
}
@inproceedings{xia2019visualizing,
author = {Chen Xia and Haoxiang Zhang and Jacob Moghtader and Allen Wu and Md. Rizwan Parvez},
title = {Visualizing Trend of Key Roles in News Articles}, 
booktitle = {EMNLP (demo)},
abstract={There are tons of news articles generated every day reflecting the activities of key roles such as people, organizations and political parties. Analyzing these key roles allows us to understand the trends in news. In this paper, we present a demonstration system that visualizes the trend of key roles in news articles based on natural language processing techniques. Specifically, we apply a semantic role labeler and the dynamic word embedding technique to understand relationships between key roles in the news across different time periods and visualize the trends of key role and news topics change over time.},
rank = {8},
code_url={https://github.com/kasinxc/Visualizing-Trend-of-Key-Roles-in-News-Articles},
src_url={https://arxiv.org/pdf/1909.05449.pdf},
paper_url={https://arxiv.org/pdf/1909.05449.pdf},
year = {2019}
}
@inproceedings{li2019efficient,
author = {Liunian Harold Li and Patrick H. Chen and Cho-Jui Hsieh and Md. Rizwan Parvez},
title = {Efficient Contextual Representation Learning With Continuous Outputs}, 
booktitle = {TACL}, 
abstract = {Contextual representation models have achieved great success in improving various downstream natural language processing tasks. However, these language-model-based encoders are difficult to train due to their large parameter size and high computational complexity. By carefully examining the training procedure, we observe that the softmax layer, which predicts a distribution of the target word, often induces significant overhead, especially when the vocabulary size is large. Therefore, we revisit the design of the output layer and consider directly predicting the pre-trained embedding of the target word for a given context. When applied to ELMo, the proposed approach achieves a 4 times speedup and eliminates 80% trainable parameters while achieving competitive performance on downstream tasks. Further analysis shows that the approach maintains the speed advantage under various settings, even when the sentence encoder is scaled up.}, 
rank = {10}, 
keyword={effecient},
presentation_time={4B Machine Learning, 5B Machine Learning},
youtube_id={QFBMXRwjlHw},
slides_url={http://kwchang.net/documents/slides/li2019efficient_slide.pdf},
paper_url = {https://arxiv.org/pdf/1902.11269.pdf}, 
year = {2019}
}
@inproceedings{wang2019balanced,
author = {Tianlu Wang and Jieyu Zhao and Mark Yatskar and Md. Rizwan Parvez and Vicente Ordonez},
title = {Balanced Datasets Are Not Enough: Estimating and Mitigating Gender Bias in Deep Image Representations}, 
booktitle = {ICCV},
comment = {A short version is presented in a workshop at CVPR}, 
abstract = {In this work, we present a framework to measure and mitigate intrinsic biases with respect to protected variables --such as gender-- in visual recognition tasks. We show that trained models significantly amplify the association of target labels with gender beyond what one would expect from biased datasets. Surprisingly, we show that even when datasets are balanced such that each label co-occurs equally with each gender, learned models amplify the association between labels and gender, as much as if data had not been balanced! To mitigate this, we adopt an adversarial approach to remove unwanted features corresponding to protected variables from intermediate representations in a deep neural network -- and provide a detailed analysis of its effectiveness. Experiments on two datasets: the COCO dataset (objects), and the imSitu dataset (actions), show reductions in gender bias amplification while maintaining most of the accuracy of the original models.}, 
rank = {11}, 
keyword={fairrep},
code_url={https://github.com/uvavision/Balanced-Datasets-Are-Not-Enough},
demo_url={https://www.vislang.ai/genderless},
tweet={https://twitter.com/yatskar/status/1069750565662449664},
paper_url = {https://arxiv.org/pdf/1811.08489.pdf}, 
year = {2019}
}
@inproceedings{hu2019fewshot,
author = {Ziniu Hu and Ting Chen and Md. Rizwan Parvez and Yizhou Sun},
title = {Few-Shot Representation Learning for Out-Of-Vocabulary Words}, 
booktitle = {ACL}, 
abstract = {Existing approaches for learning word embeddings often assume there are sufficient occurrences for each word in the corpus, such that the representation of words can be accurately estimated from their contexts. However, in real-world scenarios, out-of-vocabulary (a.k.a. OOV) words that do not appear in training corpus emerge frequently. It is challenging to learn accurate representations of these words with only a few observations. In this paper, we formulate the learning of OOV embeddings as a few-shot regression problem, and address it by training a representation function to predict the oracle embedding vector (defined as embedding trained with abundant observations) based on limited observations. Specifically, we propose a novel hierarchical attention-based architecture to serve as the neural regression function, with which the context information of a word is encoded and aggregated from K observations. Furthermore, our approach can leverage Model-Agnostic Meta-Learning (MAML) for adapting the learned model to the new corpus fast and robustly. Experiments show that the proposed approach significantly outperforms existing methods in constructing accurate embeddings for OOV words, and improves downstream tasks where these embeddings are utilized.}, 
rank = {18}, 
keyword={rep},
code_url={https://github.com/acbull/HiCE},
paper_url = {https://arxiv.org/pdf/1907.00505.pdf}, 
poster_url ={http://kwchang.net/documents/poster/hu2019fewshot_poster.pdf},
year = {2019}
}
@inproceedings{sun2019mitigating,
author = {Tony Sun and Andrew Gaut and Shirlyn Tang and Yuxin Huang and Mai ElSherief and Jieyu Zhao and Diba Mirza and Md. Rizwan Parvez and William Yang Wang},
title = {Mitigating Gender in Natural Language Processing: Literature Review}, 
booktitle = {ACL},
tweet={https://twitter.com/WilliamWangNLP/status/1143212008310886401},
abstract = {As Natural Language Processing (NLP) and Machine Learning (ML) tools rise in popularity, it becomes increasingly vital to recognize the role they play in shaping societal biases and stereotypes. Although NLP models have shown success in modeling various applications, they propagate and may even amplify gender bias found in text corpora. While the study of bias in artificial intelligence is not new, methods to mitigate gender bias in NLP are relatively nascent. In this paper, we review contemporary studies on recognizing and mitigating gender bias in NLP. We discuss gender bias based on four forms of representation bias and analyze methods recognizing gender bias. Furthermore, we discuss the advantages and drawbacks of existing gender debiasing methods. Finally, we discuss future studies for recognizing and mitigating gender bias in NLP.}, 
rank = {19},
vimeo_id={384482151},
keyword={fairnlp},
paper_url = {https://arxiv.org/pdf/1906.08976.pdf},
slides_url = {http://kwchang.net/documents/slides/sun2019debiasing_slide.pdf},
year = {2019}
}
@inproceedings{ahmad2019difficulties,
author = {Wasi Uddin Ahmad and Zhisong Zhang and Xuezhe Ma and Eduard Hovy and Md. Rizwan Parvez and Nanyun Peng},
title = {On Difficulties of Cross-Lingual Transfer with Order Differences: A Case Study on Dependency Parsing}, 
booktitle = {NAACL}, 
abstract = {Different languages might have different wordorders. In this paper, we investigate cross-lingual transfer and posit that an order-agnostic model will perform better when trans-ferring to distant foreign languages. To test ourhypothesis, we train dependency parsers on anEnglish corpus and evaluate their transfer per-formance on 30 other languages. Specifically,we compare encoders and decoders based onRecurrent Neural Networks (RNNs) and mod-ified self-attentive architectures. The formerrelies on sequential information while the lat-ter is more flexible at modeling word order.Rigorous experiments and detailed analysisshows that RNN-based architectures transferwell to languages that are close to English,while self-attentive models have better overallcross-lingual transferability and perform espe-cially well on distant languages.}, 
rank = {21}, 
keyword={crosslingual},
paper_url = {https://arxiv.org/pdf/1811.00570.pdf},
code_url = {https://github.com/uclanlp/CrossLingualDepParser},
youtube_id ={YuFI0DOw8N0},
year = {2019}
}
@inproceedings{zhao2019gender,
author = {Jieyu Zhao and Tianlu Wang and Mark Yatskar and Ryan Cotterell and Vicente Ordonez and Md. Rizwan Parvez},
title = {Gender Bias in Contextualized Word Embeddings}, 
booktitle = {NAACL (short)}, 
abstract = {Despite the great success of contextualized word embeddings on downstream applications, these representations potentially embed the societal biases exhibited in their training corpus. In this paper, we quantify, analyze and mitigate the gender bias exhibited in ELMo contextualized word vectors. We first demonstrate that the vectors encode and propagate information about genders unequally and then conduct a principal component analysis to visualize the geometry of the gender information in the embeddings. Then we show that ELMo works unequally well for men and women in down-stream tasks. Finally, we explore a variety of methods to remove such gender bias and demonstrate that it can be reduced through data augmentation.}, 
rank = {22},
keyword={fairrep},
slides_url = {http://kwchang.net/documents/slides/zhao2019gender_slide.pdf},
paper_url = {https://arxiv.org/pdf/1904.03310.pdf},
youtube_id = {n9KGNbpnu5c},
year = {2019}
}
@inproceedings{ahmad2019context,
author = {Wasi Ahmad and Md. Rizwan Parvez and Hongning Wang},
title = {Context Attentive Document Ranking and Query Suggestion}, 
booktitle = {SIGIR}, 
abstract = {We present a context-aware neural ranking model to exploit users' on-task search activities and enhance retrieval performance. Inparticular, a two-level hierarchical recurrent neural network isintroduced to learn search context representation of individualqueries, search tasks, and corresponding dependency structure byjointly optimizing two companion retrieval tasks: document rank-ing and query suggestion. To identify variable dependency structurebetween search context and users' ongoing search activities, at-tention at both levels of recurrent states are introduced. Extensiveexperiment comparisons against a rich set of baseline methods andan in-depth ablation analysis confirm the value of our proposedapproach for modeling search context buried in search tasks.}, 
rank = {30}, 
keyword={app},
paper_url = {https://arxiv.org/pdf/1906.02329.pdf},
slides_url={http://kwchang.net/documents/slides/ahmad2019context_slide.pdf},
code_url = {https://github.com/wasiahmad/context_attentive_ir},
year = {2019}
}
@inproceedings{chen2019multifaceted,
author = {Muhao Chen and Chelsea J.-T. Ju and Guangyu Zhou and Xuelu Chen and Tianran Zhang and Md. Rizwan Parvez and Carlo Zaniolo and Wei Wang},
title = {Multifaceted Protein-Protein Interaction Prediction Based on Siamese Residual RCNN}, 
booktitle = {ISMB}, 
abstract = {Sequence-based protein-protein interaction (PPI) prediction represents a fundamental computational biology problem. To address this problem, extensive research efforts have been made to extract predefined features from the sequences. Based on these features, statistical algorithms are learned to classify the PPIs. However, such explicit features are usually costly to extract, and typically have limited coverage on the PPI information. Hence, we present an end-to-end framework, Lasagna, for PPI predictions using only the primary sequences of a protein pair. Lasagna incorporates a deep residual recurrent convolutional neural network in the Siamese learning architecture, which leverages both robust local features and contextualized information that are significant for capturing the mutual influence of protein sequences. Our framework relieves the data pre-processing efforts that are required by other systems, and generalizes well to different application scenarios. Experimental evaluations show that Lasagna outperforms various state-of-the-art systems on the binary PPI prediction problem. Moreover, it shows a promising performance on more challenging problems of interaction type prediction and binding affinity estimation, where existing approaches fall short.}, 
rank = {40}, 
keyword={app},
code_url={https://github.com/muhaochen/seq_ppi},
paper_url = {https://www.biorxiv.org/content/10.1101/501791v1}, 
year = {2019}
}
@inproceedings{hu2019pretraining,
author = {Ziniu Hu and Changjun Fan and Ting Chen and Md. Rizwan Parvez and Yizhou Sun},
title = {Pre-Training Graph Neural Networks for Generic Structural Feature Extraction}, 
booktitle = {ICLR 2019 Workshop: Representation Learning on Graphs and Manifolds}, 
abstract = {Graph neural networks (GNNs) are shown to be successful in modeling applications with graph structures. However, training an accurate GNN model requires a large collection of labeled data and expressive features, which might be inaccessible for some applications. To tackle this problem, we propose a pre-training framework that captures generic graph structural information that is transferable across tasks. Our framework can leverage the following three tasks: 1) denoising link reconstruction, 2) centrality score ranking, and 3) cluster preserving. The pre-training procedure can be conducted purely on the synthetic graphs, and the pre-trained GNN is then adapted for downstream applications. With the proposed pre-training procedure, the generic structural information is learned and preserved, thus the pre-trained GNN requires less amount of labeled data and fewer domain-specific features to achieve high performance on different downstream tasks. Comprehensive experiments demonstrate that our proposed framework can significantly enhance the performance of various tasks at the level of node, link, and graph.}, 
rank = {50}, 
paper_url = {https://arxiv.org/pdf/1905.13728.pdf}, 
year = {2019}
}
@inproceedings{shi2019bilingual,
author = {Weijia Shi and Muhao Chen and Yingtao Tian and Md. Rizwan Parvez},
title = {Learning Bilingual Word Embeddings Using Lexical Definitions}, 
booktitle = {Repl4NLP (ACL workshop)}, 
abstract = {Bilingual word embeddings, which represent lexicons of different languages in a shared embedding space, are essential for supporting semantic and knowledge transfers in a variety of cross-lingual NLP tasks. Existing approaches to training bilingual word embeddings require either large collections of pre-defined seed lexicons that are expensive to obtain, or parallel sentences that comprise coarse and noisy alignment. In contrast, we propose BiLex that leverages publicly available lexical definitions for bilingual word embedding learning. Without the need of predefined seed lexicons, BiLex comprises a novel word pairing strategy to automatically identify and propagate the precise fine-grain word alignment from lexical definitions. We evaluate BiLex in word-level and sentence-level translation tasks, which seek to find the cross-lingual counterparts of words and sentences respectively. BiLex significantly outperforms previous embedding methods on both tasks.}, 
poster={http://kwchang.net/documents/slides/shi2019bilingual_poster.pdf},
paper_url = {https://arxiv.org/pdf/1906.08939.pdf},
rank = {58}, 
year = {2019}
}
@inproceedings{alzanto2018generating,
author = {Moustafa Alzantot and Yash Sharma and Ahmed Elgohary and Bo-Jhang Ho and Mani Srivastava and Md. Rizwan Parvez},
title = {Generating Natural Language Adversarial Examples}, 
booktitle = {EMNLP (short)}, 
abstract = {Deep neural networks (DNNs) are vulnerable to adversarial examples, perturbations to correctly classified examples which can cause the network to misclassify. In the image domain, these perturbations can often be made virtually indistinguishable to human perception, causing humans and state-of-the-art models to disagree. However, in the natural language domain, small perturbations are clearly perceptible, and the replacement of a single word can drastically alter the semantics of the document. Given these challenges, we use a population-based optimization algorithm to generate semantically and syntactically similar adversarial examples. We demonstrate via a human study that 94.3% of the generated examples are classified to the original label by human evaluators, and that the examples are perceptibly quite similar. We hope our findings encourage researchers to pursue improving the robustness of DNNs in the natural language domain.}, 
rank = {11}, 
keyword={robustness},
keynote_url = {https://www.paperdigest.org/2023/04/most-influential-emnlp-papers-2023-04/}, 
keynote = {Top-10 cited paper at EMNLP 18},
code_url={https://github.com/nesl/nlp_adversarial_examples},
paper_url = {https://arxiv.org/pdf/1804.07998.pdf}, 
year = {2018}
}
@inproceedings{zhao2018learning,
author = {Jieyu Zhao and Yichao Zhou and Zeyu Li and Wei Wang and Md. Rizwan Parvez},
title = {Learning Gender-Neutral Word Embeddings}, 
booktitle = {EMNLP (short)}, 
abstract = {Word embeddings have become a fundamental component in a wide range of Natu-ral Language Processing (NLP) applications.However, these word embeddings trained onhuman-generated corpora inherit strong gen-der stereotypes that reflect social constructs.In this paper, we propose a novel word em-bedding model, De-GloVe, that preserves gen-der information in certain dimensions of wordvectors while compelling other dimensions tobe free of gender influence. Quantitative andqualitative experiments demonstrate that De-GloVe successfully isolates gender informa-tion without sacrificing the functionality of theembedding model.}, 
rank = {12},
keyword={fairrep},
code_url={https://github.com/uclanlp/gn_glove},
paper_url = {https://arxiv.org/pdf/1809.01496.pdf},
year = {2018}
}
@inproceedings{parvez2018building,
author = {Md Rizwan Parvez and Saikat Chakraborty and Baishakhi Ray and Md. Rizwan Parvez},
title = {Building Language Models for Text with Named Entities}, 
booktitle = {ACL}, 
abstract = {Text in many domains involves a significant amount of named entities. Predicting the entity names is often challenging for a language model as they appear less frequent on the training corpus. In this paper, we propose a novel and effective approach to building a language model which can learn the entity names by leveraging their entity type information. We also introduce two benchmark datasets based on recipes and Java programming codes, on which we evaluate the proposed model. Experimental results show that our model achieves 52.2\% better perplexity in recipe generation and 40.3\% on code generation than state-of-the-art language models.}, 
rank = {21}, 
keyword={lwll},
tweet={https://twitter.com/sameer_/status/1054642186489196544},
paper_url = {https://arxiv.org/pdf/1805.04836.pdf}, 
poster_url={http://kwchang.net/documents/poster/parvez2018building_poster.pdf},
code_url = {https://github.com/uclanlp/NamedEntityLanguageModel}, 
year = {2018}
}
@inproceedings{jiang2018learning,
author = {Chao Jiang and Hsiang-Fu Yu and Cho-Jui Hsieh and Md. Rizwan Parvez},
title = {Learning Word Embeddings for Low-resource Languages by PU Learning}, 
booktitle = {NAACL}, 
abstract = {Word embedding has been used as a key component in many downstream applications in processing natural languages. Existing approaches often assume the existence of a large collection of text for learning effective word embedding. However, such a corpus may not be available for some low-resource languages. In this paper, we study how to effectively learn a word embedding model on a corpus with only a few million tokens. In such a situation, the co-occurrence matrix is very sparse because many word pairs are not observed to co-occur. In contrast to existing approaches, we argue that the zero entries in the co-occurrence matrix also provide valuable information and design a Positive-Unlabeled Learning (PU-Learning) approach to factorize the co-occurrence matrix. The experimental results demonstrate that the proposed approach requires a smaller amount of training text to obtain a reasonable word embedding model.}, 
rank = {22}, 
keyword={rep},
slides_url={http://kwchang.net/documents/slides/jiang2018learning_slide.pdf},
paper_url = {https://arxiv.org/pdf/1805.03366.pdf},
vimeo_id = {277670013},
code_url={https://github.com/uclanlp/PU-Learning-for-Word-Embedding},
year = {2018}
}
@inproceedings{zhao2018gender,
author = {Jieyu Zhao and Tianlu Wang and Mark Yatskar and Vicente Ordonez and Md. Rizwan Parvez},
title = {Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods}, 
keynote_url = {https://www.paperdigest.org/2023/04/most-influential-naacl-papers-2023-04/}, 
keynote = {Top-10 cited paper at NAACL 18},
booktitle = {NAACL (short)}, 
abstract = {In this paper, we introduce a new benchmark for co-reference resolution focused on gender bias, WinoBias. Our corpus contains Winograd-schema style sentences with entities corresponding to people referred by their occupation (e.g. the nurse, the doctor, the carpenter). We demonstrate that a rule-based, a feature-rich, and a neural coreference system all link gendered pronouns to pro-stereotypical entities with higher accuracy than anti-stereotypical entities, by an average difference of 21.1 in F1 score. Finally, we demonstrate a data-augmentation approach that, in combination with existing word-embedding debiasing techniques, removes the bias demonstrated by these systems in WinoBias without significantly affecting their performance on existing datasets.},
rank = {23}, 
keyword={fairnlp},
poster_url = {http://kwchang.net/documents/poster/zhao2018gender_poster},
paper_url = {https://arxiv.org/pdf/1804.06876.pdf}, 
code_url = {https://uclanlp.github.io/corefBias/overview},
press_url={https://www.stitcher.com/podcast/matt-gardner/nlp-highlights/e/55861936},
comment={Jieyu comes on the NLP Highlights <a href="https://soundcloud.com/nlp-highlights/66-gender-bias-in-coreference-resolution-evaluation-and-debiasing-methods-with-jieyu-zhao"> Podcast</a> to discuss this paper.},
year = {2018}
}

@inproceedings{chen2018multilingual,
author = {Muhao Chen and Yingtao Tian and Md. Rizwan Parvez and Steven Skiena and Carlo Zaniolo},
title = {Co-training Embeddings of Knowledge Graphs and Entity Descriptions for Cross-lingual Entity Alignment}, 
booktitle = {IJCAI}, 
abstract = {Multilingual knowledge graph (KG) embeddings provide latent semantic representations of entities and structured knowledge enabled with cross-lingual inferences that benefit various knowledge-driven cross-lingual NLP tasks. However, precisely learning such cross-lingual inferences is usually hindered by the low coverage of entity alignment in many KGs. Since many multilingual KGs also provide literal descriptions of entities, in this paper, we introduce an embedding-based approach which leverages a weakly aligned multilingual KG for semi-supervised cross-lingual learning using entity descriptions. Our approach performs co-training of two embedding models, i.e. a multilingual KG embedding model and a multilingual literal description embedding model. The models are trained on a large Wikipedia-based trilingual dataset where most entity alignment is unknown to training. Experimental results show that the performance of the proposed approach on the entity alignment task improves at each iteration of co-training, and eventually reaches a stage at which it significantly surpasses previous approaches. We also show that our approach has promising abilities for zero-shot entity alignment, and cross-lingual KG completion.}, 
rank = {32}, 
keyword={rep},
slides_url={https://muhaochen.github.io/slides/kdcoe.pdf},
code_url={https://github.com/muhaochen/MTransE-tf/blob/master/README.md},
paper_url = {https://www.ijcai.org/proceedings/2018/0556.pdf}, 
year = {2018}
}
@inproceedings{ahmad2018multitask,
author = {Wasi Ahmad and Md. Rizwan Parvez and Hongning Wang},
title = {Multi-Task Learning for Document Ranking and Query Suggestion}, 
booktitle = {ICLR}, 
abstract = {We propose a multi-task learning framework to jointly learn document ranking and query suggestion for web search. It consists of two major components, a document ranker and a query recommender. Document ranker combines current query and session information and compares the combined representation with document representation to rank the documents. Query recommen tracks users' query reformulation sequence considering all previous in-session queries using a sequence to sequence approach. As both tasks are driven by the users' underlying search intent, we perform joint learning of these two components through session recurrence, which encodes search context and intent. Extensive comparisons against state-of-the-art document ranking and query suggestion algorithms are performed on the public AOL search log, and the promising results endorse the effectiveness of the joint learning framework.}, 
rank = {39}, 
keyword={app},
paper_url = {https://openreview.net/pdf?id=SJ1nzBeA-}, 
code_url = {https://github.com/wasiahmad/mnsrf_ranking_suggestion}, 
year = {2018}
}
@inproceedings{ahmad2018intent,
author = {Wasi Ahmad and Md. Rizwan Parvez and Hongning Wang},
title = {Intent-aware Query Obfuscation for Privacy Protection in Personalized Web Search}, 
booktitle = {SIGIR}, 
abstract = {Modern web search engines exploit users' search history to personalize search results, with a goal of improving their service utility on a per-user basis. But it is this very dimension that leads to the risk of privacy infringement and raises serious public concerns. In this work, we propose a client-centered intent-aware query obfuscation solution for protecting user privacy in a personalized web search scenario. In our solution, each user query is submitted with l additional cover queries and corresponding clicks, which act as decoys to mask users' genuine search intent from a search engine. The cover queries are sequentially sampled from a set of hierarchically organized language models to ensure the coherency of fake search intents in a cover search task. Our approach emphasizes the plausibility of generated cover queries, not only to the current genuine query but also to previous queries in the same task, to increase the complexity for a search engine to identify a user's true intent. We also develop two new metrics from an information theoretic perspective to evaluate the effectiveness of provided privacy protection. Comprehensive experiment comparisons with state-of-the-art query obfuscation techniques are performed on the public AOL search log, and the propitious results substantiate the effectiveness of our solution.}, 
rank = {40},
keyword={app},
paper_url = {https://dl.acm.org/citation.cfm?id=3209983}, 
code_url = {https://github.com/wasiahmad/intent_aware_privacy_protection_in_pws}, 
year = {2018}
}
@inproceedings{feng2018conterexamples,
author = {Lu Feng and Mahsa Ghasemi and Md. Rizwan Parvez and Ufuk Topcu},
title = {Counterexamples for Robotic Planning Explained in Structured Language}, 
booktitle = {ICRA}, 
abstract = {Automated techniques such as model checking have been used to verify models of robotic mission plans based on Markov decision processes (MDPs) and generate counterexamples that may help diagnose requirement violations. However, such artifacts may be too complex for humans to understand, because existing representations of counterexamples typically include a large number of paths or a complex automaton. To help improve the interpretability of counterexamples, we define a notion of explainable counterexample, which includes a set of structured natural language sentences to describe the robotic behavior that lead to a requirement violation in an MDP model of robotic mission plan. We propose an approach based on mixed-integer linear programming for generating explainable counterexamples that are minimal, sound and complete. We demonstrate the usefulness of the proposed approach via a case study of warehouse robots planning.}, 
rank = {43}, 
keyword={app},
paper_url = {https://arxiv.org/abs/1803.08966}, 
year = {2018}
}
@inproceedings{AC18,
author = {Wasi Ahmad and Md. Rizwan Parvez},
title = {A Corpus to Learn Refer-to-as Relations for Nominals}, 
booktitle = {LREC}, 
abstract = {Continuous representations for words or phrases, trained on large unlabeled corpora are proved very useful for many natural language processing tasks. While these vector representations capture many fine-grained syntactic and semantic regularities among words or phrases, it often lacks coreferential information which is useful for many downstream tasks like information extraction, text summarization etc. In this paper, we argue that good word and phrase embeddings should contain information for identifying refer-to-as relationship and construct a corpus from Wikipedia to generate coreferential neural embeddings for nominals. The term \emph{nominal} refers to a word or a group of words that functions like a noun phrase. In addition, we use coreference resolution as a proxy to evaluate the learned neural embeddings for noun phrases. To simplify the evaluation procedure, we design a coreferential phrase prediction task where the learned nominal embeddings are used to predict which candidate nominals can be referred to a target nominal. We further describe how to construct an evaluation dataset for such task from well known OntoNotes corpus and demonstrate encouraging baseline results.},
rank = {50}, 
paper_url = {https://www.aclweb.org/anthology/L18-1062.pdf},
code_url = {https://github.com/wasiahmad/mining_wikipedia/tree/master/WikiMiner}, 
year = {2018}
}
@inproceedings{PPCS18,
author = {Sarah Masud Preum and Md. Rizwan Parvez and Md. Rizwan Parvez and John Stankovic},
title = {A Corpus of Drug Usage Guidelines Annotated with Type of Advice}, 
booktitle = {LREC}, 
abstract = {Adherence to drug usage guidelines for prescription and over-the-counter drugs is critical for drug safety and effectiveness of treatment. Drug usage guideline documents contain advice on potential drug-drug interaction, drug-food interaction, and drug administration process. Current research on drug safety and public health indicates patients are often either unaware of such critical advice or overlook them. Categorizing advice statements from these documents according to their topics can enable the patients to find safety critical information. However, automatically categorizing drug usage guidelines based on their topic is an open challenge and there is no annotated dataset on drug usage guidelines. To address the latter issue, this paper presents (i) an annotation scheme for annotating safety critical advice from drug usage guidelines, (ii) an annotation tool for such data, and (iii) an annotated dataset containing drug usage guidelines from 90 drugs. This work is expected to accelerate further release of annotated drug usage guideline datasets and research on automatically filtering safety critical information from these textual documents.}, 
rank = {52}, 
code_url={https://zenodo.org/record/1173345#.XsTp4xNKh26},
paper_url = {https://arxiv.org/abs/1805.04836}, 
year = {2018}
}
@inproceedings{ZCCZ18,
author = {Pei Zhou and Muhao Chen and Md. Rizwan Parvez and Carlo Zaniolo},
title = {Quantification and Analysis of Scientific Language Variation Across Research Fields}, 
booktitle = {CDEC (workshop at ICDM)}, 
abstract = {Quantifying differences in terminologies from various academic domains has been a longstanding problem yet to be
solved. We propose a computational approach for analyzing linguistic variation among scientific research fields by capturing the
semantic change of terms based on a neural language model. The
model is trained on a large collection of literature in five computer
science research fields, for which we obtain field-specific vector
representations for key terms, and global vector representations
for other words. Several quantitative approaches are introduced
to identify the terms whose semantics have drastically changed,
or remain unchanged across different research fields. We also
propose a metric to quantify the overall linguistic variation of
research fields. After quantitative evaluation on human annotated
data and qualitative comparison with other methods, we show
that our model can improve cross-disciplinary data collaboration
by identifying terms that potentially induce confusion during
interdisciplinary studies.}, 
paper_url = {https://arxiv.org/pdf/1812.01250.pdf}, 
year = {2018},
rank={60}
}
@inproceedings{DAECL18,
author = {Dat Duong and Wasi Uddin Ahmad and Eleazar Eskin and Md. Rizwan Parvez and Jingyi Jessica Li},
title = {Word and sentence embedding tools to measure semantic similarity of Gene Ontology terms by their definitions}, 
booktitle = {Journal of Computational Biology}, 
abstract = {The Gene Ontology (GO) database contains GO terms that describe biological functions of genes.
Previous methods for comparing GO terms have relied on the fact that GO terms are organized
into a tree structure. Under this paradigm, the locations of two GO terms in the tree dictate their
similarity score. In this paper, we introduce two new solutions for this problem, by focusing
instead on the definitions of the GO terms. We apply neural network based techniques from
the natural language processing (NLP) domain. The first method does not rely on the GO tree,
whereas the second indirectly depends on the GO tree. In our first approach, we compare two GO
definitions by treating them as two unordered sets of words. The word similarity is estimated by a
word embedding model that maps words into an N-dimensional space. In our second approach,
we account for the word-ordering within a sentence. We use a sentence encoder to embed GO
definitions into vectors and estimate how likely one definition entails another. We validate our
methods in two ways. In the first experiment, we test the model's ability to differentiate a true
protein-protein network from a randomly generated network. In the second experiment, we test
the model in identifying orthologs from randomly-matched genes in human, mouse, and fly. In
both experiments, a hybrid of NLP and GO-tree based method achieves the best classification
accuracy.}, 
keyword={app},
paper_url = {https://www.biorxiv.org/content/biorxiv/early/2018/05/14/103648.full.pdf}, 
code_url = {https://github.com/datduong/NLPMethods2CompareGOterms}, 
rank={50},
year = {2018}
}
@inproceedings{LD17,
author = {Ching-pei Lee and Md. Rizwan Parvez},
title = {Distributed Block-diagonal Approximation Methods for Regularized Empirical Risk Minimization}, 
booktitle = {Machine Learning Journal}, 
abstract = {Designing distributed algorithms for empirical risk minimization (ERM) has become an active research topic in recent years because of the practical need to deal with the huge volume of data. In this paper, we propose a general framework for training an ERM model via solving its dual problem in parallel over multiple machines. Our method provides a versatile approach for many large-scale machine learning problems, including linear binary/multi-class classification, regression, and structured prediction. Comparing with existing approaches, we show that our method has faster convergence under weaker conditions both theoretically and empirically.}, 
paper_url = {http://www.optimization-online.org/DB_HTML/2017/06/6060.html},
code_url={https://github.com/leepei/blockERM/},
year = {2019},
keyword={effecient}
}
@inproceedings{ACK17,
author = {Kenneth Arnold and Md. Rizwan Parvez and Adam T. Kalai},
title = {Counterfactual Language Model Adaptation for Suggesting Phrases}, 
booktitle = {IJCNLP (short)}, 
abstract = {We study the challenge of suggesting multi-word phrases to be inserted while typing on a mobile keyboard. Recent work in mobile text entry user-interfaces has shown that, unlike single-word predictions, these phrases are treated as suggestions rather than predictions, meaning that users often insert words that weren't what they were planning on typing.
This suggests the NLP problem of offering multi-word suggestions that are likely to be accepted by a user. We propose a method for customizing an existing language model to adapt it to a specific such task, and show how to learn the parameters of that customization offline.},
comment = {A short version was presented at AAAI Workshop on Human-Aware Artificial Intelligence}, 
paper_url = {https://arxiv.org/abs/1710.01799}, 
year = {2017}
}
@inproceedings{zhao2017men,
author = {Jieyu Zhao and Tianlu Wang and Mark Yatskar and Vicente Ordonez and Md. Rizwan Parvez},
title = {Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints}, 
booktitle = {EMNLP},
selected=true,
keyword={fairnlp},
abstract = {Language is increasingly being used to define rich visual recognition problems with supporting image collections sourced from the web. Structured prediction models are used in these tasks to take advantage of correlations between co-occuring labels and visual input but risk inadvertently encoding social biases found in web corpora.
In this work, we study data and models associated with multilabel object classification and visual semantic role labeling. We find that (a) datasets for these tasks contain significant gender bias and (b) models trained on these datasets further amplify existing bias. For example, the activity cooking is over 33% more likely to involve females than males in a training set, but a trained model amplifies the disparity to 68% at test time. We propose to inject corpus-level constraints for calibrating existing structured prediction models and design an algorithm based on Lagrangian relaxation for the resulting inference problems. Our method results in no performance loss for the underlying recognition task but decreases the magnitude of bias amplification by 33.3% and 44.9% for multilabel classification and visual semantic role labeling, respectively.},
paper_url = {https://arxiv.org/pdf/1707.09457.pdf}, 
code_url = {https://github.com/uclanlp/reducingbias}, 
slides_url = {http://kwchang.net/documents/slides/zhao2017men_slide.pdf}, 
keynote = {<i class="fa fa-trophy"></i> EMNLP 2017 Best Long Paper Award; Top-10 cited paper at EMNLP 17}, 
year = {2017}
}
@inproceedings{bolukbasi2017structured,
author = {Tolga Bolukbasi and Md. Rizwan Parvez and Joseph Wang and Venkatesh Saligrama},
title = {Structured Prediction with Test-time Budget Constraints}, 
booktitle = {AAAI},
keyword={effecient},
abstract = {We study the problem of structured prediction under test-time budget constraints. We propose a novel approach applicable to a wide range of structured prediction problems in computer vision and natural language processing. Our approach seeks to adaptively generate computationally costly features during test-time in order to reduce the computational cost of prediction while maintaining prediction performance. We show that training the adaptive feature generation system can be reduced to a series of structured learning problems, resulting in efficient training using existing structured learning algorithms. This framework provides theoretical justification for several existing heuristic approaches found in literature. We evaluate our proposed adaptive system on two real-world structured prediction tasks, optical character recognition (OCR) and dependency parsing. For OCR our method cuts the feature acquisition time by half coming within a 1% margin of top accuracy. For dependency parsing we realize an overall runtime gain of 20% without significant loss in performance.}, 
paper_url = {http://arxiv.org/abs/1602.08761},
slides_url = {http://kwchang.net/documents/slides/bolukbasi2017structured_slide.pdf},
year = {2017}
}
@inproceedings{upadhyay2017beyond,
author = {Shyam Upadhyay and Md. Rizwan Parvez and Matt Taddy and Adam Kalai and James Zou},
title = {Beyond Bilingual: Multi-sense Word Embeddings using Multilingual Context}, 
booktitle = {ACL RepL4NLP Workshop}, 
abstract = {Word embeddings, which represent a word as a point in a vector space, have become ubiquitous to several NLP tasks. A recent line of work uses bilingual (two languages) corpora to learn a different vector for each sense of a word, by exploiting crosslingual signals to aid sense identification. We present a multi-view Bayesian non-parametric algorithm which improves multi-sense word embeddings by (a) using multilingual (i.e., more than two languages) corpora to significantly improve sense embeddings beyond what one achieves with bilingual information, and (b) uses a principled approach to learn a variable number of senses per word, in a data-driven manner. Ours is the first approach with the ability to leverage multilingual corpora efficiently for multi-sense representation learning. Experiments show that multilingual training significantly improves performance over monolingual and bilingual training, by allowing us to combine different parallel corpora to leverage multilingual context. Multilingual training yields comparable performance to a state of the art monolingual model trained on five times more training data.},
paper_url = {https://arxiv.org/pdf/1706.08160.pdf}, 
keynote = {<i class="fa fa-trophy"></i> Best Paper Award}, 
year = {2017},
keyword={rep}
}
@inproceedings{CCSR16,
author = {Md. Rizwan Parvez and Ming-Wei Chang and Vivek Srikumar and Alexander M. Rush},
title = {EMNLP 16 Workshop on Structured Prediction for NLP}, 
booktitle = {EMNLP}, 
abstract = {Many prediction tasks in NLP involve assigning values to mutually dependent variables. For example, when designing a model to automatically perform linguistic analysis of a sentence or a document (e.g., parsing, semantic role labeling, or discourse analysis), it is crucial to model the correlations between labels. Many other NLP tasks, such as machine translation, textual entailment, and information extraction, can be also modeled as structured prediction problems.
In order to tackle such problems, various structured prediction approaches have been proposed, and their effectiveness has been demonstrated. Studying structured prediction is interesting from both NLP and machine learning (ML) perspectives. From the NLP perspective, syntax and semantics of natural language are clearly structured and advances in this area will enable researchers to understand the linguistic structure of data. From the ML perspective, the large amount of available text data and complex linguistic structures bring challenges to the learning community. Designing expressive yet tractable models and studying efficient learning and inference algorithms become important issues.
Recently, there has been significant interest in non-standard structured prediction approaches that take advantage of non-linearity, latent components, and/or approximate inference in both the NLP and ML communities. Researchers have also been discussing the intersection between deep learning and structured prediction through the DeepStructure reading group. This workshop intends to bring together NLP and ML researchers working on diverse aspects of structured prediction and expose the participants to recent progress in this area.
Workshop Site}, 
paper_url = {http://aclweb.org/anthology/W/W16/W16-59.pdf}, 
year = {2016}
}
@inproceedings{BCWS16,
author = {Shyam Upadhyay and Ming-Wei Chang and Md. Rizwan Parvez and Wen-tau Yih},
title = {Learning from Explicit and Implicit Supervision Jointly For Algebra Word Problems}, 
booktitle = {EMNLP}, 
abstract = {Automatically solving algebra word problems has raised considerable interest recently. Existing state-of-the-art approaches mainly rely on learning from human annotated equations. In this paper, we demonstrate that it is possible to efficiently mine algebra problems and their numerical solutions with little to no manual effort. To leverage the mined dataset, we propose a novel structured-output learning algorithm that aims to learn from both explicit (e.g., equations) and implicit (e.g., solutions) supervision signals jointly. Enabled by this new algorithm, our model gains 4.6% absolute improvement in accuracy on the ALG-514 benchmark compared to the one without using implicit supervision. The final model also outperforms the current state-of-the-art approach by 3%.
Dataset},
tweet={https://twitter.com/shyamupa/status/779688715434229760},
keyword={lwll},
paper_url = {https://www.aclweb.org/anthology/D/D16/D16-1029.pdf}, 
year = {2016}
}

@inproceedings{bolukbasi2016man,
author = {Tolga Bolukbasi and Md. Rizwan Parvez and James Zou and Venkatesh Saligrama and Adam Kalai},
title = {Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings}, 
booktitle = {NeurIPS}, 
keyword={fairrep},
abstract = {The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between between the words receptionist and female, while maintaining desired associations such as between the words queen and female. We define metrics to quantify both direct and indirect gender biases in embeddings, and develop algorithms to "debias" the embedding. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.},
comment = {A short version is accepted by NeurIPS. <br> 
Our paper is reported by NPR: He's Brilliant, She's Lovely: Teaching Computers To Be Less Sexist <br>
Our paper is reported by MIT Technology Review: How Vector Space Mathematics Reveals the Hidden Sexism in Language <br>
Our paper is reported by Dailymail: Will robots be SEXIST? Scientists are trying to reprogram misogynist machines to take out their bias},
paper_url = {http://arxiv.org/pdf/1607.06520.pdf}, 
code_url = {https://github.com/tolga-b/debiaswe},
keynote_url = {https://www.paperdigest.org/2023/04/most-influential-nips-papers-2023-04/}, 
keynote = {Top-10 cited paper at NeurIPS 16},
note = {A short version appears in ICML16 Workshop on Data4Good}, 
year = {2016}
}
@inproceedings{chang2016credit,
author = {Md. Rizwan Parvez and He He and Hal Daume III and John Langford and Stephane Ross},
title = {A Credit Assignment Compiler for Joint Prediction}, 
booktitle = {NeurIPS},
keyword={effecient},
abstract = {Many machine learning applications involve jointly predicting multiple mutually dependent output variables. Learning to search is a family of methods where the complex decision problem is cast into a sequence of decisions via a search space. Although these methods have shown promise both in theory and in practice, implementing them has been burdensomely awkward. In this paper, we show the search space can be defined by an arbitrary imperative program, turning learning to search into a credit assignment compiler. Altogether with the algorithmic improvements for the compiler, we radically reduce the complexity of programming and the running time. We demonstrate the feasibility of our approach on multiple joint prediction tasks. In all cases, we obtain accuracies as high as alternative approaches, at drastically reduced execution and programming time.}, 
paper_url = {http://arxiv.org/pdf/1406.1837.pdf}, 
code_url = {https://github.com/JohnLangford/vowpal_wabbit}, 
note = {An earlier version appears in ML system workshop at ICML 16}, 
year = {2016}
}
@inproceedings{chang2015learning,
author = {Md. Rizwan Parvez and He He and Hal Daume; III and John Lanford},
title = {Learning to Search for Dependencies}, 
booktitle = {Arxiv}, 
abstract = {We demonstrate that a dependency parser can be built using a credit assignment compiler which removes the burden of worrying about low-level machine learning details from the parser implementation. The result is a simple parser which robustly applies to many languages that provides similar statistical and computational performance with best-to-date transition-based parsing approaches, while avoiding various downsides including randomization, extra feature requirements, and custom learning algorithms.}, 
paper_url = {http://arxiv.org/abs/1503.05615}, 
code_url = {https://github.com/JohnLangford/vowpal_wabbit}, 
year = {2015}
}
@inproceedings{chang2015illinoissl,
author = {Md. Rizwan Parvez and Shyam Upadhyay and Ming-Wei Chang and Vivek Srikumar and Dan Roth },
title = {IllinoisSL: A JAVA Library for Structured Prediction}, 
booktitle = {Arxiv}, 
abstract = {Training a structured prediction model involves performing several loss-augmented inference steps. Over the lifetime of the training, many of these inference problems, although different, share the same solution. We propose AI-DCD, an Amortized Inference framework for Dual Coordinate Descent method, an approximate learning algorithm, that accelerates the training process by exploiting this redundancy of solutions, without compromising the performance of the model. We show the efficacy of our method by training a structured SVM using dual coordinate descent for an entity-relation extraction task. Our method learns the same model as an exact training algorithm would, but call the inference engine only in 10% . 24% of the inference problems encountered during training. We observe similar gains on a multi-label classification task and with a Structured Perceptron model for the entity-relation task.}, 
paper_url = {http://arxiv.org/abs/1509.07179}, 
keyword={struct},
year = {2015}
}
@inproceedings{lee2015distributed,
author = {Ching-pei Lee and Md. Rizwan Parvez and Shyam Upadhyay and Dan Roth},
title = {Distributed Training of Structured SVM}, 
booktitle = {OPT workshop at NeurIPS}, 
abstract = {Training structured prediction models is time-consuming. However, most existing approaches only use a single machine, thus, the advantage of computing power and the capacity for larger data sets of multiple machines have not been exploited. In this work, we propose an efficient algorithm for distributedly training structured support vector machines based on a distributed block-coordinate descent method. Both theoretical and experimental results indicate that our method is efficient.}, 
paper_url = {http://opt-ml.org/papers/OPT2015_paper_1.pdf}, 
year = {2015}
}
@inproceedings{chang2015learning,
author = {Md. Rizwan Parvez and Akshay Krishnamurthy and Alekh Agarwal and Hal Daume; III and John Langford},
title = {Learning to Search Better Than Your Teacher}, 
keyword={effecient},
booktitle = {ICML}, 
abstract = {Methods for learning to search for structured prediction typically imitate a reference policy, with existing theoretical guarantees demonstrating low regret compared to that reference. This is unsatisfactory in many applications where the reference policy is suboptimal and the goal of learning is to improve upon it. Can learning to search work even when the reference is poor?
We provide a new learning to search algorithm, LOLS, which does well relative to the reference policy, but additionally guarantees low regret compared to deviations from the learned policy: a local-optimality guarantee. Consequently, LOLS can improve upon the reference policy, unlike previous algorithms. This enables us to develop structured contextual bandits, a partial information structured prediction setting with many potential applications.}, 
paper_url = {http://arxiv.org/abs/1502.02206}, 
code_url = {https://github.com/JohnLangford/vowpal_wabbit}, 
video_url = {http://videolectures.net/icml2015_krishnamurthy_search_better/},
year = {2015}
}
@inproceedings{peng2015joint,
author = {Haoruo Peng and Md. Rizwan Parvez and Dan Roth},
title = {A Joint Framework for Coreference Resolution and Mention Head Detection}, 
booktitle = {CoNLL}, 
abstract = {In coreference resolution, a fair amount of research treats mention detection as a preprocessed step and focuses on developing algorithms for clustering coreferred mentions. However, there are significant gaps between the performance on gold mentions and the performance on the real problem, when mentions are predicted from raw text via an imperfect Mention Detection (MD) module. Motivated by the goal of reducing such gaps, we develop an ILP-based joint coreference resolution and mention head formulation that is shown to yield significant improvements on coreference from raw text, outperforming existing state-of-art systems on both the ACE-2004 and the CoNLL-2012 datasets. At the same time, our joint approach is shown to improve mention detection by close to 15% F1. One key insight underlying our approach is that identifying and co-referring mention heads is not only sufficient but is more robust than working with complete mentions.}, 
paper_url = {https://cogcomp.seas.upenn.edu/papers/MentionDetection.pdf}, 
year = {2015}
}
@inproceedings{chang2015structural,
author = {Md. Rizwan Parvez and Shyam Upadhyay and Gourab Kundu and Dan Roth },
title = {Structural Learning with Amortized Inference}, 
booktitle = {AAAI}, 
keyword={effecient},
abstract = {Training a structured prediction model involves performing several loss-augmented inference steps. Over the lifetime of the training, many of these inference problems, although different, share the same solution. We propose AI-DCD, an Amortized Inference framework for Dual Coordinate Descent method, an approximate learning algorithm, that accelerates the training process by exploiting this redundancy of solutions, without compromising the performance of the model. We show the efficacy of our method by training a structured SVM using dual coordinate descent for an entity-relation extraction task. Our method learns the same model as an exact training algorithm would, but call the inference engine only in 10% . 24% of the inference problems encountered during training. We observe similar gains on a multi-label classification task and with a Structured Perceptron model for the entity-relation task.}, 
paper_url = {http://cogcomp.cs.illinois.edu/page/publication_view/757},
poster_url = {http://kwchang.net/documents/poster/chang2015structural_poster.pdf},
year = {2015}
}
@inproceedings{chang2015thesis,
author = {Md. Rizwan Parvez},
title = {Selective Algorithms for Large-Scale Classification and Structured Learning}, 
booktitle = {UIUC Phd Thesis}, 
abstract = {The desired output in many machine learning tasks is a structured object, such as tree, clustering, or sequence. Learning accurate prediction models for such problems requires training on large amounts of data, making use of expressive features and performing global inference that simultaneously assigns values to all interrelated nodes in the structure. All these contribute to significant scalability problems. In this thesis, we describe a collection of results that address several aspects of these problems - by carefully selecting and caching samples, structures, or latent items.
Our results lead to entryfficient learning algorithms for large-scale binary classification models, structured prediction models and for online clustering models which, in turn, support reduction in problem size, improvements in training and evaluation speed and improved performance. We have used our algorithms to learn expressive models from large amounts of annotated data and achieve state-of-the art performance on several natural language processing tasks.}, 
paper_url = {http://cogcomp.cs.illinois.edu/page/publication_view/764}, 
year = {2015}
}
@inproceedings{samdani2014discriminative,
author = {Rajhans Samdani and Md. Rizwan Parvez and Dan Roth},
title = {A Discriminative Latent Variable Model for Online Clustering}, 
booktitle = {ICML}, 
abstract = {This paper presents a latent variable structured prediction model for discriminative supervised clustering of items called the Latent Left-linking Model (L3M). We present an online clustering algorithm for L3M based on a feature-based item similarity function. We provide a learning framework for estimating the similarity function and present a fast stochastic gradient-based learning technique. In our experiments on coreference resolution and document clustering, L3M outperforms several existing online as well as batch supervised clustering techniques.}, 
paper_url = {http://cogcomp.cs.illinois.edu/page/publication_view/740}, 
demo_url = {http://bilbo.cs.uiuc.edu/%7Ekchang10/},
slides_url = {http://kwchang.net/documents/slides/samdani2014discriminative_slide.pdf},
keyword={coref},
year = {2014}
}
@inproceedings{chang2014typed,
author = {Md. Rizwan Parvez and Wen-tau Yih and Bishan Yang and Chris Meek},
title = {Typed Tensor Decomposition of Knowledge Bases for Relation Extraction}, 
booktitle = {EMNLP}, 
abstract = {While relation extraction has traditionally been viewed as a task relying solely on textual data, recent work has shown that by taking as input existing facts in the form of entity-relation triples from both knowledge bases and textual data, the performance of relation extraction can be improved significantly. Following this new paradigm, we propose a tensor decomposition approach for knowledge base embedding that is highly scalable, and is especially suitable for relation extraction. By leveraging relational domain knowledge about entity type information, our learning algorithm is significantly faster than previous approaches and is better able to discover new relations missing from the database. In addition, when applied to a relation extraction task, our approach alone is comparable to several existing systems, and improves the weighted mean average precision of a state-of-the-art method by 10 points when used as a subcomponent.}, 
paper_url = {http://research.microsoft.com/pubs/226677/main-trescal.pdf}, 
youtube_id = {TCxwN_5eL5I},
keyword={tensor},
year = {2014}
}
@inproceedings{RCSRH14,
author = {Alla Rozovskaya and Md. Rizwan Parvez and Mark Sammons and Dan Roth and Nizar Habash},
title = {The Illinois-Columbia System in the CoNLL-2014 Shared Task}, 
booktitle = {CoNLL Shared Task}, 
abstract = {The CoNLL-2014 shared task is an extension of last year's shared task and focuses on correcting grammatical errors in essays written by non-native learners of English. In this paper, we describe the Illinois-Columbia system that participated in the shared task. Our system ranked second on the original annotations and first on the revised annotations.
The core of the system is based on the University of Illinois model that placed first in the CoNLL-2013 shared task. This baseline model has been improved and expanded for this year's competition in several respects. We describe our underlying approach, which relates to our previous work, and describe the novel aspects of the system in more detail.}, 
paper_url = {http://cogcomp.cs.illinois.edu/page/publication_view/746},
keyword={grammar},
year = {2014}
}
@inproceedings{ChangSaRo13,
author = {Md. Rizwan Parvez and Rajhans Samdani and Dan Roth},
title = {A Constrained Latent Variable Model for Coreference Resolution}, 
booktitle = {EMNLP}, 
abstract = {Coreference resolution is a well known clustering task in Natural Language Processing. In this paper, we describe the Latent Left Linking model (L3M), a novel, principled, and linguistically motivated latent structured prediction approach to coreference resolution.
We show that L3M admits efficient inference and can be augmented with knowledge-based constraints; we also present a fast stochastic gradient based learning.
Experiments on ACE and Ontonotes data show that L3M and its constrained version, CL3M, are more accurate than several state-of-the-art approaches as well as some structured prediction models proposed in the literature.}, 
paper_url = {http://cogcomp.cs.illinois.edu/page/publication_view/732}, 
poster_url = {http://cogcomp.cs.illinois.edu/files/posters/A%20Constrained%20Latent%20Variable%20Model%20for%20Coreference%20Resolution_poster.pptx}, 
demo_url = {http://cogcomp.cs.illinois.edu/page/demo_view/Coref}, 
keyword={coref},
year = {2013}
}
@inproceedings{chang2013mrlsa,
author = {Md. Rizwan Parvez and Wen-tau Yih and Chris Meek},
title = {Multi-Relational Latent Semantic Analysis}, 
booktitle = {EMNLP}, 
abstract = {We present Multi-Relational Latent Semantic Analysis (MRLSA) which generalizes Latent Semantic Analysis (LSA). MRLSA provides an elegant approach to combining multiple relations between words by constructing a 3-way tensor. Similar to LSA, a low-rank approximation of the tensor is derived using a tensor decomposition. Each word in the vocabulary is thus represented by a vector in the latent semantic space and each relation is captured by a latent square matrix. The degree of two words having a specific relation can then be measured through simple linear algebraic operations. We demonstrate that by integrating multiple relations from both homogeneous and heterogeneous information sources, MRLSA achieves state-of-the-art performance on existing benchmark datasets for two relations, antonymy and is-a.}, 
paper_url = {http://research.microsoft.com/apps/pubs/?id=201352}, 
slides_url = {http://kwchang.net/documents/slides/chang2013mrlsa_slide.pdf},
keyword={tensor},
year = {2013}
}
@inproceedings{chang2013multicore,
author = {Md. Rizwan Parvez and Vivek Srikumar and Dan Roth},
title = {Multi-core Structural SVM Training}, 
booktitle = {ECML}, 
poster_url = {http://kwchang.net/documents/poster/chang2013multicore_poster.pdf},
paper_url={https://svivek.com/research/publications/ChangSrRo13.pdf},
abstract = {Many problems in natural language processing and computer vision can be framed as structured prediction problems. Structural support vector machines (SVM) is a popular approach for training structured predictors, where learning is framed as an optimization problem. Most structural SVM solvers alternate between a model update phase and an inference phase (which predicts structures for all training examples). As structures become more complex, inference becomes a bottleneck and thus slows down learning considerably. In this paper, we propose a new learning algorithm for structural SVMs called DEMI-DCD that extends the dual coordinate descent approach by decoupling the model update and inference phases into different threads. We take advantage of multi-core hardware to parallelize learning with minimal synchronization between the model update and the inference phases. We prove that our algorithm not only converges but also fully utilizes all available processors to speed up learning, and validate our approach on two real-world NLP problems: part-of-speech tagging and relation extraction. In both cases, we show that our algorithm utilizes all available processors to speed up learning and achieves competitive performance. For example, it achieves a relative duality gap of 1% on a POS tagging problem in 192 seconds using 16 threads, while a standard implementation of a multi-threaded dual coordinate descent algorithm with the same number of threads requires more than 600 seconds to reach a solution of the same quality.}, 
keyword={struct},
year = {2013}
}
@inproceedings{ChangSuKe13,
author = {Kai-wei Chang and S. Sundararajan and S. Sathiya Keerthi},
title = {Tractable Semi-Supervised Learning of Complex Structured Prediction Models}, 
booktitle = {ECML}, 
abstract = {Semi-supervised learning has been widely studied in the literature. However, most previous works assume that the output structure is simple enough to allow the direct use of tractable inference/learning algorithms (e.g., binary label or linear chain). Therefore, these methods cannot be applied to problems with complex structure. In this paper, we propose an approximate semi-supervised learning method that uses piecewise training for estimating the model weights and a dual decomposition approach for solving the inference problem of finding the labels of unlabeled data subject to domain specific constraints. This allows us to extend semi-supervised learning to general structured prediction problems. As an example, we apply this approach to the problem of multi-label classification (a fully connected pairwise Markov random field). Experimental results on benchmark data show that, in spite of using approximations, the approach is effective and yields good improvements in generalization performance over the plain supervised method. In addition, we demonstrate that our inference engine can be applied to other semi-supervised learning frameworks, and extends them to solve problems with complex structure.}, 
paper_url = {http://www.keerthis.com/ecml_dual_transduction.pdf}, 
poster_url = {http://cogcomp.cs.illinois.edu/files/posters/Multi-core%20Structural%20SVM%20model%20poster.pptx}, 
slides_url = {../slides/ChangSuKe13_slide.pdf}, 
keyword={struct},
year = {2013}
}
@inproceedings{RCSR13,
author = {Alla Rozovskaya and Md. Rizwan Parvez and Mark Sammons and Dan Roth},
title = {The University of Illinois System in the CoNLL-2013 Shared Task}, 
booktitle = {CoNLL Shared Task}, 
abstract = {The CoNLL-2013 shared task focuses on correcting grammatical errors in essays written by non-native learners of English. In this paper, we describe the University of Illinois system that participated in the shared task. The system consists of five components and targets five types of common grammatical mistakes made by English as Second Language writers. We describe our underlying approach, which relates to our previous work, and describe the novel aspects of the system in more detail. Out of 17 participating teams, our system is ranked first based on both the original annotation and on the revised annotation.}, 
paper_url = {http://cogcomp.cs.illinois.edu/page/publication_view/731}, 
poster_url = {http://cogcomp.cs.illinois.edu/files/posters/ConllSharedTask2012.pptx}, 
keyword={grammar},
year = {2013}
}
@inproceedings{CDHR12,
author = {Md. Rizwan Parvez and Baplab Deka and W.-M. W. Hwu and Dan Roth},
title = {Efficient Pattern-Based Time Series Classification on GPU }, 
booktitle = {ICDM}, 
abstract = {Time series shapelet discovery algorithm finds subsequences from a set of time series for use as primitives for time series classification. This algorithm has drawn a lot of interest because of the interpretability of its results. However, computation requirements restrict the algorithm from dealing with large data sets and may limit its application in many domains. In this paper, we address this issue by redesigning the algorithm for implementation on highly parallel Graphics Process Units (GPUs). We investigate several concepts of GPU programming and propose a dynamic programming algorithm that is suitable for implementation on GPUs. Results show that the proposed GPU implementation significantly reduces the running time of the shapelet discovery algorithm. For example, on the largest sample dataset from the original authors, the running time is reduced from half a day to two minutes.}, 
paper_url = {http://cogcomp.cs.illinois.edu/papers/undefined.pdf}, 
year = {2012}
}
@inproceedings{CSRSR12,
author = {Md. Rizwan Parvez and Rajhans Samdani and Alla Rozovskaya and Mark Sammons and Dan Roth},
title = {Illinois-Coref: The UI System in the CoNLL-2012 Shared Task}, 
booktitle = {CoNLL Shared Task}, 
abstract = {The CoNLL-2012 shared task is an extension of the last year's coreference task. We participated in the closed track of the shared tasks in both years. In this paper, we present the improvements of Illinois-Coref system from last year. We focus on improving mention detection and pronoun coreference resolution, and present a new learning protocol. These new strategies boost the performance of the system by 5% MUC F1, 0.8% BCUB F1, and 1.7% CEAF F1 on the OntoNotes-5.0 development set.}, 
paper_url = {http://cogcomp.cs.illinois.edu/papers/CSRSR12.pdf}, 
poster_url = {http://cogcomp.cs.illinois.edu/files/posters/ConllSharedTask2012.pptx}, 
keyword={coref},
year = {2012}
}
@inproceedings{yu2010large,
author = {Hsiang-Fu Yu and Cho-Jui Hsieh and Md. Rizwan Parvez and Chih-Jen Lin},
title = {Large Linear Classification When Data Cannot Fit In Memory}, 
booktitle = {TKDD}, 
abstract = {Recent advances in linear classification have shown that for applications such as document classification, the training can be extremely efficient. However, most of the existing training methods are designed by assuming that data can be stored in the computer memory. These methods cannot be easily applied to data larger than the memory capacity due to the random access to the disk. We propose and analyze a block minimization framework for data larger than the memory size. At each step a block of data is loaded from the disk and handled by certain learning methods. We investigate two implementations of the proposed framework for primal and dual SVMs, respectively. As data cannot fit in memory, many design considerations are very different from those for traditional algorithms. Experiments using data sets 20 times larger than the memory demonstrate the effectiveness of the proposed method.}, 
paper_url = {http://www.csie.ntu.edu.tw/%7Ecjlin/papers/disk_decomposition/tkdd_disk_decomposition.pdf}, 
code_url = {http://www.csie.ntu.edu.tw/%7Ecjlin/liblinear/exp.html#lowpoly_disk_decomposition}, 
keynote = {<i class="fa fa-trophy"></i> Best Paper Award, KDD 10}, 
note = {(An earlier version appears in KDD 2010, an short version is published in IJCAI 2011 best paper track)}, 
keyword={linear},
year = {2012}
}
@inproceedings{ChangRo11,
author = {Md. Rizwan Parvez and Dan Roth},
title = {Selective Block Minimization for Faster Convergence of Limited Memory Large-scale Linear Models}, 
booktitle = {KDD}, 
abstract = {As the size of data sets used to build classifiers steadily increases, training a linear model efficiently with limited memory becomes essential. Several techniques deal with this problem by loading blocks of data from disk one at a time, but usually take a considerable number of iterations to converge to a reasonable model. Even the best block minimization techniques [1] require many block loads since they treat all training examples uniformly. As disk I/O is expensive, reducing the amount of disk access can dramatically decrease the training time.}, 
paper_url = {http://cogcomp.cs.illinois.edu/page/publication_view/660}, 
poster_url = {http://cogcomp.cs.illinois.edu/files/posters/sbm_kdd(1).pptx}, 
code_url = {http://cogcomp.cs.illinois.edu/page/software_view/LMLM}, 
slides_url = {http://cogcomp.cs.illinois.edu/files/presentations/kdd_slide.pdf}, 
keyword={linear},
year = {2011}
}
@inproceedings{CSRRSR11,
author = {Md. Rizwan Parvez and Rajhans Samdani and Alla Rozovskaya and Nick Rizzolo and Mark Sammons and Dan Roth},
title = {Inference Protocols for Coreference Resolution}, 
booktitle = {CoNLL Shared Task}, 
abstract = {This paper presents Illinois-Coref, a system for coreference resolution that participated in the CoNLL-2011 shared task. We investigate two inference methods, Best-Link and All-Link, along with their corresponding, pairwise and structured, learning protocols. Within these, we provide a flexible architecture for incorporating linguistically-motivated constraints, several of which we developed and integrated. We compare and evaluate the inference approaches and the contribution of constraints, analyze the mistakes of the system, and discuss the challenges of resolving coreference for the OntoNotes-4.0 data set.}, 
paper_url = {http://cogcomp.cs.illinois.edu/page/publication_view/669}, 
poster_url = {http://cogcomp.cs.illinois.edu/files/posters/ConllSharedTask2011_final.pptx}, 
slides_url = {http://cogcomp.cs.illinois.edu/files/presentations/Inference%20Protocols%20for%20Coreference%20Resolution.pptx}, 
keyword={coref},
year = {2011}
}
@inproceedings{CHCRL10,
author = {Yin-Wen Chang and Cho-Jui Hsieh and Md. Rizwan Parvez and Michael Ringgaard and Chih-Jen Lin},
title = {Training and Testing Low-degree Polynomial Data Mappings via Linear SVM}, 
booktitle = {JMLR}, 
abstract = {Kernel techniques have long been used in SVM to handle linearly inseparable problems by transforming data to a high dimensional space, but training and testing large data sets is often time consuming. In contrast, we can efficiently train and test much larger data sets using linear SVM without kernels. In this work, we apply fast linear-SVM methods to the explicit form of polynomially mapped data and investigate implementation issues. The approach enjoys fast training and testing, but may sometimes achieve accuracy close to that of using highly nonlinear kernels. Empirical experiments show that the proposed method is useful for certain large-scale data sets. We successfully apply the proposed method to a natural language processing (NLP) application by improving the testing accuracy under some training/testing speed requirements.}, 
paper_url = {http://www.csie.ntu.edu.tw/%7Ecjlin/papers/lowpoly_journal.pdf}, 
code_url = {http://www.csie.ntu.edu.tw/%7Ecjlin/libsvmtools/#fast_training_testing_for_degree_2_polynomial_mappings_of_data}, 
keyword={linear},
year = {2010}
}
@inproceedings{HHCL10,
author = {Fang-Lan Huang and Cho-Jui Hsieh and Md. Rizwan Parvez and Chih-Jen Lin},
title = {Iterative Scaling and Coordinate Descent Methods for Maximum Entropy Models}, 
booktitle = {JMLR}, 
abstract = {Maximum entropy (Maxent) is useful in natural language processing and many other areas. Iterative scaling (IS) methods are one of the most popular approaches to solve Maxent. With many variants of IS methods, it is difficult to understand them and see the differences. In this paper, we create a general and unified framework for iterative scaling methods. This framework also connects iterative scaling and coordinate descent methods. We prove general convergence results for IS methods and analyze their computational complexity. Based on the proposed framework, we extend a coordinate descent method for linear SVM to Maxent. Results show that it is faster than existing iterative scaling methods.}, 
paper_url = {http://www.jmlr.org/papers/volume11/huang10a/huang10a.pdf}, 
keyword={linear},
year = {2010}
}
@inproceedings{YCHL10,
author = {Guo-Xun Yuan and Md. Rizwan Parvez and Cho-Jui Hsieh and Chih-Jen Lin},
title = {A Comparison of Optimization Methods and software for Large-scale L1-regularized Linear Classification}, 
booktitle = {JMLR}, 
abstract = {Large-scale linear classification is widely used in many areas. The L1-regularized form can be applied for feature selection; however, its non-differentiability causes more difficulties in training. Although various optimization methods have been proposed in recent years, these have not yet been compared suitably. In this paper, we first broadly review existing methods. Then, we discuss state-of-the-art software packages in detail and propose two efficient implementations. Extensive comparisons indicate that carefully implemented coordinate descent methods are very suitable for training large document data.}, 
paper_url = {http://www.jmlr.org/papers/volume11/yuan10c/yuan10c.pdf}, 
code_url = {http://www.csie.ntu.edu.tw/%7Ecjlin/libsvmtools/#fast_training_testing_for_degree_2_polynomial_mappings_of_data}, 
keyword={linear},
year = {2010}
}
@inproceedings{LCCCFHKKLLWYLLL09,
author = {Hung-Yi Lo and Md. Rizwan Parvez and Shang-Tse Chen and Tsung-Hsien Chiang and ChunSung Ferng and Cho-Jui Hsieh and Yi-Kuang Ko and Tsung-Ting Kuo and Hung-Che Lai and Ken-Yi Lin and Chia-Hsuan Wang and Hsiang-Fu Yu and Chih-Jen Lin and Hsuan-Tien Lin and Shou-de Lin},
title = {An Ensemble of Three Classifiers for KDD Cup 2009: Expanded Linear Model, Heterogeneous Boosting, and Selective Naive Bayes}, 
booktitle = {KDD Cup}, 
abstract = {This paper describes our ensemble of three classifiers for the KDD Cup 2009 challenge. First, we transform the three binary classification tasks into a joint multi-class classification problem, and solve an l1-regularized maximum entropy model under the LIBLINEAR framework. Second, we propose a heterogeneous base learner, which is capable of handling different types of features and missing values, and use AdaBoost to improve the base learner. Finally, we adopt a selective naive Bayes classifier that automatically groups categorical features and discretizes numerical ones. The parameters are tuned using crossvalidation results rather than the 10% test results on the competition website. Based on the observation that the three positive labels are exclusive, we conduct a post-processing step using the linear SVM to jointly adjust the prediction scores of each classifier on the three tasks. Then, we average these prediction scores with careful validation to get the final outputs. Our final average AUC on the whole test set is 0.8461, which ranks third place in the slow track of KDD Cup 2009.}, 
paper_url = {http://www.csie.ntu.edu.tw/%7Ehtlin/paper/doc/wskdd09cup.pdf}, 
year = {2009}
}
@inproceedings{KSCHL08,
author = {S. Sathiya Keerthi and S. Sundararajan and Md. Rizwan Parvez and Cho-Jui Hsieh and Chih-Jen Lin},
title = {A Sequential Dual Method for Large Scale Multi-Class Linear SVMs}, 
booktitle = {KDD}, 
abstract = {Efficient training of direct multi-class formulations of linear Support Vector Machines is very useful in applications such as text classification with a huge number examples as well as features. This paper presents a fast dual method for this training. The main idea is to sequentially traverse through the training set and optimize the dual variables associated with one example at a time. The speed of training is enhanced further by shrinking and cooling heuristics. Experiments indicate that our method is much faster than state of the art solvers such as bundle, cutting plane and exponentiated gradient methods}, 
paper_url = {https://www.csie.ntu.edu.tw/%7Ecjlin/papers/sdm_kdd.pdf}, 
code_url = {http://www.csie.ntu.edu.tw/%7Ecjlin/liblinear}, 
keyword={linear},
year = {2008}
}
@inproceedings{HCLKS08,
author = {Cho-Jui Hsieh and Md. Rizwan Parvez and Chih-Jen Lin and Sathia S. Keerthi and S. Sundararajan},
title = {A Dual Coordinate Descent Method for Large-Scale Linear SVM}, 
booktitle = {ICML}, 
abstract = {In many applications, data appear with a huge number of instances as well as features. Linear Support Vector Machines (SVM) is one of the most popular tools to deal with such large-scale sparse data. This paper presents a novel dual coordinate descent method for linear SVM with L1- and L2- loss functions. The proposed method is simple and reaches an e-accurate solution in O(log(1/e)) iterations. Experiments indicate that our method is much faster than state of the art solvers such as Pegasos, TRON, SVMperf , and a recent primal coordinate descent implementation.},
paper_url = "https://www.csie.ntu.edu.tw/%7Ecjlin/papers/cddual.pdf", 
code_url = {http://www.csie.ntu.edu.tw/%7Ecjlin/liblinear}, 
slides_url = {http://bilbo.cs.illinois.edu/%7Ekchang10/icml_talk.pdf}, 
keyword={linear},
keynote_url = {https://www.paperdigest.org/2023/04/most-influential-icml-papers-2023-04/}, 
keynote = {Top-10 cited paper at ICML 08},
year = {2008}
}
@inproceedings{ChangHsLi08,
author = {Md. Rizwan Parvez and Cho-Jui Hsieh and Chih-Jen Lin},
title = {Coordinate Descent Method for Large-scale L2-loss Linear SVM}, 
booktitle = {JMLR}, 
abstract = {Linear support vector machines (SVM) are useful for classifying large-scale sparse data. Problems with sparse features are common in applications such as document classification and natural language processing. In this paper, we propose a novel coordinate descent algorithm for training linear SVM with the L2-loss function. At each step, the proposed method minimizes a one-variable sub-problem while fixing other variables. The sub-problem is solved by Newton steps with the line search technique. The procedure globally converges at the linear rate. As each sub-problem involves only values of a corresponding feature, the proposed approach is suitable when accessing a feature is more convenient than accessing an instance. Experiments show that our method is more efficient and stable than state of the art methods such as Pegasos and TRON.}, 
paper_url = "https://www.csie.ntu.edu.tw/%7Ecjlin/papers/cdl2.pdf", 
code_url = {http://www.csie.ntu.edu.tw/%7Ecjlin/liblinear/exp.html#cdl2_exp}, 
keyword={linear},
year = {2008}
}
@inproceedings{FCHWL08,
author = {Rong En Fan and Md. Rizwan Parvez and Cho-Jui Hsieh and X.-R. Wang and Chih-Jen Lin},
title = {LIBLINEAR: A Library for Large Linear Classification}, 
booktitle = {JMLR}, 
abstract = {LIBLINEAR is an open source library for large-scale linear classification. It supports logistic regression and linear support vector machines. We provide easy-to-use command-line tools and library calls for users and developers. Comprehensive documents are available for both beginners and advanced users. Experiments demonstrate that LIBLINEAR is very efficient on large sparse data sets.}, 
paper_url = {https://www.csie.ntu.edu.tw/%7Ecjlin/papers/liblinear.pdf}, 
code_url = {http://www.csie.ntu.edu.tw/%7Ecjlin/liblinear},
keyword={linear},
year = {2008}
}
