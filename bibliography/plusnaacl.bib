@inproceedings{sheng2021societal,
  title={Societal Biases in Language Generation: Progress and Challenges},
  author={Sheng, Emily and Chang, Kai-Wei and Natarajan, Premkumar and Peng, Nanyun},
  booktitle={ACL},
  paper_url={https://arxiv.org/abs/2105.04054},
  rank = {31},
  keyword={fairness},
  selected=true,
  year={2021}
}

@inproceedings{sun2021men,
  title={Men Are Elected, Women Are Married: Events Gender Bias on Wikipedia},
  author={Sun, Jiao and Peng, Nanyun},
  booktitle={ACL},
  paper_url={https://arxiv.org/abs/2106.01601},
  rank = {30},
  keyword={fairness},
  year={2021}
}

@inproceedings{stowe2021metaphor,
  title={Metaphor Generation with Conceptual Mappings},
  author={Stowe, Kevin and Chakrabarty, Tuhin and Peng, Nanyun and Muresan, Smaranda and Gurevych, Iryna},
  booktitle={ACL},
  paper_url={https://arxiv.org/abs/2106.01228},
  rank = {32},
  keyword={fig_gen},
  selected=true,
  year={2021}
}

@inproceedings{sw2021com,
  title={COM2SENSE: A Commonsense Reasoning Benchmark with Complementary Sentences},
  author={Singh, Shikhar and Wen, Nuan and Hou, Yu and Alipoormolabashi, Pegah and Wu, Te-lin and Ma, Xuezhe and Peng, Nanyun},
  booktitle={ACL-Findings},
  paper_url={https://arxiv.org/abs/2106.00969},
  rank = {34},
  keyword={commonsense},
  year={2021}
}

@inproceedings{tian2021hypogen,
  title={HypoGen: Hyperbole Generation with Commonsense and Counterfactual Knowledge},
  author={Tian, Yufei and Sridhar, Arvind krishna and Peng, Nanyun},
  booktitle={EMNLP-Finding},
  year={2021},
  rank = {28},
  presentation_time={FINDINGS PAPERS - GENERATION},
  presentation_id={https://underline.io/events/192/sessions/7923/lecture/38307-hypogen-hyperbole-generation-with-commonsense-and-counterfactual-knowledge},
  paper_url={https://arxiv.org/pdf/2109.05097.pdf},
  video_url={https://screencast-o-matic.com/watch/cr6lnNVXtsh},
  abstract={ A hyperbole is an intentional and creative exaggeration not to be taken literally. Despite its ubiquity in daily life, the computational explorations of hyperboles are scarce. In this paper, we tackle the under-explored and challenging task: sentence-level hyperbole generation. We start with a representative syntactic pattern for intensification and systematically study the semantic (commonsense and counterfactual) relationships between each component in such hyperboles. We then leverage commonsense and counterfactual inference to generate hyperbole candidates based on our findings from the pattern, and train neural classifiers to rank and select high-quality hyperboles. Automatic and human evaluations show that our generation method is able to generate hyperboles creatively with high success rate and intensity.},
}

@inproceedings{sun2021aesop,
  title={AESOP: Paraphrase Generation with Adaptive Syntactic Control},
  author={Sun, Jiao and Ma, Xuezhe and Peng, Nanyun},
  booktitle={EMNLP},
  presentation_time={VIRTUAL POSTER SESSION II: GENERATION},
  presentation_id={https://underline.io/events/192/posters/8242/poster/37911-aesop-paraphrase-generation-with-adaptive-syntactic-control},
  keyword={control_gen},
  rank={21},
  year={2021}
}

@inproceedings{huang2021tempgen,
  title={Document-level Entity-based Extraction as Template Generation},
  author={Huang, Kung-Hsiang and Tang, Sam and Peng, Nanyun},
  booktitle={EMNLP},
  rank={20},
  keyword={gen_ie},
  presentation_time={VIRTUAL POSTER SESSION II: INFORMATION EXTRACTION},
  presentation_id={https://underline.io/events/192/posters/8243/poster/37467-document-level-entity-based-extraction-as-template-generation},
  year={2021}
}

@inproceedings{dou2021improving,
  title={Improving Pre-trained Vision-and-Language Embeddings for Phrase Grounding},
  author={Dou, Zi-Yi and Peng, Nanyun},
  booktitle={EMNLP},
  rank={25},
  presentation_time={VIRTUAL POSTER SESSION II: SPEECH, VISION, ROBOTICS, MULTIMODAL GROUNDING},
  presentation_id={https://underline.io/events/192/posters/8255/poster/37595-improving-pre-trained-vision-and-language-embeddings-for-phrase-grounding},
  keyword={multimodal},
  year={2021}
}
@inproceedings{han2021econet,
  title={ECONET: Effective Continual Pretraining of Language Models for Event Temporal Reasoning},
  author={Han, Rujun and Ren, Xiang and Peng, Nanyun},
  booktitle={EMNLP},
  presentation_time={VIRTUAL POSTER SESSION II: INFORMATION EXTRACTION},
  presentation_id={https://underline.io/events/192/posters/8243/poster/37875-econet-effective-continual-pretraining-of-language-models-for-event-temporal-reasoning},
  paper_url={https://arxiv.org/pdf/2012.15283.pdf},
  code_url={https://github.com/PlusLabNLP/ECONET},
  rank={24},
  keyword={event_rel},
  year={2021}
}

@inproceedings{han2021ester,
  title={ESTER: A Machine Reading Comprehension Dataset for Event Semantic Relation Reasoning},
  author={Han, Rujun and Hsu, I-Hung and Sun, Jiao and Baylon, Julia and Ning, Qiang and Roth, Dan and Peng, Nanyun},
  booktitle={EMNLP},
  presentation_time={7D: RESOURCES AND EVALUATION 3},
  presentation_id={https://underline.io/events/192/sessions/7816/lecture/37869-ester-a-machine-reading-comprehension-dataset-for-reasoning-about-event-semantic-relations},
  paper_url={https://arxiv.org/pdf/2104.08350.pdf},
  code_url={https://github.com/PlusLabNLP/ESTER},
  rank={23},
  keyword={event_rel},
  year={2021}
}

@inproceedings{ma2021hyperexpan,
  title={HyperExpan: Taxonomy Expansion with Hyperbolic Representation Learning},
  author={Ma, Mingyu Derek  and
    Chen, Muhao  and
    Wu, Te-Lin and
    Peng, Nanyun},
  booktitle={EMNLP-Finding},
  year={2021},
  rank = {29},
  presentation_time={FINDINGS PAPERS - SEMANTICS: LEXICAL, SENTENCE LEVEL, TEXTUAL INFERENCE AND OTHER AREAS},
  presentation_id={https://underline.io/events/192/sessions/7934/lecture/38572-hyperexpan-taxonomy-expansion-with-hyperbolic-representation-learning},
  paper_url={https://arxiv.org/pdf/2109.10500.pdf},
  youtube_id={zUGIunzjfVE},
  slides_url = {https://mingyu.ma/pubs/hyperexpan/slides_EMNLP21.pdf},
  abstract={Taxonomies are valuable resources for many applications, but the limited coverage due to the expensive manual curation process hinders their general applicability. Prior works attempt to automatically expand existing taxonomies to improve their coverage by learning concept embeddings in Euclidean space, while taxonomies, inherently hierarchical, more naturally align with the geometric properties of a hyperbolic space. In this paper, we present HyperExpan, a taxonomy expansion algorithm that seeks to preserve the structure of a taxonomy in a more expressive hyperbolic embedding space and learn to represent concepts and their relations with a Hyperbolic Graph Neural Network (HGNN). Specifically, HyperExpan leverages position embeddings to exploit the structure of the existing taxonomies, and characterizes the concept profile information to support the inference on unseen concepts during training. Experiments show that our proposed HyperExpan outperforms baseline models with representation learning in a Euclidean feature space and achieves state-of-the-art performance on the taxonomy expansion benchmarks.}
}

@inproceedings{ghazarian2021plot,
  title={Plot-guided Adversarial Example Construction for Evaluating Open-domain Story Generation},
  author={Sarik Ghazarian and Zixi Liu and Akash S M and Ralph Weischedel and Aram Galstyan and Nanyun Peng},
  booktitle={The 2021 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  abstract={With the recent advances of open-domain story generation models, the lack of reliable automatic evaluation metrics becomes an increasingly imperative issue that hinders the development of such models. A critical bottleneck of obtaining a trustworthy learnable evaluation metric is the lack of high-quality training data for learning classifiers to efficiently distinguish between plausible and implausible machine-generated stories. Previous works relied on heuristically manipulate plausible examples to mimic possible system drawbacks such as repetition, contradiction, or irrelevant content in the text level, which can be unnatural and oversimplify the characteristics of implausible machine-generated stories. We propose to tackle these issues by generating a more comprehensive set of implausible stories using plots, which are structured representations of controllable factors used to generate stories.  Since these plots are compact and structured, it is easier to manipulate them to generate text with targeted undesirable properties, while at the same time maintain the naturalness of the generation. To improve the quality of incoherent stories, we further apply the adversarial filtering procedure to select a more nuanced set of implausible texts. We find that the evaluation metrics trained on our generated data result in more reliable automatic assessments that correlate remarkably better with human judgments than other baselines.},
  paper_url={https://www.aclweb.org/anthology/2021.naacl-main.343},
  rank = {42},
  publisher={Association for Computational Linguistics},
  code_url={https://github.com/PlusLabNLP/Plot-guided-Coherence-Evaluation},
  tweet={https://twitter.com/Sarikgha/status/1373029596715646977},
  pages={4334--4344},
presentation_time={12D-ORAL: LANGUAGE RESOURCES AND EVALUATION},
presentation_id={https://underline.io/events/122/sessions/4241/lecture/19650-plot-guided-adversarial-example-construction-for-evaluating-open-domain-story-generation},
  slides_url={https://underline.io/events/122/sessions/4241/lecture/19650-plot-guided-adversarial-example-construction-for-evaluating-open-domain-story-generation},
  year={2021},
  keyword={eval},
}

@inproceedings{chakrabarty2021mermaid,
  title={MERMAID: Metaphor Generation with Symbolism and Discriminative Decoding},
  author={Tuhin Chakrabarty and Xurui Zhang and Smaranda Muresan and Nanyun Peng},
  booktitle={The 2021 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  abstract={Generating metaphors is a challenging task as it requires a proper understanding of abstract concepts, making connections between unrelated concepts, and deviating from the literal meaning. In this paper, we aim to generate a metaphoric sentence given a literal expression by replacing relevant verbs. Based on a theoretically-grounded connection between metaphors and symbols, we propose a method to automatically construct a parallel corpus by transforming a large number of metaphorical sentences from the Gutenberg Poetry corpus (CITATION) to their literal counterpart using recent advances in masked language modeling coupled with commonsense inference. For the generation task, we incorporate a metaphor discriminator to guide the decoding of a sequence to sequence model fine-tuned on our parallel data to generate high-quality metaphors. Human evaluation on an independent test set of literal statements shows that our best model generates metaphors better than three well-crafted baselines 66\% of the time on average. A task-based evaluation shows that human-written poems enhanced with metaphors proposed by our model are preferred 68\% of the time compared to poems without metaphors.},
  paper_url={https://www.aclweb.org/anthology/2021.naacl-main.336},
  rank = {43},
presentation_time={12C-ORAL: LANGUAGE GENERATION},
presentation_id={https://underline.io/events/122/sessions/4240/lecture/19642-mermaid-metaphor-generation-with-symbolism-and-discriminative-decoding},
  code_url={https://github.com/tuhinjubcse/MetaphorGenNAACL2021},
  tweet={https://twitter.com/TuhinChakr/status/1370408736343343106},
  poster_url = {https://underline.io/events/122/posters/4245/poster/20629-mermaid-metaphor-generation-with-symbolism-and-discriminative-decoding},
  talk_url={https://underline.io/events/122/sessions/4240/lecture/19642-mermaid-metaphor-generation-with-symbolism-and-discriminative-decoding},
  year={2021},
  keyword={fig_gen},
}

@inproceedings{ma2021eventplus,
  title={EventPlus: A Temporal Event Understanding Pipeline},
  author={Mingyu Derek Ma and Jiao Sun and Mu Yang and Kung-Hsiang Huang and Nuan Wen and Shikhar Singh and Rujun Han and Nanyun Peng},
  booktitle={2021 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), Demonstrations Track},
  abstract={We present EventPlus, a temporal event understanding pipeline that integrates various state-of-the-art event understanding components including event trigger and type detection, event argument detection, event duration and temporal relation extraction. Event information, especially event temporal knowledge, is a type of common sense knowledge that helps people understand how stories evolve and provides predictive hints for future events. EventPlus as the first comprehensive temporal event understanding pipeline provides a convenient tool for users to quickly obtain annotations about events and their temporal information for any user-provided document. Furthermore, we show EventPlus can be easily adapted to other domains (e.g., biomedical domain). We make EventPlus publicly available to facilitate event-related information extraction and downstream applications.},
presentation_time={10F-POSTER: SYSTEM DEMONSTRATIONS},
presentation_id={https://underline.io/events/122/posters/4227/poster/20582-eventplus-a-temporal-event-understanding-pipeline},
  paper_url={https://www.aclweb.org/anthology/2021.naacl-demos.7},
  code_url={https://kairos-event.isi.edu},
  youtube_id={KPXpKeVIuag},
  slides_url = {https://mingyu.ma/pubs/eventplus/slides_NAACL21.pdf},
  poster_url = {https://mingyu.ma/pubs/eventplus/poster_NAACL21.pdf},
  keyword={event_rel},
  rank = {45},
  year={2021}
}

@article{ghazarian2021discol,
  title={DiSCoL: Toward Engaging Dialogue Systems through Conversational Line Guided Response Generation},
  author={Sarik Ghazarian and Zixi Liu and Tuhin Chakrabarty and Xuezhe Ma and Aram Galstyan and Nanyun Peng},
  booktitle={2021 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), Demonstrations Track},
  abstract={Having engaging and informative conversations with users is the utmost goal for open-domain conversational systems. Recent advances in transformer-based language models and their applications to dialogue systems have succeeded to generate fluent and human-like responses. However, they still lack control over the generation process towards producing contentful responses and achieving engaging conversations. To achieve this goal, we present DiSCoL (Dialogue Systems through Coversational Line guided response generation). DiSCoL is an open-domain dialogue system that leverages conversational lines (briefly convlines) as controllable and informative content-planning elements to guide the generation model produce engaging and informative responses. Two primary modules in DiSCoL’s pipeline are conditional generators trained for 1) predicting relevant and informative convlines for dialogue contexts and 2) generating high-quality responses conditioned on the predicted convlines. Users can also change the returned convlines to control the direction of the conversations towards topics that are more interesting for them. Through automatic and human evaluations, we demonstrate the efficiency of the convlines in producing engaging conversations.},
presentation_time={10F-POSTER: SYSTEM DEMONSTRATIONS},
presentation_id={https://underline.io/events/122/posters/4227/poster/20579-discol-toward-engaging-dialogue-systems-through-conversational-line-guided-response-generation},
  rank = {44},
  pages={26–34},
  paper_url={https://www.aclweb.org/anthology/2021.naacl-demos.4/},
  publisher={Association for Computational Linguistics},
  code_url={https://github.com/PlusLabNLP/Dialogue_System_Hackathon},
  tweet={https://twitter.com/Sarikgha/status/1373034669852135424},
  keyword={dialogue},
  year={2021}
}

@inproceedings{tian2021identifying,
  title={Identifying Distributional Perspective Differences from Colingual Groups},
  author={Tian, Yufei and Chakrabarty, Tuhin and Morstatter, Fred and Peng, Nanyun},
  abstract={Perspective differences exist among different cultures or languages. A lack of mutual understanding among different groups about their perspectives on specific values or events may lead to uninformed decisions or biased opinions. Automatically understanding the group perspectives can provide essential background for many downstream applications of natural language processing techniques. In this paper, we study colingual groups and use language corpora as a proxy to identify their distributional perspectives. We present a novel computational approach to learn shared understandings, and benchmark our method by building culturally-aware models for the English, Chinese, and Japanese languages. On a held out set of diverse topics including marriage, corruption, democracy, our model achieves high correlation with human judgements regarding intra-group values and inter-group differences.},
  booktitle={NAACL 2021 Workshop of Social NLP},
  paper_url={https://www.aclweb.org/anthology/2021.socialnlp-1.16},
  code_url={https://github.com/PlusLabNLP/CLUSTER},
  keyword={commonsense},
presentation_time={NINTH INTERNATIONAL WORKSHOP ON NATURAL LANGUAGE PROCESSING FOR SOCIAL MEDIA (SOCIALNLP 2021)},
presentation_id={https://underline.io/events/122/posters/4298/poster/20429-identifying-distributional-perspectives-from-colingual-groups},
  rank = {46},
  year={2021}
}

@inproceedings{huang2021document,
  title={Document-level Event Extraction with Efficient End-to-end Learning of Cross-event Dependencies},
  author={Huang, Kung-Hsiang and Peng, Nanyun},
  abstract={Fully understanding narratives often requires identifying events in the context of whole documents and modeling the event relations. However, document-level event extraction is a challenging task as it requires the extraction of event and entity coreference, and capturing arguments that span across different sentences. Existing works on event extraction usually confine on extracting events from single sentences, which fail to capture the relationships between the event mentions at the scale of a document, as well as the event arguments that appear in a different sentence than the event trigger. In this paper, we propose an end-to-end model leveraging Deep Value Networks (DVN), a structured prediction algorithm, to efficiently capture cross-event dependencies for document-level event extraction. Experimental results show that our approach achieves comparable performance to CRF-based models on ACE05, while enjoys significantly higher computational efficiency.},
  booktitle={The 3rd Workshop on Narrative Understanding (NAACL 2021)},
presentation_time={THE THIRD WORKSHOP ON NARRATIVE UNDERSTANDING},
presentation_id={https://underline.io/events/122/posters/4309/poster/20541-document-level-event-extraction-with-efficient-end-to-end-learning-of-cross-event-dependencies},
  paper_url={https://www.aclweb.org/anthology/2021.nuse-1.4},
  rank = {47},
  keyword={event},
  year={2021}
}
