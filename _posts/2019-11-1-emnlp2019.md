---
title: UCLA-NLP @ EMNLP2019
layout: post
css: "/css/academicons.css"
tag: [conference]
---

UCLA-NLP presents 3 long papers, 3 short papers, 1 tutorial and 1 demo the at [EMNLP 2019](emnlp-ijcnlp2019.org/) and 2 papers at [CoNLL 2019](https://www.conll.org/).

## [Tutorial: Bias and Fairness in Natual Language Processing]({{site.baseurl}}/talks/emnlp19-fairnlp/)
Instructors: [Kai-Wei Chang](http://kwchang.net), [Vicente Ordonez](http://vicenteordonez.com), [Margaret Mitchell](http://www.m-mitchell.com), [Vinodkumar Prabhakaran](https://www.cs.stanford.edu/~vinod)

  <a data-toggle="collapse" href="#tutorial-relate" class="my_botton">Related Publications </a>
   <a href="{{site.baseurl}}/talks/emnlp19-fairnlp/" class="my_botton">Details</a>
   <div id="tutorial-relate" class="collapse" >
   <div>   
    {% bibliography  -q @*[keyword=fairrep]* %}
    {% bibliography  -q @*[keyword=fairnlp]* %}
   </div>
   </div>


<pre class="pre">
Natural language processing techniques play important roles in our daily life. Despite these methods being successful in various applications, they run the risk of exploiting and reinforcing the societal biases (e.g. gender bias) that are present in the underlying data. For instance, an automatic resume filtering system may inadvertently select candidates based on their gender and race due to implicit associations between applicant names and job titles, causing the system to perpetuate unfairness potentially. In this talk, I will describe a collection of results that quantify and control implicit societal biases in a wide spectrum of vision and language tasks, including word embeddings, coreference resolution, and visual semantic role labeling. These results lead to greater control of NLP systems to be socially responsible and accountable.
</pre>

- [Part1: Cognitive Biases / Data Biases / Bias laundering]({{site.baseurl}}/documents/slides/emnlp19-fairNLP-part1.pdf)
- [Part2: Bias in NLP and Mitigation Approaches]({{site.baseurl}}/documents/slides/emnlp19-fairNLP-part2.pdf)
- [Part3: Building Fair and Robust Representations for Vision and Language]({{site.baseurl}}/documents/slides/emnlp19-fairNLP-part3.pdf)


## Papers
<div style="display:none">
{% cite meng2019target zhou2019examining zhou2019learning parvez2019robust shi2019retrofitting sheng2019woman xia2019visualizing %} 
</div>
{% bibliography --cited --template publications-details %}

<div style="display:none">
{% cite ahmad2019crosslingual chen2019leanring %} 
</div>
{% bibliography --cited --template publications-details %}

