---
title: UCLA-NLP @ ACL2020
layout: post
css: "/css/academicons.css"
tag: [conference]
---

At UCLA-NLP, our mission is to develop fair, accountable, robust natural language processing technology to benefit everyone.
We will present [papers](https://virtual.acl2020.org/papers.html?filter=authors&track=All+tracks&search=Kai-Wei+Chang) at [ACL 2020](https://acl2020.org/) on the following topics.

- [Fairness in NLP](#fair)
- [Analyze and Understand NLP Models](#understand)
- [Energy Efficient Pre-training](#efficent)
- [Enhance Contextulaized Encoder](#architech)

#### [Link to our papers in the virtual conference](https://virtual.acl2020.org/papers.html?filter=authors&track=All+tracks&search=Kai-Wei+Chang)

<hr id = "fair" class="thick">
### Fairness in Natural Language Processing 
Natural Language Processing (NLP) models are widely used in our daily lives. 
Despite these methods achieve high performance in various applications, they run the risk of exploiting and reinforcing the societal biases (e.g. gender bias) that are present in the underlying data.
At ACL, we present our studies on 1) how gender bias is propagated in cross-lingual transfer, 2) how bias is amplified in the distribution of model predictions, and 3) gender bias in relation extraction.

<div style="display:none">
{% cite zhao2020gender gaut2020towards jia2020mitigating %} 
</div>
{% bibliography --cited --template publications-details %}

<hr id = "understand" class="thick">
### Analyze and Understand NLP Models

It is essential to analyze and understand the capability of NLP technology. At ACL, we present the following papers on 1) analyzing the robustness of contextualized language encoders against grammatical errors, 2) understanding what are captured by pre-trained visually grounded language models like [VisualBERT](http://web.cs.ucla.edu/bibliography/li2019visualbert/), and 3) benchmarking transformer-based approaches for source code summarization.

<div style="display:none">
{% cite yin2020robustness li2020what ahmad2020transformer %} 
</div>
{% bibliography --cited --template publications-details %}

<hr id = "efficient">
### Energy Efficient Pre-Training
Contextual representation models greatly improve various NLP tasks. However they are difficult to train due to their large parameter size and high computational complexity. We present a paper to drastically reduce the trainable parameters and training time.

<div style="display:none">
{% cite li2019efficient %}
</div>
{% bibliography --cited --template publications-details %}

<hr id = "architect" class="thick">
### Enhance Contextulaized Encoder
We present the following two papers to enhance contextualized encoders by 1) injecting pronunciation embedding for Pun Recognition, and 2) by incorporating tree structure to capture compositional sentiment semantics for sentiment analysis.

<div style="display:none">
{% cite yin2020sentibert zhou2020boating %} 
</div>
{% bibliography --cited --template publications-details %}
